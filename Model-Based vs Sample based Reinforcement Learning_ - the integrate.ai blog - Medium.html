<!DOCTYPE html>
<!-- saved from url=(0099)https://medium.com/the-official-integrate-ai-blog/understanding-reinforcement-learning-93d4e34e5698 -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/branch-latest.min.js"></script><script async="" src="https://www.google-analytics.com/analytics.js"></script><script>!function(c,f){var t,o,i,e=[],r={passive:!0,capture:!0},n=new Date,a="pointerup",u="pointercancel";function p(n,e){t||(t=e,o=n,i=new Date,w(f),s())}function s(){0<=o&&o<i-n&&(e.forEach(function(n){n(o,t)}),e=[])}function l(n){if(n.cancelable){var e=(1e12<n.timeStamp?new Date:performance.now())-n.timeStamp;"pointerdown"==n.type?function(n,e){function t(){p(n,e),i()}function o(){i()}function i(){f(a,t,r),f(u,o,r)}c(a,t,r),c(u,o,r)}(e,n):p(e,n)}}function w(e){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(n){e(n,l,r)})}w(c),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){e.push(n),s()}}(addEventListener,removeEventListener)</script><script defer="" src="https://cdn.optimizely.com/js/16180790160.js"></script><title>What is Model-Based Reinforcement Learning? - the integrate.ai blog - Medium</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2018-10-29T17:23:36.472Z"><meta data-rh="true" name="title" content="What is Model-Based Reinforcement Learning? - the integrate.ai blog - Medium"><meta data-rh="true" property="og:title" content="What is Model-Based Reinforcement Learning?"><meta data-rh="true" property="twitter:title" content="What is Model-Based Reinforcement Learning?"><meta data-rh="true" name="twitter:site" content="@Medium"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/93d4e34e5698"><meta data-rh="true" property="al:android:url" content="medium://p/93d4e34e5698"><meta data-rh="true" property="al:ios:url" content="medium://p/93d4e34e5698"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="This post was originally sent as our monthly newsletter about trends in machine learning and artificial intelligence. If you’d like these analyses delivered directly to your inbox, subscribe here…"><meta data-rh="true" property="og:description" content="Our monthly analysis on machine learning trends"><meta data-rh="true" property="twitter:description" content="Our monthly analysis on machine learning trends"><meta data-rh="true" property="og:url" content="https://medium.com/the-official-integrate-ai-blog/understanding-reinforcement-learning-93d4e34e5698"><meta data-rh="true" property="al:web:url" content="https://medium.com/the-official-integrate-ai-blog/understanding-reinforcement-learning-93d4e34e5698"><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1128/1*iKKuLzwvS24L1mML4N8A_A.png"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1128/1*iKKuLzwvS24L1mML4N8A_A.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="article:author" content="https://medium.com/@integrate.ai"><meta data-rh="true" name="twitter:creator" content="@IntegrateAI"><meta data-rh="true" name="author" content="integrate.ai"><meta data-rh="true" name="robots" content="index,follow"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" name="twitter:label1" value="Reading time"><meta data-rh="true" name="twitter:data1" value="8 min read"><meta data-rh="true" name="parsely-post-id" content="93d4e34e5698"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://medium.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/m2.css"><link data-rh="true" rel="author" href="https://medium.com/@integrate.ai"><link data-rh="true" rel="canonical" href="https://medium.com/the-official-integrate-ai-blog/understanding-reinforcement-learning-93d4e34e5698"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/93d4e34e5698"><link data-rh="true" rel="icon" href="https://cdn-static-1.medium.com/_/fp/icons/favicon-rebrand-medium.3Y6xpZ-0FSdWDnPM3hSBIA.ico"><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F1*iKKuLzwvS24L1mML4N8A_A.png"],"url":"https:\u002F\u002Fmedium.com\u002Fthe-official-integrate-ai-blog\u002Funderstanding-reinforcement-learning-93d4e34e5698","dateCreated":"2018-10-01T15:39:53.383Z","datePublished":"2018-10-01T15:39:53.383Z","dateModified":"2018-10-29T17:23:36.472Z","headline":"What is Model-Based Reinforcement Learning? - the integrate.ai blog - Medium","name":"What is Model-Based Reinforcement Learning? - the integrate.ai blog - Medium","description":"This post was originally sent as our monthly newsletter about trends in machine learning and artificial intelligence. If you’d like these analyses delivered directly to your inbox, subscribe here…","identifier":"93d4e34e5698","keywords":["Lite:true","Tag:Machine Learning","Tag:Blog","Tag:Reinforcement Learning","Topic:Machine Learning","Publication:the-official-integrate-ai-blog","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_NONE","LayerCake:3"],"author":{"@type":"Person","name":"integrate.ai","url":"https:\u002F\u002Fmedium.com\u002F@integrate.ai"},"creator":["integrate.ai"],"publisher":{"@type":"Organization","name":"the integrate.ai blog","url":"https:\u002F\u002Fmedium.com\u002Fthe-official-integrate-ai-blog","logo":{"@type":"ImageObject","width":170,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F340\u002F1*eeO70qvAHD7978tgMKyCUw.png"}},"mainEntityOfPage":"https:\u002F\u002Fmedium.com\u002Fthe-official-integrate-ai-blog\u002Funderstanding-reinforcement-learning-93d4e34e5698"}</script><script data-rh="true">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><link rel="preload" href="https://cdn.optimizely.com/js/16180790160.js" as="script"><style type="text/css" data-fela-rehydration="463" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-webkit-keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@-moz-keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@-webkit-keyframes k3{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}@-moz-keyframes k3{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}@keyframes k3{0%{transform:matrix(0.97, 0, 0, 1, 0, 12);opacity:0}20%{transform:matrix(0.99, 0, 0, 1, 0, 2);opacity:0.7}40%{transform:matrix(1, 0, 0, 1, 0, -1);opacity:1}70%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}100%{transform:matrix(1, 0, 0, 1, 0, 0);opacity:1}}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{fill:rgba(0, 0, 0, 0.84)}.r{display:block}.s{position:absolute}.t{top:0}.u{left:0}.v{right:0}.w{z-index:500}.x{box-shadow:0 4px 12px 0 rgba(0, 0, 0, 0.05)}.ag{max-width:1192px}.ah{min-width:0}.ai{width:100%}.aj{height:65px}.am{flex:1 0 auto}.an{visibility:hidden}.ao{margin-left:16px}.ap{display:none}.ar{color:rgba(28, 153, 99, 1)}.as{fill:rgba(2, 184, 117, 1)}.at{font-size:inherit}.au{border:inherit}.av{font-family:inherit}.aw{letter-spacing:inherit}.ax{font-weight:inherit}.ay{padding:0}.az{margin:0}.ba:hover{cursor:pointer}.bb:hover{color:rgba(11, 59, 40, 1)}.bc:hover{fill:rgba(28, 153, 99, 1)}.bd:focus{outline:none}.be:disabled{cursor:default}.bf:disabled{color:rgba(140, 93, 255, 0.5)}.bg:disabled{fill:rgba(140, 93, 255, 0.5)}.bh{flex:0 0 auto}.bi{font-family:medium-content-sans-serif-font, "Lucida Grande", "Lucida Sans Unicode", "Lucida Sans", Geneva, Arial, sans-serif}.bj{font-style:normal}.bk{line-height:20px}.bl{font-size:15.8px}.bm{letter-spacing:0px}.bn{color:rgba(0, 0, 0, 0.54)}.bo{fill:rgba(0, 0, 0, 0.54)}.bp{justify-content:flex-end}.bq{margin-top:16px}.br{margin-bottom:16px}.bs{display:inherit}.bt{max-width:210px}.bu{text-overflow:ellipsis}.bv{overflow:hidden}.bw{white-space:nowrap}.bx{display:inline-block}.by{border:none}.bz{outline:none}.ca{font:inherit}.cb{font-size:16px}.cc{opacity:0}.cd{position:relative}.ce{width:0px}.cf{transition:width 140ms ease-in}.cg{color:inherit}.ch{fill:inherit}.ci:hover{color:rgba(0, 0, 0, 0.9)}.cj:hover{fill:rgba(0, 0, 0, 0.9)}.ck:disabled{color:rgba(0, 0, 0, 0.54)}.cl:disabled{fill:rgba(0, 0, 0, 0.54)}.cm{margin-right:10px}.cq{margin-right:16px}.cr{margin:15px 0}.cs{padding:4px 12px}.ct{color:rgba(0, 0, 0, 0.84)}.cu{background:0}.cv{border-color:rgba(0, 0, 0, 0.54)}.cw:hover{color:rgba(0, 0, 0, 0.97)}.cx:hover{fill:rgba(0, 0, 0, 0.97)}.cy:hover{border-color:rgba(0, 0, 0, 0.84)}.cz:disabled{fill:rgba(0, 0, 0, 0.76)}.da:disabled{border-color:rgba(0, 0, 0, 0.2)}.db:disabled{cursor:inherit}.dc:disabled:hover{color:rgba(0, 0, 0, 0.54)}.dd:disabled:hover{fill:rgba(0, 0, 0, 0.76)}.de:disabled:hover{border-color:rgba(0, 0, 0, 0.2)}.df{border-radius:4px}.dg{border-width:1px}.dh{border-style:solid}.di{box-sizing:border-box}.dj{text-decoration:none}.dk{padding-bottom:10px}.dl{padding-top:10px}.dm{border-radius:50%}.dn{height:32px}.do{width:32px}.dp{border-top:1px solid rgba(0, 0, 0, 0.1)}.dq{height:54px}.dr{margin-right:40px}.ds{height:36px}.dt{width:102px}.du{overflow:auto}.dv{flex:0 1 auto}.dw{list-style-type:none}.dx{line-height:40px}.dy{overflow-x:auto}.dz{align-items:flex-start}.ea{margin-top:20px}.eb{padding-top:20px}.ec{height:80px}.ed{height:20px}.ee{margin-right:15px}.ef{margin-left:15px}.eg:first-child{margin-left:0}.eh{font-weight:300}.ei{font-size:15px}.ej{text-transform:uppercase}.ek{letter-spacing:1px}.el{margin-bottom:0px}.em{height:119px}.ep{padding-left:24px}.eq{padding-right:24px}.er{margin-left:auto}.es{margin-right:auto}.et{max-width:728px}.eu{top:calc(100vh + 100px)}.ev{bottom:calc(100vh + 100px)}.ew{width:10px}.ex{pointer-events:none}.ey{word-break:break-word}.ez{word-wrap:break-word}.fa:after{display:block}.fb:after{content:""}.fc:after{clear:both}.fd{max-width:680px}.fe{line-height:1.23}.ff{letter-spacing:0}.fg{font-family:medium-content-title-font, Georgia, Cambria, "Times New Roman", Times, serif}.fr{margin-bottom:-0.27em}.fx{line-height:1.394}.gi{margin-bottom:-0.42em}.go{margin-top:32px}.gp{justify-content:space-between}.gt{height:48px}.gu{width:48px}.gv{margin-left:12px}.gw{margin-bottom:2px}.gy{max-height:20px}.gz{display:-webkit-box}.ha{-webkit-line-clamp:1}.hb{-webkit-box-orient:vertical}.hc:hover{text-decoration:underline}.hd{margin-left:8px}.he{padding:0px 8px}.hf{border-color:rgba(2, 184, 117, 1)}.hg:hover{border-color:rgba(28, 153, 99, 1)}.hh{line-height:18px}.hi{align-items:flex-end}.hq{padding-right:6px}.hr{margin-right:8px}.hs{fill:rgba(0, 0, 0, 0.76)}.ht{margin-right:-6px}.hu{line-height:1.58}.hv{letter-spacing:-0.004em}.hw{font-family:medium-content-serif-font, Georgia, Cambria, "Times New Roman", Times, serif}.if{margin-bottom:-0.46em}.ig{letter-spacing:-0.003em}.ij{font-style:italic}.ik{background-repeat:repeat-x}.il{background-image:linear-gradient(to right,rgba(0, 0, 0, 0.84) 100%,rgba(0, 0, 0, 0.84) 0);background-image:url('data:image/svg+xml;utf8,<svg preserveAspectRatio="none" viewBox="0 0 1 1" xmlns="http://www.w3.org/2000/svg"><line x1="0" y1="0" x2="1" y2="1" stroke="rgba(0, 0, 0, 0.84)" /></svg>')}.im{background-size:1px 1px}.in{background-position:0 1.05em;background-position:0 calc(1em + 1px)}.io{max-width:1128px}.iu{clear:both}.iv{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.iw{cursor:zoom-in}.ix{z-index:auto}.iy{transition:opacity 100ms 400ms}.iz{height:100%}.ja{will-change:transform}.jb{transform:translateZ(0)}.jc{margin:auto}.jd{background-color:rgba(0, 0, 0, 0.05)}.je{padding-bottom:75.53191489361701%}.jf{height:0}.jg{filter:blur(20px)}.jh{transform:scale(1.1)}.ji{visibility:visible}.jj{background:rgba(255, 255, 255, 1)}.jk{margin-top:10px}.jl{text-align:center}.jo{box-shadow:inset 3px 0 0 0 rgba(0, 0, 0, 0.84)}.jp{padding-left:23px}.jq{margin-left:-20px}.jr{font-weight:700}.js{line-height:1.12}.jt{letter-spacing:-0.022em}.ju{font-weight:600}.kd{margin-bottom:-0.28em}.kj{max-width:1140px}.kk{padding-bottom:57.36842105263158%}.kl{max-width:1108px}.km{padding-bottom:59.74729241877256%}.kn{will-change:opacity}.ko{position:fixed}.kp{width:188px}.kq{left:50%}.kr{transform:translateX(406px)}.ks{top:calc(65px + 54px + 14px)}.kv{top:calc(65px + 54px + 40px)}.kx{width:131px}.ky{flex-direction:column}.kz{padding-bottom:28px}.la{border-bottom:1px solid rgba(0, 0, 0, 0.1)}.lb{font-size:18px}.lc{padding-bottom:20px}.ld{padding-top:2px}.le{max-height:120px}.lf{-webkit-line-clamp:6}.lg{padding-top:28px}.lh{margin-bottom:19px}.li{margin-left:-3px}.lo{outline:0}.lp{border:0}.lq{user-select:none}.lr{cursor:pointer}.ls> svg{pointer-events:none}.lt:active{border-style:none}.lu{-webkit-user-select:none}.lv:focus{fill:rgba(0, 0, 0, 0.54)}.lw:hover{fill:rgba(0, 0, 0, 0.54)}.me button{text-align:left}.mf{margin-top:40px}.mg{flex-wrap:wrap}.mh{margin-top:25px}.mi{margin-bottom:8px}.mj{border-radius:3px}.mk{padding:5px 10px}.ml{background:rgba(0, 0, 0, 0.05)}.mm{line-height:22px}.mn{margin-top:15px}.mo{flex-direction:row}.mp{max-width:155px}.mv{border:1px solid rgba(0, 0, 0, 0.1)}.mw{height:60px}.mx{width:60px}.nk:hover{border-color:rgba(0, 0, 0, 0.54)}.nl:active{border-style:solid}.nm{z-index:2}.no{top:1px}.nu{padding-right:8px}.nv{padding-top:32px}.nw{margin-bottom:25px}.ny{margin-bottom:32px}.nz{min-height:80px}.oe{width:80px}.of{padding-left:102px}.oh{letter-spacing:0.05em}.oi{margin-bottom:6px}.oj{font-size:28px}.ok{line-height:36px}.ol{max-width:555px}.om{max-width:450px}.on{line-height:24px}.op{max-width:550px}.oq{padding-top:24px}.or{margin-top:5px}.os{height:40px}.ot{width:40px}.ou{font-size:12px}.ov{line-height:15px}.ow{padding-top:8px}.ox{padding-top:25px}.oz{color:rgba(0, 0, 0, 0.76)}.pa{opacity:1}.pb{padding:20px}.pc{border:1px solid rgba(2, 184, 117, 1)}.pd{margin-top:64px}.pe{background-color:rgba(0, 0, 0, 0.02)}.pf{padding:60px 0}.pg{background-color:rgba(0, 0, 0, 0.9)}.px{padding-bottom:48px}.py{border-bottom:1px solid rgba(255, 255, 255, 0.54)}.pz{margin:0 -12px}.qa{margin:0 12px}.qb{flex:1 1 0}.qc{padding-bottom:12px}.qd:hover{color:rgba(255, 255, 255, 0.99)}.qe:hover{fill:rgba(255, 255, 255, 0.99)}.qf:disabled{color:rgba(255, 255, 255, 0.7)}.qg:disabled{fill:rgba(255, 255, 255, 0.7)}.qh{color:rgba(255, 255, 255, 0.98)}.qi{fill:rgba(255, 255, 255, 0.98)}.qj{text-align:inherit}.qk{font-size:21.6px}.ql{letter-spacing:-0.32px}.qm{color:rgba(255, 255, 255, 0.7)}.qn{fill:rgba(255, 255, 255, 0.7)}.qo{text-decoration:underline}.qp{padding-bottom:8px}.qq{width:200px}.qw:disabled{color:rgba(3, 168, 124, 0.5)}.qx:disabled{fill:rgba(3, 168, 124, 0.5)}.qy{-webkit-user-select:none}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.af{margin:0 64px}.fp{font-size:40px}.fq{margin-top:0.78em}.fw{line-height:48px}.gg{font-size:24px}.gh{margin-top:0.79em}.gn{line-height:32px}.hp{margin-left:30px}.id{font-size:21px}.ie{margin-top:2em}.it{margin-top:56px}.kb{font-size:34px}.kc{margin-top:1.95em}.ki{margin-top:0.86em}.ln{margin-right:5px}.md{margin-top:5px}.mu{margin-right:16px}.nt{width:25px}.pu{padding-left:64px}.pv{padding-right:64px}.pw{max-width:1320px}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.ho{margin-left:30px}.jm{margin-left:auto}.jn{text-align:center}.lm{margin-right:5px}.mc{margin-top:5px}.mt{margin-right:16px}.ns{width:25px}.pr{padding-left:64px}.ps{padding-right:64px}.pt{max-width:1080px}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.cp{display:flex}.hn{margin-left:30px}.ll{margin-right:5px}.mb{margin-top:5px}.ms{margin-right:16px}.nr{width:15px}.po{padding-left:48px}.pp{padding-right:48px}.pq{max-width:904px}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.ak{height:56px}.al{display:flex}.aq{display:block}.cn{margin-left:10px}.co{margin-right:10px}.en{margin-bottom:0px}.eo{height:110px}.gr{margin-top:32px}.gs{flex-direction:column-reverse}.hl{margin-bottom:30px}.hm{margin-left:0px}.lk{margin-left:8px}.lz{margin-top:2px}.ma{margin-right:8px}.mr{margin-left:16px}.nq{width:15px}.nx{padding-top:0}.oa{margin-bottom:24px}.ob{align-items:center}.oc{width:102px}.od{position:relative}.og{padding-left:0}.oo{margin-top:24px}.oy{border-top:none}.ph{padding:32px 0}.pl{padding-left:24px}.pm{padding-right:24px}.pn{max-width:728px}.qr{width:140px}.qs{margin-bottom:16px}.qt{margin-top:30px}.qu{width:100%}.qv{flex-direction:row}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.z{margin:0 24px}.fh{font-size:30px}.fi{margin-top:0.72em}.fs{line-height:40px}.fy{font-size:18px}.fz{margin-top:0.79em}.gj{line-height:24px}.gq{margin-top:32px}.gx{margin-bottom:0px}.hj{margin-bottom:30px}.hk{margin-left:0px}.hx{margin-top:1.56em}.ih{line-height:28px}.ip{margin-top:40px}.jv{margin-top:1.2em}.ke{margin-top:0.67em}.lj{margin-left:8px}.lx{margin-top:2px}.ly{margin-right:8px}.mq{margin-left:16px}.np{width:15px}.pi{padding-left:24px}.pj{padding-right:24px}.pk{max-width:552px}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.ae{margin:0 64px}.fn{font-size:40px}.fo{margin-top:0.78em}.fv{line-height:48px}.ge{font-size:24px}.gf{margin-top:0.79em}.gm{line-height:32px}.ib{font-size:21px}.ic{margin-top:2em}.is{margin-top:56px}.jz{font-size:34px}.ka{margin-top:1.95em}.kh{margin-top:0.86em}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.ac{margin:0 48px}.fl{font-size:40px}.fm{margin-top:0.78em}.fu{line-height:48px}.gc{font-size:24px}.gd{margin-top:0.79em}.gl{line-height:32px}.hz{font-size:21px}.ia{margin-top:2em}.ir{margin-top:56px}.jx{font-size:34px}.jy{margin-top:1.95em}.kg{margin-top:0.86em}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.ab{margin:0 24px}.fj{font-size:30px}.fk{margin-top:0.72em}.ft{line-height:40px}.ga{font-size:18px}.gb{margin-top:0.79em}.gk{line-height:24px}.hy{margin-top:1.56em}.ii{line-height:28px}.iq{margin-top:40px}.jw{margin-top:1.2em}.kf{margin-top:0.67em}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="print">.y{display:none}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.kt{transition:opacity 200ms}.my{transition:border-color 150ms ease}.mz::before{background:
      radial-gradient(circle, rgba(0, 0, 0, 0.84) 60%, transparent 70%)
    }.na::before{border-radius:50%}.nb::before{content:""}.nc::before{display:block}.nd::before{z-index:0}.ne::before{left:0}.nf::before{height:100%}.ng::before{position:absolute}.nh::before{top:0}.ni::before{width:100%}.nj:hover::before{animation:k2 2000ms infinite cubic-bezier(.1,.12,.25,1)}.nn{transition:fill 200ms ease}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (max-width: 1230px)">.ku{display:none}</style><style type="text/css" data-fela-rehydration="463" data-fela-type="RULE" media="all and (max-width: 1198px)">.kw{display:none}</style><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><nav class="r s t u v c w x y"><div><div class="r c"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="aj n o ak al"><div class="n o am w"><a href="https://medium.com/?source=post_page-----93d4e34e5698----------------------" aria-label="Homepage" rel="noopener"><svg width="35" height="35" viewBox="5 5 35 35" class="q"><path d="M5 40V5h35v35H5zm8.56-12.63c0 .56-.03.69-.32 1.03L10.8 31.4v.4h6.97v-.4L15.3 28.4c-.29-.34-.34-.5-.34-1.03v-8.95l6.13 13.36h.71l5.26-13.36v10.64c0 .3 0 .35-.19.53l-1.85 1.8v.4h9.2v-.4l-1.83-1.8c-.18-.18-.2-.24-.2-.53V15.94c0-.3.02-.35.2-.53l1.82-1.8v-.4h-6.47l-4.62 11.55-5.2-11.54h-6.8v.4l2.15 2.63c.24.3.29.37.29.77v10.35z"></path></svg></a><div class="ji" id="li-general-navbar-open-in-app-button"><div class="ao ap aq"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F93d4e34e5698&amp;~feature=LiMobileNavBar&amp;~channel=ShowPostUnderCollection&amp;source=post_page-----93d4e34e5698----------------------" class="ar as at au av aw ax ay az ba bb bc bd be bf bg" rel="noopener nofollow">Open in app</a></div></div></div><div class="r bh w"><span class="bi b bj bk bl bm r bn bo"><div class="n o bp"><div class="n f"><div class="bx" aria-hidden="true"><div class="n"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25" class="ao cm r cn co"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></button><input class="by bz ca cb bk cc cd ce cf" placeholder="Search the integrate.ai blog" value=""></div></div></div><div class="ap cp"><a href="https://medium.com/search?source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="ao cq r cn co"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></a></div><a class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener" href="https://medium.com/me/list/queue?source=post_page-----93d4e34e5698----------------------"><svg width="25" height="25" viewBox="0 0 25 25" class="cq r g"><path d="M16 6a2 2 0 0 1 2 2v13.66h-.01a.5.5 0 0 1-.12.29.5.5 0 0 1-.7.03l-5.67-4.13-5.66 4.13a.5.5 0 0 1-.7-.03.48.48 0 0 1-.13-.29H5V8c0-1.1.9-2 2-2h9zM6 8v12.64l5.16-3.67a.49.49 0 0 1 .68 0L17 20.64V8a1 1 0 0 0-1-1H7a1 1 0 0 0-1 1z"></path><path d="M21 5v13.66h-.01a.5.5 0 0 1-.12.29.5.5 0 0 1-.7.03l-.17-.12V5a1 1 0 0 0-1-1h-9a1 1 0 0 0-1 1H8c0-1.1.9-2 2-2h9a2 2 0 0 1 2 2z"></path></svg></a><div class="cq n co"><div class="bx" aria-hidden="true"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl r"><svg width="25" height="25" viewBox="-293 409 25 25" class="cr r"><path d="M-273.33 423.67l-1.67-1.52v-3.65a5.5 5.5 0 0 0-6.04-5.47 5.66 5.66 0 0 0-4.96 5.71v3.41l-1.68 1.55a1 1 0 0 0-.32.74V427a1 1 0 0 0 1 1h3.49a3.08 3.08 0 0 0 3.01 2.45 3.08 3.08 0 0 0 3.01-2.45h3.49a1 1 0 0 0 1-1v-2.59a1 1 0 0 0-.33-.74zm-7.17 5.63c-.84 0-1.55-.55-1.81-1.3h3.62a1.92 1.92 0 0 1-1.81 1.3zm6.35-2.45h-12.7v-2.35l1.63-1.5c.24-.22.37-.53.37-.85v-3.41a4.51 4.51 0 0 1 3.92-4.57 4.35 4.35 0 0 1 4.78 4.33v3.65c0 .32.14.63.38.85l1.62 1.48v2.37z"></path></svg></button></div></div><div class="ji" id="li-post-page-navbar-upsell-button"><div class="cq r g"><div><a href="https://medium.com/membership?source=upgrade_membership---nav_full------------------------" class="cs ct q cu cv cw cx cy ba ck cz da db dc dd de df bi b bj bk bl bm dg dh di bx dj bd" rel="noopener">Upgrade</a></div></div></div><div class="n" aria-hidden="true"><div class="dk dl n o"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><img alt="Ayushverma" class="r dm dn do" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/0_fSKu5zWydc5B9tfM" width="32" height="32"></button></div></div></div></span></div></div></div></div></div><div class="dp r c aq"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="dq bv n o"><div class="dr r bh"><a href="https://medium.com/the-official-integrate-ai-blog?source=post_page-----93d4e34e5698----------------------" rel="noopener"><div class="ds dt r"><img alt="the integrate.ai blog" class="" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_eeO70qvAHD7978tgMKyCUw.png" width="102" height="36"></div></a></div><div class="du r dv"><ul class="dw az dx bw dy n dz g ea eb ec"><li class="n o ed ee ef eg"><span class="bi eh ei bk bn ej ek"><a href="https://medium.com/the-official-integrate-ai-blog/news/home?source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener">News</a></span></li><li class="n o ed ee ef eg"><span class="bi eh ei bk bn ej ek"><a href="https://medium.com/the-official-integrate-ai-blog/incontext/home?source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener">Podcast</a></span></li><li class="n o ed ee ef eg"><span class="bi eh ei bk bn ej ek"><a href="https://medium.com/the-official-integrate-ai-blog/blog/home?source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener">Blog</a></span></li></ul></div></div></div></div></div></div></nav><div class="el em r en eo"></div><article><section class="ep eq er es ai et di r"></section><span class="r"></span><div><div class="s u eu ev ew ex"></div><div class="er es et cd"><div class="r h g f e"><aside class="qz s t" style="width: 720px;"><div class="rd re s rf bw ai"><h4 class="bi eh ei bk bn"><span class="bx re bw bv bu">Top highlight</span></h4></div></aside></div></div><section class="ey ez fa fb fc"><div class="n p"><div class="z ab ac ae af fd ah ai"><div><div id="ffa8" class="fe ff ct bj fg b fh fi fj fk fl fm fn fo fp fq fr"><h1 class="fg b fh fs fj ft fl fu fn fv fp fw ct">What is Model-Based Reinforcement Learning?</h1></div></div><h2 id="c481" class="fx ff bn bj bi eh fy fz gj ga gb gk gc gd gl ge gf gm gg gh gn gi">Our monthly analysis on machine learning trends</h2><div class="go"><div class="n gp gq gr gs"><div class="o n"><div><a rel="noopener" href="https://medium.com/@integrate.ai?source=post_page-----93d4e34e5698----------------------"><img alt="integrate.ai" class="r dm gt gu" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_j2sYTw20WODHLS4w0rD8dQ.png" width="48" height="48"></a></div><div class="gv ai r"><div class="n"><div style="flex:1"><span class="bi b bj bk bl bm r ct q"><div class="gw n o gx"><span class="bi eh cb bk bv gy bu gz ha hb ct"><a class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener" href="https://medium.com/@integrate.ai?source=post_page-----93d4e34e5698----------------------">integrate.ai</a></span><div class="hd r bh h"><button class="he cu ar as hf bb bc hg ba df bi b bj hh ei bm dg dh di bx dj bd">Follow</button></div></div></span></div></div><span class="bi b bj bk bl bm r bn bo"><span class="bi eh cb bk bv gy bu gz ha hb bn"><div><a class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener" href="https://medium.com/the-official-integrate-ai-blog/understanding-reinforcement-learning-93d4e34e5698?source=post_page-----93d4e34e5698----------------------">Oct 1, 2018</a> <!-- -->·<!-- --> <!-- -->8<!-- --> min read</div></span></span></div></div><div class="n hi hj hk hl hm hn ho hp y"><div class="n o"><div class="hq r bh"><a href="https://medium.com/p/93d4e34e5698/share/twitter?source=post_actions_header---------------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></a></div><div class="hq r bh"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="q"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="hq r bh"><a href="https://medium.com/p/93d4e34e5698/share/facebook?source=post_actions_header---------------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></a></div><div class="hr r"><div><div class="hs"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="1" aria-labelledby="1"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div><div class="ht r am"><div class="bx" aria-hidden="true"><div class="bx" aria-hidden="true"><div class="r bh"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="-480.5 272.5 21 21" class="q"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></button></div></div></div></div></div></div></div></div><p id="9a5c" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph=""><em class="ij">This post was originally sent as our monthly newsletter about trends in machine learning and artificial intelligence. If you’d like these analyses delivered directly to your inbox, </em><a href="https://www.integrate.ai/subscribe/" class="cg dj ik il im in" target="_blank" rel="noopener nofollow"><em class="ij">subscribe here</em></a><em class="ij">!</em></p><p id="8474" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">Machines learn differently than people. For instance, you probably didn’t learn the difference between a positive and a negative movie review by analyzing tens of thousands of labeled examples of each. There is, however, a specific subfield of machine learning that bears a striking resemblance to aspects of how we learn.</p><p id="fc8e" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">Reinforcement learning (RL) is a field that’s been around for a few decades. Lately, it’s been picking up steam thanks to its integration of deep neural networks (deep reinforcement learning) and the <a href="https://www.theatlantic.com/technology/archive/2016/03/the-invisible-opponent/475611/" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">newsworthy successes</a> it’s accumulated as a result. At its core though, RL is concerned with how to go about making decisions and taking sequential actions in a specific environment to maximize a reward. Or, to put a more personal spin on it, what steps should you take to get promoted at your job, or to improve your fitness, or to save money to buy a house? We tend to figure out an optimal approach to accomplish goals like these through some degree of trial and error, evolving our strategies based on feedback from our environment.</p><p id="bf55" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">At a basic level, RL works in much the same way. Of course, backed by computing power, it can explore different strategies (or “policies” in the RL literature) much faster than we can, often with pretty impressive results (especially for <a href="https://www.youtube.com/watch?v=TmPfTpjtdgg" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">simple environments</a>). On the other hand, lacking the <a href="https://www.technologyreview.com/s/610434/why-humans-learn-faster-than-ai-for-now/" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">prior knowledge that humans bring to new situations and environments</a>, RL approaches also tend to need to explore many more policies than a human would before finding an optimal one.</p><figure class="ip iq ir is it iu er es paragraph-image"><div class="iv iw cd ix ai"><div class="er es io"><div class="jc r cd jd"><div class="je jf r"><div class="cc iy s t u iz ai bv ja jb"><img class="s t u iz ai jg jh an rg" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_iKKuLzwvS24L1mML4N8A_A.png" width="1128" height="852" role="presentation"></div><img class="pa rc s t u iz ai jj" width="1128" height="852" srcset="https://miro.medium.com/max/552/1*iKKuLzwvS24L1mML4N8A_A.png 276w, https://miro.medium.com/max/1104/1*iKKuLzwvS24L1mML4N8A_A.png 552w, https://miro.medium.com/max/1280/1*iKKuLzwvS24L1mML4N8A_A.png 640w, https://miro.medium.com/max/1400/1*iKKuLzwvS24L1mML4N8A_A.png 700w" sizes="700px" role="presentation" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_iKKuLzwvS24L1mML4N8A_A(1).png"><noscript><img class="s t u iz ai" src="https://miro.medium.com/max/2256/1*iKKuLzwvS24L1mML4N8A_A.png" width="1128" height="852" srcSet="https://miro.medium.com/max/552/1*iKKuLzwvS24L1mML4N8A_A.png 276w, https://miro.medium.com/max/1104/1*iKKuLzwvS24L1mML4N8A_A.png 552w, https://miro.medium.com/max/1280/1*iKKuLzwvS24L1mML4N8A_A.png 640w, https://miro.medium.com/max/1400/1*iKKuLzwvS24L1mML4N8A_A.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="jk jl et er es jm jn bi eh cb bk bn" data-selectable-paragraph="">Google DeepMind’s <a href="https://deepmind.com/blog/producing-flexible-behaviours-simulated-environments/" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">research</a> demonstrates how a humanoid figure can learn to<br>maneuver around a simulated environment</figcaption></figure><p id="a566" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">As reinforcement learning is a broad field, let’s focus on one specific aspect: model-based reinforcement learning. <mark class="ra rb lr">As we’ll see, model-based RL attempts to overcome the issue of a lack of prior knowledge by enabling the agent — whether this agent happens to be a robot in the real world, an avatar in a virtual one, or just a piece software that take actions — to construct a functional representation of its environment.</mark></p><p id="439b" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">While model-based reinforcement learning may not have clear commercial applications at this stage, its potential impact is enormous. After all, as AI becomes more complex and adaptive — extending beyond a focus on classification and representation toward more human-centered capabilities — model-based RL will almost certainly play an essential role in shaping these frontiers.</p><blockquote class="jo jp jq"><p id="fcdf" class="hu ig ct ij hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">“The next big step forward in AI will be systems that actually understand their worlds. The world is only accessed through the lens of experience, so to understand the world means to be able to predict and control your experience, your sense data, with some accuracy and flexibility. In other words, understanding means forming a predictive model of the world and using it to get what you want. This is model-based reinforcement learning.”</p><p id="6553" class="hu ig ct ij hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph=""><strong class="hw jr">Richard S. Sutton<br>Primary Researcher at the Alberta Machine Intelligence Institute</strong></p></blockquote><h1 id="eef6" class="js jt ct bj bi ju fh jv fj jw jx jy jz ka kb kc kd" data-selectable-paragraph=""><strong class="ax">To Model or Not to Model</strong></h1><p id="82dc" class="hu ig ct bj hw b fy ke ih ga kf ii hz kg gl ib kh gm id ki gn if ey" data-selectable-paragraph="">“Model” is one of those terms that gets thrown around a lot in machine learning (and in scientific disciplines more generally), often with a relatively vague explanation of what we mean. Fortunately, in reinforcement learning, a model has a very specific meaning: it refers to the different dynamic states of an environment and how these states lead to a reward.</p><p id="0713" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">Model-based RL entails constructing such a model. Model-free RL, conversely, forgoes this environmental information and only concerns itself with determining what action to take given a specific state. As a result, model-based RL tends to emphasize planning, whereas model-free RL tends to emphasize learning (that said, a lot of learning also goes on in model-based RL). The distinction between these two approaches can seem a bit abstract, so let’s consider a real-world analogy.</p><p id="44c0" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">Imagine you’re visiting a city that you’ve never been to before and for whatever reason you don’t have access to a map. You know the general direction from your hotel to the area where most of the sights of interest are, but there are quite a number of different possible routes, some of which lead you through a slightly dangerous neighborhood.</p><figure class="ip iq ir is it iu er es paragraph-image"><div class="iv iw cd ix ai"><div class="er es kj"><div class="jc r cd jd"><div class="kk jf r"><div class="cc iy s t u iz ai bv ja jb"><img class="s t u iz ai jg jh an rg" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_mbL0rXZdVBkG7BrlNFxmpA.png" width="1140" height="654" role="presentation"></div><img class="pa rc s t u iz ai jj" width="1140" height="654" srcset="https://miro.medium.com/max/552/1*mbL0rXZdVBkG7BrlNFxmpA.png 276w, https://miro.medium.com/max/1104/1*mbL0rXZdVBkG7BrlNFxmpA.png 552w, https://miro.medium.com/max/1280/1*mbL0rXZdVBkG7BrlNFxmpA.png 640w, https://miro.medium.com/max/1400/1*mbL0rXZdVBkG7BrlNFxmpA.png 700w" sizes="700px" role="presentation" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_mbL0rXZdVBkG7BrlNFxmpA(1).png"><noscript><img class="s t u iz ai" src="https://miro.medium.com/max/2280/1*mbL0rXZdVBkG7BrlNFxmpA.png" width="1140" height="654" srcSet="https://miro.medium.com/max/552/1*mbL0rXZdVBkG7BrlNFxmpA.png 276w, https://miro.medium.com/max/1104/1*mbL0rXZdVBkG7BrlNFxmpA.png 552w, https://miro.medium.com/max/1280/1*mbL0rXZdVBkG7BrlNFxmpA.png 640w, https://miro.medium.com/max/1400/1*mbL0rXZdVBkG7BrlNFxmpA.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="jk jl et er es jm jn bi eh cb bk bn" data-selectable-paragraph="">A state graph from a <a href="https://www.semanticscholar.org/paper/Behavioural-Animation-of-Autonomous-Virtual-Agents-Conde-Tambellini/ed15732e8864376e78ef6410072b77387aeec267" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">paper</a> on RL approaches for simulated urban environments</figcaption></figure><p id="2755" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">One navigational option is to keep track of all the routes you’ve taken (and the different streets and landmarks that make up these routes) to begin to create a map of the area. This map would be incomplete (it would only rely on where you’d already walked), but would at least allow you to plan a course ahead of time to avoid that neighborhood while still optimizing for the most direct route. You could even spend time back in your hotel room drawing out the different possible itineraries on a sheet of paper and trying to gauge which one seems like the best overall option. You can think of this as a model-based approach.</p><p id="db59" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">Another option — especially if you’re the type of person who’s not big on planning — would simply be to keep track of the different locations you’d visited (intersections, parks, and squares for instance) and the actions you took (which way you turned), but ignore the details of the routes themselves. In this case, whenever you found yourself in a location you’d already visited, you could favor the directional choice that led to a good outcome (avoiding the dangerous neighborhood and arriving at your destination more efficiently) over the directions that led to a negative outcome. You wouldn’t specifically know the next location you’d arrive at with each decision, but you would at least have learned a simple procedure for what action to take given a specific location. This is essentially the approach that model-free RL takes.</p><p id="66fd" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">As it relates to specific RL terms and concepts, we can say that you, the urban navigator, are the <strong class="hw jr"><em class="ij">agent</em></strong>; that the different locations at which you need to make a directional decision are the <strong class="hw jr"><em class="ij">states</em></strong>; and that the direction you choose to take from these states are the <strong class="hw jr"><em class="ij">actions</em></strong>. The <strong class="hw jr"><em class="ij">rewards</em></strong> (the feedback based on the agent’s actions) would most likely be positive anytime an action both got you closer to your destination and avoided the dangerous neighborhood, zero if you avoided the neighborhood but failed to get closer to your destination, and negative anytime you failed to avoid the neighborhood. The <strong class="hw jr"><em class="ij">policy</em></strong> is whatever strategy you use to determine what action/direction to take based on your current state/location. Finally, the <strong class="hw jr"><em class="ij">value</em></strong> is the expected long-term return (the sum of all your current and future rewards) based on your current state and policy.</p><p id="1f5e" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">In general, the core function of RL algorithms is to determine a policy that maximizes this long-term return, though there are a variety of <a href="https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287" class="cg dj ik il im in" target="_blank" rel="noopener">different methods and algorithms</a> to accomplish this. And again, the major difference between model-based and model-free RL is simply that the former incorporates a model of the agent’s environment, specifically one that influences how the agent’s overall policy is determined.</p><figure class="ip iq ir is it iu er es paragraph-image"><div class="iv iw cd ix ai"><div class="er es kl"><div class="jc r cd jd"><div class="km jf r"><div class="cc iy s t u iz ai bv ja jb"><img class="s t u iz ai jg jh an rg" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_Cavu8KUpkCznhU11SFnb4Q.png" width="1108" height="662" role="presentation"></div><img class="pa rc s t u iz ai jj" width="1108" height="662" srcset="https://miro.medium.com/max/552/1*Cavu8KUpkCznhU11SFnb4Q.png 276w, https://miro.medium.com/max/1104/1*Cavu8KUpkCznhU11SFnb4Q.png 552w, https://miro.medium.com/max/1280/1*Cavu8KUpkCznhU11SFnb4Q.png 640w, https://miro.medium.com/max/1400/1*Cavu8KUpkCznhU11SFnb4Q.png 700w" sizes="700px" role="presentation" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_Cavu8KUpkCznhU11SFnb4Q(1).png"><noscript><img class="s t u iz ai" src="https://miro.medium.com/max/2216/1*Cavu8KUpkCznhU11SFnb4Q.png" width="1108" height="662" srcSet="https://miro.medium.com/max/552/1*Cavu8KUpkCznhU11SFnb4Q.png 276w, https://miro.medium.com/max/1104/1*Cavu8KUpkCznhU11SFnb4Q.png 552w, https://miro.medium.com/max/1280/1*Cavu8KUpkCznhU11SFnb4Q.png 640w, https://miro.medium.com/max/1400/1*Cavu8KUpkCznhU11SFnb4Q.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div></figure><h1 id="2556" class="js jt ct bj bi ju fh jv fj jw jx jy jz ka kb kc kd" data-selectable-paragraph=""><strong class="ax">A Modest Comparison</strong></h1><p id="5b89" class="hu ig ct bj hw b fy ke ih ga kf ii hz kg gl ib kh gm id ki gn if ey" data-selectable-paragraph="">So what are the pros and cons of the model-based vs. the model-free approach? Model-based RL has a lot going for it. For one thing, it tends to have higher sample efficiency than model-free RL, meaning it requires less data to learn a policy. In other words, by leveraging the information it’s learned about its environment, model-based RL can plan rather than just react, even simulating sequences of actions without having to directly perform them in the actual environment.</p><p id="1163" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">A related benefit is that by virtue of the modeling process, model-based RL has the potential to be transferable to other goals and tasks. While learning a single policy is good for one task, if you can predict the dynamics of the environment, you can generalize those insights to multiple tasks. Finally, having a model means you can determine some degree of model uncertainty, so that you can gauge how confident you should be about the resulting decision process.</p><p id="8d12" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">Moving to the cons of model-based RL (or the pros of model-free RL), one of the biggest ones is simply that by having to learn a policy (the overall strategy to maximize the reward) as well as a model, you’re compounding the degree of potential error. In other words, there are two different sources of approximation error in model-based RL, whereas in model-free RL there’s only one. For similar reasons, model-based approaches tend to be far more computationally demanding than model-free ones, which by definition simplify the learning process.</p><p id="8d6f" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">It’s worth noting that this doesn’t necessarily need to be a binary decision. Some of the most effective <a href="https://arxiv.org/abs/1803.00101" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">recent approaches</a> have <a href="https://arxiv.org/abs/1709.03153" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">combined model-based and model-free strategies</a>. Perhaps this isn’t so surprising given the evidence that, as one <a href="https://www.princeton.edu/~yael/Publications/DayanNiv2008.pdf" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">paper</a> states, “the [human] brain employs both model-free and model-based decision-making strategies in parallel, with each dominating in different circumstances.”</p><h1 id="cc72" class="js jt ct bj bi ju fh jv fj jw jx jy jz ka kb kc kd" data-selectable-paragraph=""><strong class="ax">Recent Research and Frameworks</strong></h1><p id="062a" class="hu ig ct bj hw b fy ke ih ga kf ii hz kg gl ib kh gm id ki gn if ey" data-selectable-paragraph="">A few years ago, OpenAI released an open source RL toolkit — <a href="https://gym.openai.com/" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">OpenAI Gym</a> — that provides a variety of flexible environments for algorithm experimentation and development. A team at Google has now followed suit, releasing its own <a href="https://ai.googleblog.com/2018/08/introducing-new-framework-for-flexible.html" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">Tensorflow-based framework</a> this past month. Beyond just aiding experimentation, the Google team has also stated its explicit goal to help make RL research more reproducible (and, by extension, more accountable to the larger community). Rather than providing an environment, the Tensorflow framework instead offers a<a href="https://github.com/google/dopamine" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">codebase</a> of agents (four in all) as well as their training data, allowing users — even those with limited RL experience — a convenient entry point into experimental research.</p><p id="cd3c" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">Speaking of research, a <a href="https://arxiv.org/abs/1807.03858" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">number</a> of <a href="https://arxiv.org/abs/1808.09105" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">recent</a> <a href="https://arxiv.org/abs/1807.04723" class="cg dj ik il im in" target="_blank" rel="noopener nofollow">papers</a> have demonstrated the practical and theoretical possibilities of model-based RL. One of the takeaways from these papers is just how broad the current applications of RL are. They include everything from robotics to natural language processing to a seemingly endless range of simulated environments.</p><p id="20f6" class="hu ig ct bj hw b fy hx ih ga hy ii hz ia gl ib ic gm id ie gn if ey" data-selectable-paragraph="">This broad applicability certainly isn’t limited solely to model-based approaches. Still, on a more philosophical level, what makes model-based RL so compelling is partly the fact that it more faithfully mirrors the procedures we use to learn. We take it for granted, after all, that knowing more about our environment and its likely responses to our actions is useful for making good decisions. In a sense, model-based RL has simply figured out a way to mathematically formalize this basic human insight.</p><h1 id="f1d8" class="js jt ct bj bi ju fh jv fj jw jx jy jz ka kb kc kd" data-selectable-paragraph=""><strong class="ax">What This Means For You</strong></h1><p id="6404" class="hu ig ct bj hw b fy ke ih ga kf ii hz kg gl ib kh gm id ki gn if ey" data-selectable-paragraph="">Model-based RL isn’t quite ready for primetime production contexts now. Still, it’s already become integral for developing algorithms that can handle complex sequences of events in both real and simulated environments. This is one of those areas of machine learning that’s worth keeping track of in the coming years: when model-based RL finally breaks into commercial settings, it’s going to make some serious waves.</p></div></div></section></div></article><div class="pa ex kn ko ai kv kt kw" data-test-id="post-sidebar"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="kx n ky"><div class="rh"><div class="kz la r"><a href="https://medium.com/the-official-integrate-ai-blog?source=post_sidebar--------------------------post_sidebar-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener"><h2 class="bi ju lb bk ct">the integrate.ai blog</h2></a><div class="lc ld r"><h4 class="bi eh cb bk bv le bu gz lf hb bn">TO based startup, building a future in which AI enriches…</h4></div><div class="bx" aria-hidden="true"><button class="cs cu ar as hf bb bc hg ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div><div class="lg lh li n"><div class="n o"><div class="r cd lj lk ll lm ln"><div class=""><button class="ay lo lp lq lr ls lt lu q lv lw"><svg width="29" height="29"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r lx ly lz ma mb mc md"><div class="me"><h4 class="bi eh cb bk bn"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl">267 </button></h4></div></div></div></div><div class="lh r"></div><div><div class="hs"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="2" aria-labelledby="2"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div><div class="pa rh kn ko kp kq kr ks kt ku"></div><div><div class="mf iu n ky p"><div class="n p"><div class="z ab ac ae af fd ah ai"><div class="n mg"></div><div class="n o mg"></div><div class="mh r"><ul class="ay az"><li class="bx dw hr mi"><a href="https://medium.com/tag/machine-learning" class="mj mk dj bn r ml mm a b ei">Machine Learning</a></li><li class="bx dw hr mi"><a href="https://medium.com/tag/blog" class="mj mk dj bn r ml mm a b ei">Blog</a></li><li class="bx dw hr mi"><a href="https://medium.com/tag/reinforcement-learning" class="mj mk dj bn r ml mm a b ei">Reinforcement Learning</a></li></ul></div><div class="mn n gp y"><div class="n mo"><div class="mp r"><div class="n o"><div class="r cd mq mr ms mt mu"><div class=""><div class="c mv dm n o mw cd mx my mz na nb nc nd ne nf ng nh ni nj nk"><button class="ay lo lp lq lr ls nl lu o jj dm n p nm u iz s t ai q lv lw nn"><svg width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></button></div></div></div><div class="r lx ly lz ma mb mc md"><div class="cd no me"><h4 class="bi eh cb bk ct"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl">267 claps</button></h4></div></div></div></div><div class="r np nq nr ns nt"></div></div><div class="n o"><div class="hq r bh"><a href="https://medium.com/p/93d4e34e5698/share/twitter?source=post_actions_footer---------------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></a></div><div class="hq r bh"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="q"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="hq r bh"><a href="https://medium.com/p/93d4e34e5698/share/facebook?source=post_actions_footer---------------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></a></div><div class="nu r bh"><div><div class="hs"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="3" aria-labelledby="3"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div><div class="bx" aria-hidden="true"><div class="bx" aria-hidden="true"><div class="r bh"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="-480.5 272.5 21 21" class="q"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></button></div></div></div></div></div><div class="nv dp nw mh r nx y"><div class="r g"><div class="ny nz r cd"><span class="r oa al ob"><div class="r s oc od"><a rel="noopener" href="https://medium.com/@integrate.ai?source=follow_footer--------------------------follow_footer-"><img alt="integrate.ai" class="r dm ec oe" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_j2sYTw20WODHLS4w0rD8dQ(1).png" width="80" height="80"></a></div><span class="r"><div class="of r og"><p class="bi eh ei bk bn ej oh">Written by</p></div><div class="of oi n og"><div class="ai n o gp"><h2 class="bi ju oj ok ct"><a class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener" href="https://medium.com/@integrate.ai?source=follow_footer--------------------------follow_footer-">integrate.ai</a></h2><div class="r g"><button class="cs cu ar as hf bb bc hg ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div></div></span></span><div class="of ol r og aq"><div class="om r"><h4 class="bi eh lb on bn">TO based startup, building a future in which AI enriches people’s lives while creating better, more valuable businesses. www.integrate.ai</h4></div><div class="ap oo aq"><button class="cs cu ar as hf bb bc hg ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div></div><div class="nv r"></div><div class="ny nz r cd"><span class="r oa al ob"><div class="r s oc od"><a href="https://medium.com/the-official-integrate-ai-blog?source=follow_footer--------------------------follow_footer-" rel="noopener"><img alt="the integrate.ai blog" class="df oe ec" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_vg0fajz0k-RurDLtkV_EXg.jpeg" width="80" height="80"></a></div><span class="r"><div class="of oi n og"><div class="ai n o gp"><h2 class="bi ju oj ok ct"><a href="https://medium.com/the-official-integrate-ai-blog?source=follow_footer--------------------------follow_footer-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener">the integrate.ai blog</a></h2><div class="r g"><div class="bx" aria-hidden="true"><button class="cs cu ar as hf bb bc hg ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div></div></div></span></span><div class="of op r og aq"><div class="om r"><h4 class="bi eh lb on bn">TO based startup, building a future in which AI enriches people’s lives while creating better, more valuable businesses.</h4></div><div class="ap oo aq"><div class="bx" aria-hidden="true"><button class="cs cu ar as hf bb bc hg ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div></div></div></div><div class="ap aq"><div class="oq r"><div class="n mo"><div class="or r"><a rel="noopener" href="https://medium.com/@integrate.ai?source=follow_footer--------------------------follow_footer-"><img alt="integrate.ai" class="r dm os ot" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_j2sYTw20WODHLS4w0rD8dQ(2).png" width="40" height="40"></a></div><div class="gv r"><p class="bi eh ou ov bn ej oh">Written by</p><div class="n mo"><h2 class="bi ju lb bk ct"><a class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener" href="https://medium.com/@integrate.ai?source=follow_footer--------------------------follow_footer-">integrate.ai</a></h2><div class="gv r"><button class="he cu ar as hf bb bc hg ba df bi b bj hh ei bm dg dh di bx dj bd">Follow</button></div></div><div class="ow r"><h4 class="bi eh cb bk bn">TO based startup, building a future in which AI enriches people’s lives while creating better, more valuable businesses. www.integrate.ai</h4></div></div></div><div class="oq r"><div class="n mo"><a href="https://medium.com/the-official-integrate-ai-blog?source=follow_footer--------------------------follow_footer-" rel="noopener"><img alt="the integrate.ai blog" class="df ot os" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_vg0fajz0k-RurDLtkV_EXg(1).jpeg" width="40" height="40"></a><div class="gv r"><div class="n mo"><h2 class="bi ju lb bk ct"><a href="https://medium.com/the-official-integrate-ai-blog?source=follow_footer--------------------------follow_footer-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener">the integrate.ai blog</a></h2><div class="gv r"><div class="bx" aria-hidden="true"><button class="he cu ar as hf bb bc hg ba df bi b bj hh ei bm dg dh di bx dj bd">Follow</button></div></div></div><div class="ow r"><h4 class="bi eh cb bk bn">TO based startup, building a future in which AI enriches people’s lives while creating better, more valuable businesses.</h4></div></div></div></div></div></div></div><div class="ox dp r nx oy y"><a href="https://medium.com/p/93d4e34e5698/responses/show?source=follow_footer--------------------------follow_footer-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener"><span class="oz pa lr"><div class="pb pc df r jl g"><span class="ar">Write the first response</span></div></span></a></div></div></div><div class="pd r pe y"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="sr r ss"><div class="qp la ny r"><h2 class="bi ju st su ct">More From Medium</h2></div><div class="dz n mo mg sv sw sx sy sz ta tb tc td te tf tg th ti tj"><div class="tk tl tm tn to tp tq tr ts tt tu tv tw tx ty tz ua ub uc ud ue"><div class="ai iz"><div class="r uf"><div class="ug uh sv sw sx ui uj sy sz ta uk ul tb tc td um un te tf tg uo up th ti tj n mg"><div class="tk tl tm tn to tp uq ur ts tt us ut tw tx uu uv ua ub uw ux ue"><div class="uy r uz f"><h4 class="bi eh cb bk bn">More from the integrate.ai blog</h4></div><div class="br r va ss"><a class="cg ch at au av aw ax ay az ba ci cj bd be ck cl r" rel="noopener" href="https://medium.com/the-official-integrate-ai-blog/what-you-need-to-know-about-natural-language-processing-2c8240e6c38e?source=post_recirc---------0------------------"></a></div></div><div class="tk tl tm tn to tp uq ur ts tt us ut tw tx uu uv ua ub uw ux ue"><div class="br r"><div class="vb ap h vc"><h4 class="bi eh cb bk bn">More from the integrate.ai blog</h4></div><a rel="noopener" href="https://medium.com/the-official-integrate-ai-blog/what-you-need-to-know-about-natural-language-processing-2c8240e6c38e?source=post_recirc---------0------------------"><h3 class="ct q fg vd bj ve vf vg">What You Need to Know About Natural Language Processing</h3></a></div><div class="n o gp"><div class="cm r dv"><div class="o n"><div></div><div class="ai r"><div class="n"><div style="flex: 1 1 0%;"><span class="bi b bj bk bl bm r ct q"><div class="el n o gx"><span class="bi eh cb bk bv gy bu gz ha hb ct"><a class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener" href="https://medium.com/@integrate.ai?source=post_recirc---------0------------------">integrate.ai</a><span> in <a href="https://medium.com/the-official-integrate-ai-blog?source=post_recirc---------0------------------" class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener">the integrate.ai blog</a></span></span></div></span></div></div><span class="bi b bj bk bl bm r bn bo"><span class="bi eh cb bk bv gy bu gz ha hb bn"><div><a class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener" href="https://medium.com/the-official-integrate-ai-blog/what-you-need-to-know-about-natural-language-processing-2c8240e6c38e?source=post_recirc---------0------------------">Oct 29, 2018</a> · 8 min read</div></span></span></div></div></div><div class="n o"><div class="n o"><div class="r cd lj lk ll lm ln"><div class=""><button class="ay lo lp lq lr ls lt qy q lv lw"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r lx ly lz ma mb mc md"><div class="me"><h4 class="bi eh cb bk bn">246</h4></div></div></div><div class="vh gv cm ed sf r"></div><div class="hs"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="21" aria-labelledby="21"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div><div class="tk tl tm tn to tp tq tr ts tt tu tv tw tx ty tz ua ub uc ud ue"><div class="ai iz"><div class="r uf"><div class="ug uh sv sw sx ui uj sy sz ta uk ul tb tc td um un te tf tg uo up th ti tj n mg"><div class="tk tl tm tn to tp uq ur ts tt us ut tw tx uu uv ua ub uw ux ue"><div class="uy r uz f"><h4 class="bi eh cb bk bn">Related reads</h4></div><div class="br r va ss"><a href="https://towardsdatascience.com/ai-learning-to-land-a-rocket-reinforcement-learning-84d61f97d055?source=post_recirc---------1------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl r" rel="noopener"></a></div></div><div class="tk tl tm tn to tp uq ur ts tt us ut tw tx uu uv ua ub uw ux ue"><div class="br r"><div class="vb ap h vc"><h4 class="bi eh cb bk bn">Related reads</h4></div><a href="https://towardsdatascience.com/ai-learning-to-land-a-rocket-reinforcement-learning-84d61f97d055?source=post_recirc---------1------------------" rel="noopener"><h3 class="ct q fg vd bj ve vf vg">AI Learning to land a Rocket | Reinforcement Learning</h3></a></div><div class="n o gp"><div class="cm r dv"><div class="o n"><div></div><div class="ai r"><div class="n"><div style="flex: 1 1 0%;"><span class="bi b bj bk bl bm r ct q"><div class="el n o gx"><span class="bi eh cb bk bv gy bu gz ha hb ct"><a class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener" href="https://medium.com/@fakemonk?source=post_recirc---------1------------------">Ashish Gupta</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------1------------------" class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener">Towards Data Science</a></span></span></div></span></div></div><span class="bi b bj bk bl bm r bn bo"><span class="bi eh cb bk bv gy bu gz ha hb bn"><div><a href="https://towardsdatascience.com/ai-learning-to-land-a-rocket-reinforcement-learning-84d61f97d055?source=post_recirc---------1------------------" class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener">Aug 28, 2019</a> · 8 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="n o"><div class="n o"><div class="r cd lj lk ll lm ln"><div class=""><button class="ay lo lp lq lr ls lt qy q lv lw"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r lx ly lz ma mb mc md"><div class="me"><h4 class="bi eh cb bk bn">169</h4></div></div></div><div class="vh gv cm ed sf r"></div><div class="hs"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="22" aria-labelledby="22"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div><div class="tk tl tm tn to tp tq tr ts tt tu tv tw tx ty tz ua ub uc ud ue"><div class="ai iz"><div class="r uf"><div class="ug uh sv sw sx ui uj sy sz ta uk ul tb tc td um un te tf tg uo up th ti tj n mg"><div class="tk tl tm tn to tp uq ur ts tt us ut tw tx uu uv ua ub uw ux ue"><div class="uy r uz f"><h4 class="bi eh cb bk bn">Related reads</h4></div><div class="br r va ss"><a href="https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-part-ii-trpo-ppo-87f2c5919bb9?source=post_recirc---------2------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl r" rel="noopener"></a></div></div><div class="tk tl tm tn to tp uq ur ts tt us ut tw tx uu uv ua ub uw ux ue"><div class="br r"><div class="vb ap h vc"><h4 class="bi eh cb bk bn">Related reads</h4></div><a href="https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-part-ii-trpo-ppo-87f2c5919bb9?source=post_recirc---------2------------------" rel="noopener"><h3 class="ct q fg vd bj ve vf vg">Introduction to Various Reinforcement Learning Algorithms. Part II (TRPO, PPO)</h3></a></div><div class="n o gp"><div class="cm r dv"><div class="o n"><div></div><div class="ai r"><div class="n"><div style="flex: 1 1 0%;"><span class="bi b bj bk bl bm r ct q"><div class="el n o gx"><span class="bi eh cb bk bv gy bu gz ha hb ct"><a class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener" href="https://medium.com/@huangkh19951228?source=post_recirc---------2------------------">Kung-Hsiang, Huang (Steeve)</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------2------------------" class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener">Towards Data Science</a></span></span></div></span></div></div><span class="bi b bj bk bl bm r bn bo"><span class="bi eh cb bk bv gy bu gz ha hb bn"><div><a href="https://towardsdatascience.com/introduction-to-various-reinforcement-learning-algorithms-part-ii-trpo-ppo-87f2c5919bb9?source=post_recirc---------2------------------" class="cg ch at au av aw ax ay az ba hc bd be ck cl" rel="noopener">Jan 17, 2018</a> · 10 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="n o"><div class="n o"><div class="r cd lj lk ll lm ln"><div class=""><button class="ay lo lp lq lr ls lt qy q lv lw"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r lx ly lz ma mb mc md"><div class="me"><h4 class="bi eh cb bk bn">1.8K</h4></div></div></div><div class="vh gv cm ed sf r"></div><div class="hs"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="23" aria-labelledby="23"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="pf r pg ph"><section class="er es ai di r pi pj pk pl pm pn po pp pq pr ps pt pu pv pw"><div class="px py ny n gp g"><div class="pz n gp"><div class="qa r qb"><div class="qc r"><a class="cg ch at au av aw ax ay az ba qd qe bd be qf qg" rel="noopener" href="https://medium.com/about?autoplay=1&amp;source=post_page-----93d4e34e5698----------------------"><h4 class="qh qi qj bi ju bj on qk ql r">Discover <!-- -->Medium</h4></a></div><span class="bi b bj bk bl bm r qm qn">Welcome to a place where words matter. On <!-- -->Medium<!-- -->, smart voices and original ideas take center stage - with no ads in sight.<!-- --> <a class="cg ch at au av aw ax ay az ba bd be qf qg qo" rel="noopener" href="https://medium.com/about?autoplay=1&amp;source=post_page-----93d4e34e5698----------------------">Watch</a></span></div><div class="qa r qb"><div class="qp r"><a href="https://medium.com/topics?source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba qd qe bd be qf qg" rel="noopener"><h4 class="qh qi qj bi ju bj on qk ql r">Make <!-- -->Medium<!-- --> yours</h4></a></div><span class="bi b bj bk bl bm r qm qn">Follow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox.<!-- --> <a href="https://medium.com/topics?source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba bd be qf qg qo" rel="noopener">Explore</a></span></div><div class="qa r qb"><div class="qc r"><a class="cg ch at au av aw ax ay az ba qd qe bd be qf qg" rel="noopener" href="https://medium.com/membership?source=post_page-----93d4e34e5698----------------------"><h4 class="qh qi qj bi ju bj on qk ql r">Become a member</h4></a></div><span class="bi b bj bk bl bm r qm qn">Get unlimited access to the best stories on <!-- -->Medium<!-- --> — and support writers while you’re at it. Just $5/month.<!-- --> <a class="cg ch at au av aw ax ay az ba bd be qf qg qo" rel="noopener" href="https://medium.com/membership?source=post_page-----93d4e34e5698----------------------">Upgrade</a></span></div></div></div><div class="n ky"><div class="n o gp"><a href="https://medium.com/?source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba qd qe bd be qf qg" rel="noopener"><svg height="22" width="112" viewBox="0 0 111.5 22" class="qi"><path d="M56.3 19.5c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5V19c-.7 1.8-2.4 3-4.3 3-3.3 0-5.8-2.6-5.8-7.5 0-4.5 2.6-7.6 6.3-7.6 1.6-.1 3.1.8 3.8 2.4V3.2c0-.3-.1-.6-.3-.7l-1.4-1.4V1l6.5-.8v19.3zm-4.8-.8V9.5c-.5-.6-1.2-.9-1.9-.9-1.6 0-3.1 1.4-3.1 5.7 0 4 1.3 5.4 3 5.4.8.1 1.6-.3 2-1zm9.1 3.1V9.4c0-.3-.1-.6-.3-.7l-1.4-1.5v-.1h6.5v12.5c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5zm-.2-19.2C60.4 1.2 61.5 0 63 0c1.4 0 2.6 1.2 2.6 2.6S64.4 5.3 63 5.3a2.6 2.6 0 0 1-2.6-2.7zm22.5 16.9c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5v-3.2c-.6 2-2.4 3.4-4.5 3.4-2.9 0-4.4-2.1-4.4-6.2 0-1.9 0-4.1.1-6.5 0-.3-.1-.5-.3-.7L67.7 7v.1H74v8c0 2.6.4 4.4 2 4.4.9-.1 1.7-.6 2.1-1.3V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v12.4zm22 2.3c0-.5.1-6.5.1-7.9 0-2.6-.4-4.5-2.2-4.5-.9 0-1.8.5-2.3 1.3.2.8.3 1.7.3 2.5 0 1.8-.1 4.2-.1 6.5 0 .3.1.5.3.7l1.5 1.4v.1H96c0-.4.1-6.5.1-7.9 0-2.7-.4-4.5-2.2-4.5-.9 0-1.7.5-2.2 1.3v9c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v3.1a4.6 4.6 0 0 1 4.6-3.4c2.2 0 3.6 1.2 4.2 3.5.7-2.1 2.7-3.6 4.9-3.5 2.9 0 4.5 2.2 4.5 6.2 0 1.9-.1 4.2-.1 6.5-.1.3.1.6.3.7l1.4 1.4v.1h-6.6zm-81.4-2l1.9 1.9v.1h-9.8v-.1l2-1.9c.2-.2.3-.4.3-.7V7.3c0-.5 0-1.2.1-1.8L11.4 22h-.1L4.5 6.8c-.1-.4-.2-.4-.3-.6v10c-.1.7 0 1.3.3 1.9l2.7 3.6v.1H0v-.1L2.7 18c.3-.6.4-1.3.3-1.9v-11c0-.5-.1-1.1-.5-1.5L.7 1.1V1h7l5.8 12.9L18.6 1h6.8v.1l-1.9 2.2c-.2.2-.3.5-.3.7v15.2c0 .2.1.5.3.6zm7.6-5.9c0 3.8 1.9 5.3 4.2 5.3 1.9.1 3.6-1 4.4-2.7h.1c-.8 3.7-3.1 5.5-6.5 5.5-3.7 0-7.2-2.2-7.2-7.4 0-5.5 3.5-7.6 7.3-7.6 3.1 0 6.4 1.5 6.4 6.2v.8h-8.7zm0-.8h4.3v-.8c0-3.9-.8-4.9-2-4.9-1.4.1-2.3 1.6-2.3 5.7z"></path></svg></a><span class="bi b bj bk bl bm r qm qn"><div class="ow qq n gp qr al"><h4 class="bi eh lb on qh"><a class="cg ch at au av aw ax ay az ba hc bd be qf qg" rel="noopener" href="https://medium.com/about?autoplay=1&amp;source=post_page-----93d4e34e5698----------------------">About</a></h4><h4 class="bi eh lb on qh"><a href="https://help.medium.com/?source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba hc bd be qf qg" rel="noopener">Help</a></h4><h4 class="bi eh lb on qh"><a class="cg ch at au av aw ax ay az ba hc bd be qf qg" rel="noopener" href="https://medium.com/policy/9db0094a1e0f?source=post_page-----93d4e34e5698----------------------">Legal</a></h4></div></span></div><div class="ap qs qt al"><h4 class="bi eh lb on qm">Get the Medium app</h4></div><div class="ap qs qu al qv"><div class="cq r"><a href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba qd qe bd be qf qg" rel="noopener nofollow"><img alt="A button that says &#39;Download on the App Store&#39;, and if clicked it will lead you to the iOS App store" class="" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_M2FVPPidy2x386MRAE-EeA.png" width="135" height="41"></a></div><div class="r"><a href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----93d4e34e5698----------------------" class="cg ch at au av aw ax ay az ba qd qe bd be qf qg" rel="noopener nofollow"><img alt="A button that says &#39;Get it on, Google Play&#39;, and if clicked it will lead you to the Google Play store" class="" src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/1_HyH8oIcJvXp7xzu5oF6dTg.png" width="135" height="41"></a></div></div></div></section></div></div></div><script>window.__BUILD_ID__ = "master-20200522-161040-9687e55f61"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"config":{"nodeEnv":"production","version":"master-20200522-161040-9687e55f61","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"collector-medium.lightstep.com","token":"ce5be895bef60919541332990ac9fef2","appVersion":"master-20200522-161040-9687e55f61"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","context":{"deployment":{"target":"production","tag":"master-20200522-161040-9687e55f61","commit":"9687e55f6131eab13ff704124850880e8f57e2a6"}},"datacenter":"us"},"sentry":{"dsn":"https:\u002F\u002F589e367c28ca47b195ce200d1507d18b@sentry.io\u002F1423575","environment":"production"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e","8ccfed20cbb2","ae2a65f35510","3f6ecf56618","7b6769f2748b","fc8964313712","ef8e90590e66","191186aaafa0","d944778ce714","bdc4052bbdba","88d9857e584e"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"internalLinksPostIds":["0","1","2","3","4","5","6","7"],"webpMiroImageIds":["1*y7gegIZOYlsnhWFJwIyDJw","1*ByGRQD1zlYXGS4YBYAoLVA","1*orNowUCqCER-BwaAXOZx0A","1*itOsotYFripvvRKY1itrVQ","1*b_LB1ifqWQ2x3JG_m3MJsg","1*AD7jcqVRun0Hhwmg0-Vqfg","1*0kJoJveqoxkYXEmdM2FZ3A","1*pTq8R2lALVUytg_k4y5CpQ","1*1_tSnwIHb_oPsU9vucJijQ","1*EBN0PWXjvaF2gRdk9fCvzA","1*Uxc2_wlnoVQNMQUhQaLVZg","1*ABOw4ARUQ90kwKfXqeVdXA","1*Ok2A1h7LmAtYjWVG9c8IMA","1*Kw1AUMFyy3AGJ1BbTdeyWg","1*2RZldaiJQXadc5zjscYncg","1*hPIJUpxe2QMvOMNcTlnOlQ","1*MZyvxFpPUvfBUfoNvFhRzg","1*2ROzqt2hXcYs6BuKjG2_nQ","1*NO9eMccT-vPrY8nylJ4PVw","2*6cf2Ep3P-r1vCrc-6Bc-vA","1*hVxgUA6kP-PgL5TJjuyePg","1*VGtACZSU6AxT3ugiNr-WGg","0*8dBf1Vy9mkDdcuwQ","1*5ciI2lDFX8sJanIJa6ppnA","1*Hqtfw2Juvf6Zb9uGimLLMg","1*suPSqLiNrJPCUbtdUwLnGw","1*dIANAeHtMxPlVO9awEN0Jw","1*N2KcM3GCLymsKxnSBXyG_g","1*fgNVzsUlPl9tA8ladAT-KA","1*h-La0GVOrPo6SrFpNWQLtw","1*3IPJZVYg-95RkV8H4DRjvA","1*DgnF3PmTVG14Oz_-8BWX_g","1*x_SKDZtUCcWMH9FB092srw","1*oQ4U4pCo7OUPMXXphwqzTg","1*fjC3jxxcmOwXLwqxraNHfw","1*DXy0NEVftDaLKDVG8dS3YQ","1*KbxEajPgdT9GhcWWGG8JmQ","1*e6oTrX0jQU0lPM_0Tt-oYw","1*oQ4U4pCo7OUPMXXphwqzTg","1*5I_5X9Of8dwLfLEwJWd9jA","1*wYUZRoGUFOj1kdT7R8S0TQ","1*dzn6a448FO7kqbXk2K1qiA","1*YQDEXca6FZq-9L5WXBH-3A","1*YlpXJYsNOORiPqY0Rx6zIQ","1*NM3ybm1NGbyvF_IGL5DPYQ","1*DJ36tR2MtLrCRA1BO62L8Q","1*wV6yqGmy-aGNGWt1paWy5g","0*iWmcqANWK8Ayo6NP","0*nB8YhFfPe8q0sJcJ","0*GN_xV2uMHSeGuotv","0*oT1BmxuFNEyN0XC4","0*Aow5I0AXoM8HG4RA","0*geqIA7abXJGEobLr"],"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*3sela1OADrJr7dJk_CXaEQ.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"performanceTags":[],"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":["pandemic","epidemic","coronavirus","covid19","co-vid-19","containment","self-care","flatten-the-curve","public-health","virus","public-health-crisis","quarantine","self-quarantine","zika","corona","disease-prevention","wuhan","chinavirus","outbreak","influenza","socialdistancing","social-distance","flu","vaccines","healthcare","medicine","conspiracy-theories","conspiracy","virality","epidemia","pandemia","salud","corona-e-virus","coronavirus-covid19","covid-19","covid-19-symptoms","covid-19-crisis","covid-19-testing","covid-19-treatment","coronavirus-update","coronavirus-diaries"],"COVID_APPLICABLE_TOPIC_NAMES":["coronavirus"],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":["coronavirus","health"],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4"},"debug":{"requestId":"0f6487c0-59c6-48ee-92aa-a6038e37faac","edge":"","originalSpanCarrier":{"ot-tracer-spanid":"6febfb8522eef63c","ot-tracer-traceid":"6249195c4fac14b2","ot-tracer-sampled":"true"}},"session":{"user":{"id":"85164a79d2b9"},"xsrf":"IevGUv1FCW2S","isSpoofed":false},"stats":{"itemCount":0,"sending":false,"timeout":null,"backup":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmedium.com\u002Fthe-official-integrate-ai-blog\u002Funderstanding-reinforcement-learning-93d4e34e5698","host":"medium.com","hostname":"medium.com","referrer":"https:\u002F\u002Fwww.google.com\u002F","susiModal":{"step":null,"operation":"register"},"postRead":false},"client":{"isBot":false,"isCustomDomain":false,"isEu":false,"isNativeMedium":false,"isSafariMobile":false,"inAppBrowserName":"","supportsWebp":true},"multiVote":{"clapsPerPost":{}},"tracing":{}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY.variantFlags.0":{"name":"add_friction_to_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.0.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.0.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.1":{"name":"allow_access","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.1.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.1.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.2":{"name":"allow_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.2.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.2.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.3":{"name":"allow_test_auth","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.3.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.3.valueType":{"__typename":"VariantFlagString","value":"disallow"},"ROOT_QUERY.variantFlags.4":{"name":"assign_default_topic_to_posts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.4.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.4.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.5":{"name":"available_annual_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.5.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.5.valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"},"ROOT_QUERY.variantFlags.6":{"name":"available_monthly_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.6.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.6.valueType":{"__typename":"VariantFlagString","value":"60e220181034"},"ROOT_QUERY.variantFlags.7":{"name":"bane_add_user","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.7.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.7.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.8":{"name":"branch_seo_metadata","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.8.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.8.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.9":{"name":"browsable_stream_config_bucket","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.9.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.9.valueType":{"__typename":"VariantFlagString","value":"curated-topics"},"ROOT_QUERY.variantFlags.10":{"name":"coronavirus_topic_recirc","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.10.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.10.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.11":{"name":"covid_19_cdc_banner","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.11.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.11.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.12":{"name":"disable_android_subscription_activity_carousel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.12.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.12.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.13":{"name":"disable_gosocial_followers_that_you_follow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.13.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.13.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.14":{"name":"disable_ios_resume_reading_toast","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.14.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.14.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.15":{"name":"disable_ios_subscription_activity_carousel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.15.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.15.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.16":{"name":"disable_mobile_featured_chunk","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.16.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.16.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.17":{"name":"disable_post_recommended_from_friends_provider","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.17.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.17.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.18":{"name":"enable_android_local_currency","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.18.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.18.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.19":{"name":"enable_annual_renewal_reminder_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.19.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.19.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.20":{"name":"enable_app_flirty_thirty","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.20.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.20.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.21":{"name":"enable_apple_sign_in","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.21.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.21.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.22":{"name":"enable_automated_mission_control_triggers","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.22.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.22.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.23":{"name":"enable_braintree_integration","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.23.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.23.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.24":{"name":"enable_braintree_webhook","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.24.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.24.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.25":{"name":"enable_branch_io","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.25.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.25.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.26":{"name":"enable_branding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.26.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.26.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.27":{"name":"enable_branding_fonts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.27.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.27.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.28":{"name":"enable_cleansweep_cachev2_reads","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.28.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.28.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.29":{"name":"enable_cleansweep_double_writes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.29.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.29.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.30":{"name":"enable_confirm_sign_in","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.30.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.30.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.31":{"name":"enable_cta_meter","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.31.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.31.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.32":{"name":"enable_curation_priority_queue_experiment","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.32.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.32.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.33":{"name":"enable_dedicated_series_tab_api_ios","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.33.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.33.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.34":{"name":"enable_different_grid","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.34.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.34.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.35":{"name":"enable_digest_feature_logging","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.35.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.35.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.36":{"name":"enable_digest_tagline","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.36.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.36.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.37":{"name":"enable_disregard_trunc_state_for_footer","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.37.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.37.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.38":{"name":"enable_edit_alt_text","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.38.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.38.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.39":{"name":"enable_email_sign_in_captcha","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.39.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.39.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.40":{"name":"enable_embedding_based_diversification","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.40.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.40.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.41":{"name":"enable_end_of_post_cleanup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.41.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.41.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.42":{"name":"enable_ev_mission_email_v3","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.42.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.42.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.43":{"name":"enable_ev_mission_trial_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.43.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.43.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.44":{"name":"enable_expanded_feature_chunk_pool","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.44.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.44.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.45":{"name":"enable_filter_by_resend_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.45.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.45.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.46":{"name":"enable_filter_expire_processor","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.46.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.46.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.47":{"name":"enable_first_name_on_paywall","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.47.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.47.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.48":{"name":"enable_footer_app_buttons","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.48.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.48.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.49":{"name":"enable_free_corona_topic","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.49.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.49.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.50":{"name":"enable_global_susi_modal","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.50.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.50.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.51":{"name":"enable_google_one_tap","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.51.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.51.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.52":{"name":"enable_highlander_member_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.52.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.52.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.53":{"name":"enable_ios_post_stats","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.53.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.53.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.54":{"name":"enable_janky_spam_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.54.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.54.valueType":{"__typename":"VariantFlagString","value":"users,posts"},"ROOT_QUERY.variantFlags.55":{"name":"enable_json_logs_trained_ranker","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.55.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.55.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.56":{"name":"enable_kafka_events","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.56.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.56.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.57":{"name":"enable_kbfd_rex","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.57.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.57.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.58":{"name":"enable_kbfd_rex_app_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.58.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.58.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.59":{"name":"enable_kbfd_rex_daily_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.59.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.59.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.60":{"name":"enable_li_open_in_app","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.60.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.60.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.61":{"name":"enable_lite_about_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.61.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.61.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.62":{"name":"enable_lite_notifications","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.62.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.62.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.63":{"name":"enable_lite_post","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.63.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.63.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.64":{"name":"enable_lite_post_cd","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.64.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.64.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.65":{"name":"enable_lite_post_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.65.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.65.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.66":{"name":"enable_lite_post_highlights_view_only","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.66.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.66.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.67":{"name":"enable_lite_profile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.67.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.67.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.68":{"name":"enable_lite_pub_header_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.68.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.68.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.69":{"name":"enable_lite_server_upstream_deadlines","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.69.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.69.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.70":{"name":"enable_lite_stories","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.70.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.70.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.71":{"name":"enable_lite_topics","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.71.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.71.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.72":{"name":"enable_lite_unread_notification_count_mutation","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.72.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.72.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.73":{"name":"enable_lo_open_in_app","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.73.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.73.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.74":{"name":"enable_logged_out_history","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.74.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.74.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.75":{"name":"enable_login_code_flow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.75.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.75.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.76":{"name":"enable_marketing_emails","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.76.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.76.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.77":{"name":"enable_media_resource_try_catch","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.77.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.77.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.78":{"name":"enable_membership_remove_section_a","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.78.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.78.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.79":{"name":"enable_miro_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.79.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.79.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.80":{"name":"enable_ml_rank_modules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.80.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.80.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.81":{"name":"enable_ml_rank_rex_anno","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.81.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.81.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.82":{"name":"enable_more_on_coronavirus","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.82.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.82.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.83":{"name":"enable_mute","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.83.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.83.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.84":{"name":"enable_new_collaborative_filtering_data","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.84.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.84.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.85":{"name":"enable_new_suspended_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.85.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.85.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.86":{"name":"enable_new_three_dot_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.86.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.86.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.87":{"name":"enable_olsen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.87.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.87.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.88":{"name":"enable_open_in_app_regwall","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.88.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.88.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.89":{"name":"enable_optimizely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.89.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.89.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.90":{"name":"enable_parsely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.90.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.90.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.91":{"name":"enable_patronus_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.91.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.91.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.92":{"name":"enable_popularity_feature","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.92.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.92.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.93":{"name":"enable_post_import","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.93.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.93.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.94":{"name":"enable_post_page_nav_stickiness_removal","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.94.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.94.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.95":{"name":"enable_post_seo_settings_screen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.95.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.95.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.96":{"name":"enable_post_settings_screen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.96.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.96.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.97":{"name":"enable_primary_topic_for_mobile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.97.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.97.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.98":{"name":"enable_responses_2","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.98.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.98.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.99":{"name":"enable_rito_upstream_deadlines","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.99.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.99.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.100":{"name":"enable_rtr_channel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.100.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.100.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.101":{"name":"enable_save_to_medium","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.101.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.101.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.102":{"name":"enable_sepia_to_olsen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.102.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.102.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.103":{"name":"enable_starspace","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.103.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.103.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.104":{"name":"enable_starspace_digest_app","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.104.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.104.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.105":{"name":"enable_starspace_ranker_starspace","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.105.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.105.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.106":{"name":"enable_tick_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.106.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.106.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.107":{"name":"enable_tipalti_onboarding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.107.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.107.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.108":{"name":"enable_topic_lifecycle_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.108.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.108.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.109":{"name":"enable_tribute_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.109.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.109.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.110":{"name":"enable_trumpland_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.110.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.110.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.111":{"name":"enable_utc_fix_on_partner_program_dashboard","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.111.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.111.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.112":{"name":"exclude_curated_in_popular_topic","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.112.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.112.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.113":{"name":"featured_fc_and_ydr","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.113.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.113.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.114":{"name":"filter_low_scoring_users","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.114.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.114.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.115":{"name":"glyph_embed_commands","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.115.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.115.valueType":{"__typename":"VariantFlagString","value":"control"},"ROOT_QUERY.variantFlags.116":{"name":"glyph_font_set","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.116.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.116.valueType":{"__typename":"VariantFlagString","value":"m2"},"ROOT_QUERY.variantFlags.117":{"name":"google_sign_in_android","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.117.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.117.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.118":{"name":"is_not_medium_subscriber","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.118.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.118.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.119":{"name":"limit_post_referrers","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.119.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.119.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.120":{"name":"make_nav_sticky","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.120.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.120.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.121":{"name":"new_transition_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.121.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.121.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.122":{"name":"pub_sidebar","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.122.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.122.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.123":{"name":"rank_model","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.123.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.123.valueType":{"__typename":"VariantFlagString","value":"default"},"ROOT_QUERY.variantFlags.124":{"name":"remove_post_post_similarity","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.124.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.124.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.125":{"name":"share_post_linkedin","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.125.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.125.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.126":{"name":"sign_up_with_email_button","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.126.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.126.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.127":{"name":"signin_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.127.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.127.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"},"ROOT_QUERY.variantFlags.128":{"name":"signup_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.128.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.128.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"},"ROOT_QUERY.variantFlags.129":{"name":"skip_sign_in_recaptcha","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.129.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.129.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.130":{"name":"use_new_admin_topic_backend","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.130.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.130.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.131":{"name":"xgboost_auto_suspend","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.131.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.131.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY":{"variantFlags":[{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.0","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.1","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.2","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.3","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.4","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.5","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.6","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.7","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.8","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.9","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.10","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.11","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.12","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.13","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.14","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.15","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.16","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.17","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.18","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.19","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.20","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.21","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.22","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.23","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.24","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.25","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.26","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.27","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.28","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.29","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.30","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.31","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.32","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.33","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.34","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.35","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.36","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.37","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.38","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.39","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.40","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.41","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.42","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.43","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.44","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.45","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.46","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.47","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.48","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.49","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.50","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.51","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.52","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.53","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.54","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.55","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.56","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.57","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.58","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.59","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.60","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.61","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.62","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.63","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.64","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.65","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.66","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.67","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.68","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.69","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.70","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.71","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.72","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.73","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.74","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.75","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.76","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.77","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.78","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.79","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.80","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.81","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.82","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.83","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.84","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.85","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.86","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.87","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.88","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.89","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.90","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.91","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.92","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.93","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.94","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.95","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.96","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.97","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.98","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.99","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.100","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.101","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.102","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.103","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.104","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.105","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.106","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.107","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.108","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.109","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.110","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.111","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.112","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.113","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.114","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.115","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.116","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.117","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.118","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.119","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.120","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.121","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.122","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.123","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.124","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.125","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.126","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.127","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.128","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.129","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.130","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.131","typename":"VariantFlag"}],"viewer":{"type":"id","generated":false,"id":"User:85164a79d2b9","typename":"User"},"meterPost({\"postId\":\"93d4e34e5698\",\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"type":"id","generated":false,"id":"MeteringInfo:singleton","typename":"MeteringInfo"},"postResult({\"id\":\"93d4e34e5698\"})":{"type":"id","generated":false,"id":"Post:93d4e34e5698","typename":"Post"}},"User:85164a79d2b9":{"id":"85164a79d2b9","username":"ayushverma1321","name":"Ayushverma","imageId":"0*fSKu5zWydc5B9tfM","mediumMemberAt":0,"hasPastMemberships":false,"isPartnerProgramEnrolled":false,"email":"ayushverma1321@gmail.com","unverifiedEmail":"","createdAt":1589189777130,"isEligibleToViewNewResponses":false,"isMembershipTrialEligible":true,"isSuspended":false,"__typename":"User"},"MeteringInfo:singleton":{"__typename":"MeteringInfo","postIds":{"type":"json","json":[]},"maxUnlockCount":4,"unlocksRemaining":4},"Post:93d4e34e5698":{"__typename":"Post","id":"93d4e34e5698","mediumUrl":"https:\u002F\u002Fmedium.com\u002Fthe-official-integrate-ai-blog\u002Funderstanding-reinforcement-learning-93d4e34e5698","canonicalUrl":"","collection":{"type":"id","generated":false,"id":"Collection:71fa8c342920","typename":"Collection"},"content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"type":"id","generated":true,"id":"$Post:93d4e34e5698.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})","typename":"PostContent"},"creator":{"type":"id","generated":false,"id":"User:dbf4eb8c5945","typename":"User"},"firstPublishedAt":1538408393383,"isLocked":false,"isPublished":true,"layerCake":3,"primaryTopic":{"type":"id","generated":false,"id":"machine-learning","typename":"Topic"},"title":"What is Model-Based Reinforcement Learning?","latestPublishedVersion":"2653d22578e0","visibility":"PUBLIC","isLimitedState":false,"sequence":null,"pendingCollection":null,"shareKey":null,"statusForCollection":"APPROVED","readingTime":7.466981132075471,"readingList":"READING_LIST_NONE","allowResponses":true,"clapCount":267,"viewerClapCount":null,"voterCount":63,"recommenders":[],"license":"ALL_RIGHTS_RESERVED","tags":[{"type":"id","generated":false,"id":"Tag:machine-learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:blog","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:reinforcement-learning","typename":"Tag"}],"topics":[{"type":"id","generated":false,"id":"1eca0103fff3","typename":"Topic"}],"postResponses":{"type":"id","generated":true,"id":"$Post:93d4e34e5698.postResponses","typename":"PostResponses"},"responsesCount":0,"collaborators":[],"translationSourcePost":null,"newsletterId":"","inResponseToPostResult":null,"inResponseToMediaResource":null,"lockedSource":"LOCKED_POST_SOURCE_NONE","curationEligibleAt":0,"isDistributionAlertDismissed":false,"audioVersionUrl":"","socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1540833816472,"previewContent":{"type":"id","generated":true,"id":"$Post:93d4e34e5698.previewContent","typename":"PreviewContent"},"previewImage":{"type":"id","generated":false,"id":"ImageMetadata:1*iKKuLzwvS24L1mML4N8A_A.png","typename":"ImageMetadata"},"isShortform":false,"seoTitle":"","updatedAt":1540833816472,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false},"Collection:71fa8c342920":{"id":"71fa8c342920","isAuroraVisible":false,"domain":null,"googleAnalyticsId":null,"slug":"the-official-integrate-ai-blog","customStyleSheet":null,"colorBehavior":"ACCENT_COLOR","favicon":{"type":"id","generated":false,"id":"ImageMetadata:","typename":"ImageMetadata"},"name":"the integrate.ai blog","logo":{"type":"id","generated":false,"id":"ImageMetadata:1*eeO70qvAHD7978tgMKyCUw.png","typename":"ImageMetadata"},"__typename":"Collection","avatar":{"type":"id","generated":false,"id":"ImageMetadata:1*vg0fajz0k-RurDLtkV_EXg.jpeg","typename":"ImageMetadata"},"isAuroraEligible":false,"isEnrolledInHightower":false,"isNewsletterV3Enabled":false,"newsletterV3":null,"creator":{"type":"id","generated":false,"id":"User:dbf4eb8c5945","typename":"User"},"viewerIsEditor":false,"navItems":[{"type":"id","generated":true,"id":"Collection:71fa8c342920.navItems.0","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:71fa8c342920.navItems.1","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:71fa8c342920.navItems.2","typename":"NavItem"}],"colorPalette":{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette","typename":"ColorPalette"},"viewerCanEditOwnPosts":false,"viewerCanEditPosts":false,"viewerIsMuting":false,"description":"TO based startup, building a future in which AI enriches people’s lives while creating better, more valuable businesses.","viewerIsFollowing":false,"viewerIsSubscribedToLetters":false,"canToggleEmail":true,"isUserSubscribedToCollectionEmails":false,"ampEnabled":false,"twitterUsername":null,"facebookPageId":null,"tagline":"TO based startup, building a future in which AI enriches…"},"ImageMetadata:":{"id":"","__typename":"ImageMetadata"},"ImageMetadata:1*eeO70qvAHD7978tgMKyCUw.png":{"id":"1*eeO70qvAHD7978tgMKyCUw.png","originalWidth":3097,"originalHeight":1093,"__typename":"ImageMetadata"},"ImageMetadata:1*vg0fajz0k-RurDLtkV_EXg.jpeg":{"id":"1*vg0fajz0k-RurDLtkV_EXg.jpeg","__typename":"ImageMetadata"},"User:dbf4eb8c5945":{"id":"dbf4eb8c5945","__typename":"User","isSuspended":false,"allowNotes":true,"name":"integrate.ai","isFollowing":false,"username":"integrate.ai","bio":"TO based startup, building a future in which AI enriches people’s lives while creating better, more valuable businesses. www.integrate.ai","imageId":"1*j2sYTw20WODHLS4w0rD8dQ.png","mediumMemberAt":0,"isBlocking":false,"isMuting":false,"isPartnerProgramEnrolled":false,"twitterScreenName":"IntegrateAI"},"Collection:71fa8c342920.navItems.0":{"title":"News","url":"https:\u002F\u002Fmedium.com\u002Fthe-official-integrate-ai-blog\u002Fnews\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:71fa8c342920.navItems.1":{"title":"Podcast","url":"https:\u002F\u002Fmedium.com\u002Fthe-official-integrate-ai-blog\u002Fincontext\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:71fa8c342920.navItems.2":{"title":"Blog","url":"https:\u002F\u002Fmedium.com\u002Fthe-official-integrate-ai-blog\u002Fblog\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"$Collection:71fa8c342920.colorPalette":{"tintBackgroundSpectrum":null,"__typename":"ColorPalette","highlightSpectrum":{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.highlightSpectrum","typename":"ColorSpectrum"},"defaultBackgroundSpectrum":{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum","typename":"ColorSpectrum"}},"$Collection:71fa8c342920.colorPalette.highlightSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.4","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.0":{"color":"#FFFFFFFF","point":0,"__typename":"ColorPoint"},"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.1":{"color":"#FFE9FDF0","point":0.1,"__typename":"ColorPoint"},"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.2":{"color":"#FFE2FAEE","point":0.2,"__typename":"ColorPoint"},"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.3":{"color":"#FFADFFCF","point":0.6,"__typename":"ColorPoint"},"$Collection:71fa8c342920.colorPalette.highlightSpectrum.colorPoints.4":{"color":"#FF7DFFB3","point":1,"__typename":"ColorPoint"},"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum.colorPoints.3","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum.colorPoints.0":{"color":"#FF02B875","point":0,"__typename":"ColorPoint"},"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum.colorPoints.1":{"color":"#FF00AB6B","point":0.1,"__typename":"ColorPoint"},"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum.colorPoints.2":{"color":"#FF1C9963","point":0.2,"__typename":"ColorPoint"},"$Collection:71fa8c342920.colorPalette.defaultBackgroundSpectrum.colorPoints.3":{"color":"#FF092E20","point":1,"__typename":"ColorPoint"},"$Post:93d4e34e5698.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"isLockedPreviewOnly":false,"validatedShareKey":"","__typename":"PostContent","bodyModel":{"type":"id","generated":true,"id":"$Post:93d4e34e5698.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel","typename":"RichText"}},"machine-learning":{"name":"Machine Learning","slug":"machine-learning","__typename":"Topic","isFollowing":null},"$Post:93d4e34e5698.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.0":{"name":"edc5","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:93d4e34e5698.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel":{"sections":[{"type":"id","generated":true,"id":"$Post:93d4e34e5698.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.0","typename":"Section"}],"paragraphs":[{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_0","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_1","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_2","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_3","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_4","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_5","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_6","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_7","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_8","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_9","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_10","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_11","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_12","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_13","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_14","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_15","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_16","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_17","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_18","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_19","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_20","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_21","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_22","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_23","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_24","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_25","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_26","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_27","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_28","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_29","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_30","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2653d22578e0_31","typename":"Paragraph"}],"__typename":"RichText"},"Paragraph:2653d22578e0_0":{"id":"2653d22578e0_0","name":"ffa8","type":"H3","href":null,"layout":null,"metadata":null,"text":"What is Model-Based Reinforcement Learning?","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_1":{"id":"2653d22578e0_1","name":"c481","type":"H4","href":null,"layout":null,"metadata":null,"text":"Our monthly analysis on machine learning trends","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_2":{"id":"2653d22578e0_2","name":"9a5c","type":"P","href":null,"layout":null,"metadata":null,"text":"This post was originally sent as our monthly newsletter about trends in machine learning and artificial intelligence. If you’d like these analyses delivered directly to your inbox, subscribe here!","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_2.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_2.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_2.markups.0":{"type":"A","start":181,"end":195,"href":"https:\u002F\u002Fwww.integrate.ai\u002Fsubscribe\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_2.markups.1":{"type":"EM","start":0,"end":196,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_3":{"id":"2653d22578e0_3","name":"8474","type":"P","href":null,"layout":null,"metadata":null,"text":"Machines learn differently than people. For instance, you probably didn’t learn the difference between a positive and a negative movie review by analyzing tens of thousands of labeled examples of each. There is, however, a specific subfield of machine learning that bears a striking resemblance to aspects of how we learn.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_4":{"id":"2653d22578e0_4","name":"fc8e","type":"P","href":null,"layout":null,"metadata":null,"text":"Reinforcement learning (RL) is a field that’s been around for a few decades. Lately, it’s been picking up steam thanks to its integration of deep neural networks (deep reinforcement learning) and the newsworthy successes it’s accumulated as a result. At its core though, RL is concerned with how to go about making decisions and taking sequential actions in a specific environment to maximize a reward. Or, to put a more personal spin on it, what steps should you take to get promoted at your job, or to improve your fitness, or to save money to buy a house? We tend to figure out an optimal approach to accomplish goals like these through some degree of trial and error, evolving our strategies based on feedback from our environment.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_4.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_4.markups.0":{"type":"A","start":200,"end":220,"href":"https:\u002F\u002Fwww.theatlantic.com\u002Ftechnology\u002Farchive\u002F2016\u002F03\u002Fthe-invisible-opponent\u002F475611\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_5":{"id":"2653d22578e0_5","name":"bf55","type":"P","href":null,"layout":null,"metadata":null,"text":"At a basic level, RL works in much the same way. Of course, backed by computing power, it can explore different strategies (or “policies” in the RL literature) much faster than we can, often with pretty impressive results (especially for simple environments). On the other hand, lacking the prior knowledge that humans bring to new situations and environments, RL approaches also tend to need to explore many more policies than a human would before finding an optimal one.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_5.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_5.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_5.markups.0":{"type":"A","start":238,"end":257,"href":"https:\u002F\u002Fwww.youtube.com\u002Fwatch?v=TmPfTpjtdgg","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_5.markups.1":{"type":"A","start":291,"end":359,"href":"https:\u002F\u002Fwww.technologyreview.com\u002Fs\u002F610434\u002Fwhy-humans-learn-faster-than-ai-for-now\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_6":{"id":"2653d22578e0_6","name":"56c2","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*iKKuLzwvS24L1mML4N8A_A.png","typename":"ImageMetadata"},"text":"Google DeepMind’s research demonstrates how a humanoid figure can learn to\nmaneuver around a simulated environment","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_6.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*iKKuLzwvS24L1mML4N8A_A.png":{"id":"1*iKKuLzwvS24L1mML4N8A_A.png","originalHeight":852,"originalWidth":1128,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:2653d22578e0_6.markups.0":{"type":"A","start":18,"end":26,"href":"https:\u002F\u002Fdeepmind.com\u002Fblog\u002Fproducing-flexible-behaviours-simulated-environments\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_7":{"id":"2653d22578e0_7","name":"a566","type":"P","href":null,"layout":null,"metadata":null,"text":"As reinforcement learning is a broad field, let’s focus on one specific aspect: model-based reinforcement learning. As we’ll see, model-based RL attempts to overcome the issue of a lack of prior knowledge by enabling the agent — whether this agent happens to be a robot in the real world, an avatar in a virtual one, or just a piece software that take actions — to construct a functional representation of its environment.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_8":{"id":"2653d22578e0_8","name":"439b","type":"P","href":null,"layout":null,"metadata":null,"text":"While model-based reinforcement learning may not have clear commercial applications at this stage, its potential impact is enormous. After all, as AI becomes more complex and adaptive — extending beyond a focus on classification and representation toward more human-centered capabilities — model-based RL will almost certainly play an essential role in shaping these frontiers.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_9":{"id":"2653d22578e0_9","name":"fcdf","type":"BQ","href":null,"layout":null,"metadata":null,"text":"“The next big step forward in AI will be systems that actually understand their worlds. The world is only accessed through the lens of experience, so to understand the world means to be able to predict and control your experience, your sense data, with some accuracy and flexibility. In other words, understanding means forming a predictive model of the world and using it to get what you want. This is model-based reinforcement learning.”","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_10":{"id":"2653d22578e0_10","name":"6553","type":"BQ","href":null,"layout":null,"metadata":null,"text":"Richard S. Sutton\nPrimary Researcher at the Alberta Machine Intelligence Institute","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_10.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_10.markups.0":{"type":"STRONG","start":0,"end":82,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_11":{"id":"2653d22578e0_11","name":"eef6","type":"H3","href":null,"layout":null,"metadata":null,"text":"To Model or Not to Model","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_11.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_11.markups.0":{"type":"STRONG","start":0,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_12":{"id":"2653d22578e0_12","name":"82dc","type":"P","href":null,"layout":null,"metadata":null,"text":"“Model” is one of those terms that gets thrown around a lot in machine learning (and in scientific disciplines more generally), often with a relatively vague explanation of what we mean. Fortunately, in reinforcement learning, a model has a very specific meaning: it refers to the different dynamic states of an environment and how these states lead to a reward.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_13":{"id":"2653d22578e0_13","name":"0713","type":"P","href":null,"layout":null,"metadata":null,"text":"Model-based RL entails constructing such a model. Model-free RL, conversely, forgoes this environmental information and only concerns itself with determining what action to take given a specific state. As a result, model-based RL tends to emphasize planning, whereas model-free RL tends to emphasize learning (that said, a lot of learning also goes on in model-based RL). The distinction between these two approaches can seem a bit abstract, so let’s consider a real-world analogy.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_14":{"id":"2653d22578e0_14","name":"44c0","type":"P","href":null,"layout":null,"metadata":null,"text":"Imagine you’re visiting a city that you’ve never been to before and for whatever reason you don’t have access to a map. You know the general direction from your hotel to the area where most of the sights of interest are, but there are quite a number of different possible routes, some of which lead you through a slightly dangerous neighborhood.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_15":{"id":"2653d22578e0_15","name":"891c","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*mbL0rXZdVBkG7BrlNFxmpA.png","typename":"ImageMetadata"},"text":"A state graph from a paper on RL approaches for simulated urban environments","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_15.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*mbL0rXZdVBkG7BrlNFxmpA.png":{"id":"1*mbL0rXZdVBkG7BrlNFxmpA.png","originalHeight":654,"originalWidth":1140,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:2653d22578e0_15.markups.0":{"type":"A","start":21,"end":26,"href":"https:\u002F\u002Fwww.semanticscholar.org\u002Fpaper\u002FBehavioural-Animation-of-Autonomous-Virtual-Agents-Conde-Tambellini\u002Fed15732e8864376e78ef6410072b77387aeec267","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_16":{"id":"2653d22578e0_16","name":"2755","type":"P","href":null,"layout":null,"metadata":null,"text":"One navigational option is to keep track of all the routes you’ve taken (and the different streets and landmarks that make up these routes) to begin to create a map of the area. This map would be incomplete (it would only rely on where you’d already walked), but would at least allow you to plan a course ahead of time to avoid that neighborhood while still optimizing for the most direct route. You could even spend time back in your hotel room drawing out the different possible itineraries on a sheet of paper and trying to gauge which one seems like the best overall option. You can think of this as a model-based approach.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_17":{"id":"2653d22578e0_17","name":"db59","type":"P","href":null,"layout":null,"metadata":null,"text":"Another option — especially if you’re the type of person who’s not big on planning — would simply be to keep track of the different locations you’d visited (intersections, parks, and squares for instance) and the actions you took (which way you turned), but ignore the details of the routes themselves. In this case, whenever you found yourself in a location you’d already visited, you could favor the directional choice that led to a good outcome (avoiding the dangerous neighborhood and arriving at your destination more efficiently) over the directions that led to a negative outcome. You wouldn’t specifically know the next location you’d arrive at with each decision, but you would at least have learned a simple procedure for what action to take given a specific location. This is essentially the approach that model-free RL takes.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_18":{"id":"2653d22578e0_18","name":"66fd","type":"P","href":null,"layout":null,"metadata":null,"text":"As it relates to specific RL terms and concepts, we can say that you, the urban navigator, are the agent; that the different locations at which you need to make a directional decision are the states; and that the direction you choose to take from these states are the actions. The rewards (the feedback based on the agent’s actions) would most likely be positive anytime an action both got you closer to your destination and avoided the dangerous neighborhood, zero if you avoided the neighborhood but failed to get closer to your destination, and negative anytime you failed to avoid the neighborhood. The policy is whatever strategy you use to determine what action\u002Fdirection to take based on your current state\u002Flocation. Finally, the value is the expected long-term return (the sum of all your current and future rewards) based on your current state and policy.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.2","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.3","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.4","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.5","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.6","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.7","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.8","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.9","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.10","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_18.markups.11","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_18.markups.0":{"type":"STRONG","start":99,"end":104,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.1":{"type":"STRONG","start":192,"end":198,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.2":{"type":"STRONG","start":268,"end":275,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.3":{"type":"STRONG","start":281,"end":288,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.4":{"type":"STRONG","start":607,"end":613,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.5":{"type":"STRONG","start":737,"end":742,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.6":{"type":"EM","start":99,"end":104,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.7":{"type":"EM","start":192,"end":198,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.8":{"type":"EM","start":268,"end":275,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.9":{"type":"EM","start":281,"end":288,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.10":{"type":"EM","start":607,"end":613,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_18.markups.11":{"type":"EM","start":737,"end":742,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_19":{"id":"2653d22578e0_19","name":"1f5e","type":"P","href":null,"layout":null,"metadata":null,"text":"In general, the core function of RL algorithms is to determine a policy that maximizes this long-term return, though there are a variety of different methods and algorithms to accomplish this. And again, the major difference between model-based and model-free RL is simply that the former incorporates a model of the agent’s environment, specifically one that influences how the agent’s overall policy is determined.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_19.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_19.markups.0":{"type":"A","start":140,"end":172,"href":"https:\u002F\u002Ftowardsdatascience.com\u002Fintroduction-to-various-reinforcement-learning-algorithms-i-q-learning-sarsa-dqn-ddpg-72a5e0cb6287","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_20":{"id":"2653d22578e0_20","name":"a6b7","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*Cavu8KUpkCznhU11SFnb4Q.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*Cavu8KUpkCznhU11SFnb4Q.png":{"id":"1*Cavu8KUpkCznhU11SFnb4Q.png","originalHeight":662,"originalWidth":1108,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:2653d22578e0_21":{"id":"2653d22578e0_21","name":"2556","type":"H3","href":null,"layout":null,"metadata":null,"text":"A Modest Comparison","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_21.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_21.markups.0":{"type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_22":{"id":"2653d22578e0_22","name":"5b89","type":"P","href":null,"layout":null,"metadata":null,"text":"So what are the pros and cons of the model-based vs. the model-free approach? Model-based RL has a lot going for it. For one thing, it tends to have higher sample efficiency than model-free RL, meaning it requires less data to learn a policy. In other words, by leveraging the information it’s learned about its environment, model-based RL can plan rather than just react, even simulating sequences of actions without having to directly perform them in the actual environment.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_23":{"id":"2653d22578e0_23","name":"1163","type":"P","href":null,"layout":null,"metadata":null,"text":"A related benefit is that by virtue of the modeling process, model-based RL has the potential to be transferable to other goals and tasks. While learning a single policy is good for one task, if you can predict the dynamics of the environment, you can generalize those insights to multiple tasks. Finally, having a model means you can determine some degree of model uncertainty, so that you can gauge how confident you should be about the resulting decision process.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_24":{"id":"2653d22578e0_24","name":"8d12","type":"P","href":null,"layout":null,"metadata":null,"text":"Moving to the cons of model-based RL (or the pros of model-free RL), one of the biggest ones is simply that by having to learn a policy (the overall strategy to maximize the reward) as well as a model, you’re compounding the degree of potential error. In other words, there are two different sources of approximation error in model-based RL, whereas in model-free RL there’s only one. For similar reasons, model-based approaches tend to be far more computationally demanding than model-free ones, which by definition simplify the learning process.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_25":{"id":"2653d22578e0_25","name":"8d6f","type":"P","href":null,"layout":null,"metadata":null,"text":"It’s worth noting that this doesn’t necessarily need to be a binary decision. Some of the most effective recent approaches have combined model-based and model-free strategies. Perhaps this isn’t so surprising given the evidence that, as one paper states, “the [human] brain employs both model-free and model-based decision-making strategies in parallel, with each dominating in different circumstances.”","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_25.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_25.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_25.markups.2","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_25.markups.0":{"type":"A","start":105,"end":122,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1803.00101","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_25.markups.1":{"type":"A","start":128,"end":174,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1709.03153","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_25.markups.2":{"type":"A","start":241,"end":246,"href":"https:\u002F\u002Fwww.princeton.edu\u002F~yael\u002FPublications\u002FDayanNiv2008.pdf","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_26":{"id":"2653d22578e0_26","name":"cc72","type":"H3","href":null,"layout":null,"metadata":null,"text":"Recent Research and Frameworks","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_26.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_26.markups.0":{"type":"STRONG","start":0,"end":30,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_27":{"id":"2653d22578e0_27","name":"062a","type":"P","href":null,"layout":null,"metadata":null,"text":"A few years ago, OpenAI released an open source RL toolkit — OpenAI Gym — that provides a variety of flexible environments for algorithm experimentation and development. A team at Google has now followed suit, releasing its own Tensorflow-based framework this past month. Beyond just aiding experimentation, the Google team has also stated its explicit goal to help make RL research more reproducible (and, by extension, more accountable to the larger community). Rather than providing an environment, the Tensorflow framework instead offers acodebase of agents (four in all) as well as their training data, allowing users — even those with limited RL experience — a convenient entry point into experimental research.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_27.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_27.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_27.markups.2","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_27.markups.0":{"type":"A","start":61,"end":71,"href":"https:\u002F\u002Fgym.openai.com\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_27.markups.1":{"type":"A","start":228,"end":254,"href":"https:\u002F\u002Fai.googleblog.com\u002F2018\u002F08\u002Fintroducing-new-framework-for-flexible.html","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_27.markups.2":{"type":"A","start":543,"end":551,"href":"https:\u002F\u002Fgithub.com\u002Fgoogle\u002Fdopamine","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_28":{"id":"2653d22578e0_28","name":"cd3c","type":"P","href":null,"layout":null,"metadata":null,"text":"Speaking of research, a number of recent papers have demonstrated the practical and theoretical possibilities of model-based RL. One of the takeaways from these papers is just how broad the current applications of RL are. They include everything from robotics to natural language processing to a seemingly endless range of simulated environments.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_28.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_28.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_28.markups.2","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_28.markups.0":{"type":"A","start":24,"end":30,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.03858","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_28.markups.1":{"type":"A","start":34,"end":40,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1808.09105","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_28.markups.2":{"type":"A","start":41,"end":47,"href":"https:\u002F\u002Farxiv.org\u002Fabs\u002F1807.04723","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_29":{"id":"2653d22578e0_29","name":"20f6","type":"P","href":null,"layout":null,"metadata":null,"text":"This broad applicability certainly isn’t limited solely to model-based approaches. Still, on a more philosophical level, what makes model-based RL so compelling is partly the fact that it more faithfully mirrors the procedures we use to learn. We take it for granted, after all, that knowing more about our environment and its likely responses to our actions is useful for making good decisions. In a sense, model-based RL has simply figured out a way to mathematically formalize this basic human insight.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_30":{"id":"2653d22578e0_30","name":"f1d8","type":"H3","href":null,"layout":null,"metadata":null,"text":"What This Means For You","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2653d22578e0_30.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2653d22578e0_30.markups.0":{"type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2653d22578e0_31":{"id":"2653d22578e0_31","name":"6404","type":"P","href":null,"layout":null,"metadata":null,"text":"Model-based RL isn’t quite ready for primetime production contexts now. Still, it’s already become integral for developing algorithms that can handle complex sequences of events in both real and simulated environments. This is one of those areas of machine learning that’s worth keeping track of in the coming years: when model-based RL finally breaks into commercial settings, it’s going to make some serious waves.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Tag:machine-learning":{"id":"machine-learning","displayTitle":"Machine Learning","__typename":"Tag"},"Tag:blog":{"id":"blog","displayTitle":"Blog","__typename":"Tag"},"Tag:reinforcement-learning":{"id":"reinforcement-learning","displayTitle":"Reinforcement Learning","__typename":"Tag"},"1eca0103fff3":{"topicId":"1eca0103fff3","name":"Machine Learning","__typename":"Topic","slug":"machine-learning"},"$Post:93d4e34e5698.postResponses":{"count":0,"__typename":"PostResponses","responsesConnection({\"paging\":{\"limit\":10}})":{"type":"id","generated":true,"id":"$Post:93d4e34e5698.postResponses.responsesConnection({\"paging\":{\"limit\":10}})","typename":"StreamConnection"}},"$Post:93d4e34e5698.previewContent":{"subtitle":"Our monthly analysis on machine learning trends","__typename":"PreviewContent"},"$Post:93d4e34e5698.postResponses.responsesConnection({\"paging\":{\"limit\":10}}).pagingInfo":{"next":null,"__typename":"Paging"},"$Post:93d4e34e5698.postResponses.responsesConnection({\"paging\":{\"limit\":10}})":{"pagingInfo":{"type":"id","generated":true,"id":"$Post:93d4e34e5698.postResponses.responsesConnection({\"paging\":{\"limit\":10}}).pagingInfo","typename":"Paging"},"stream":[],"__typename":"StreamConnection"}}</script><script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/manifest.b83f1349.js"></script><script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/vendors_main.f2d8bc2b.chunk.js"></script><script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/main.d3c8430f.chunk.js"></script><script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/vendors_instrumentation.d7114bfc.chunk.js"></script>
<script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/instrumentation.26954fdd.chunk.js"></script>
<script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/reporting.f609fc16.chunk.js"></script>
<script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/vendors_AMPPost_CollectionHomepage_CollectionHomepagePreview_CollectionNewShortformEditor_Collection_37c9fa1e.77e6fe9c.chunk.js"></script>
<script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/vendors_AMPPost_DebugCachedPost_Post_SequencePost_Series.0bf77567.chunk.js"></script>
<script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/AMPPost_CollectionHomepage_CollectionHomepagePreview_CollectionNewShortformEditor_CollectionPostShor_3fa3f642.0e3f583f.chunk.js"></script>
<script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/AMPPost_CollectionHomepage_CollectionHomepagePreview_DebugCachedPost_PackageBuilder_Post_PostSetting_8e568ca5.05d2b9ba.chunk.js"></script>
<script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/Post.f1e962b1.chunk.js"></script><script>window.main();</script><script src="./Model-Based vs Sample based Reinforcement Learning_ - the integrate.ai blog - Medium_files/p.js" async="" id="parsely-cf"></script></body></html>