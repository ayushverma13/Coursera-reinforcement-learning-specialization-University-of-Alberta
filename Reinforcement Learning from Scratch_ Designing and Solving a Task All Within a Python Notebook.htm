<!DOCTYPE html>
<!-- saved from url=(0136)https://towardsdatascience.com/reinforcement-learning-from-scratch-designing-and-solving-a-task-all-within-a-python-notebook-48c40021da4 -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/branch-latest.min.js"></script><script async="" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/analytics.js"></script><script>!function(c,f){var t,o,i,e=[],r={passive:!0,capture:!0},n=new Date,a="pointerup",u="pointercancel";function p(n,e){t||(t=e,o=n,i=new Date,w(f),s())}function s(){0<=o&&o<i-n&&(e.forEach(function(n){n(o,t)}),e=[])}function l(n){if(n.cancelable){var e=(1e12<n.timeStamp?new Date:performance.now())-n.timeStamp;"pointerdown"==n.type?function(n,e){function t(){p(n,e),i()}function o(){i()}function i(){f(a,t,r),f(u,o,r)}c(a,t,r),c(u,o,r)}(e,n):p(e,n)}}function w(e){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(n){e(n,l,r)})}w(c),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){e.push(n),s()}}(addEventListener,removeEventListener)</script><script defer="" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/16180790160.js"></script><title>Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2018-12-20T09:19:00.227Z"><meta data-rh="true" name="title" content="Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook"><meta data-rh="true" property="og:title" content="Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook"><meta data-rh="true" property="twitter:title" content="Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook"><meta data-rh="true" name="twitter:site" content="@TDataScience"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/48c40021da4"><meta data-rh="true" property="al:android:url" content="medium://p/48c40021da4"><meta data-rh="true" property="al:ios:url" content="medium://p/48c40021da4"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="In this article, I will introduce a new project that attempts to help those learning Reinforcement Learning by fully defining and solving a simple task all within a Python notebook. The environment…"><meta data-rh="true" property="og:description" content="Part 1: Defining the Environment, Finding the Optimal Policy with Value-Iteration and Introducing Q-Learning"><meta data-rh="true" property="twitter:description" content="Part 1: Defining the Environment, Finding the Optimal Policy with Value-Iteration and Introducing Q-Learning"><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/reinforcement-learning-from-scratch-designing-and-solving-a-task-all-within-a-python-notebook-48c40021da4"><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/reinforcement-learning-from-scratch-designing-and-solving-a-task-all-within-a-python-notebook-48c40021da4"><meta data-rh="true" property="og:image" content="https://miro.medium.com/freeze/max/720/1*hrzESilcBh6DFTMGLc7JNQ.gif"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/freeze/max/720/1*hrzESilcBh6DFTMGLc7JNQ.gif"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="article:author" content="https://towardsdatascience.com/@sterlingosborne"><meta data-rh="true" name="twitter:creator" content="@DataOsborne"><meta data-rh="true" name="author" content="Sterling Osborne, PhD Researcher"><meta data-rh="true" name="robots" content="index,follow"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" name="twitter:label1" value="Reading time"><meta data-rh="true" name="twitter:data1" value="12 min read"><meta data-rh="true" name="parsely-post-id" content="48c40021da4"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/m2.css"><link data-rh="true" rel="author" href="https://towardsdatascience.com/@sterlingosborne"><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/reinforcement-learning-from-scratch-designing-and-solving-a-task-all-within-a-python-notebook-48c40021da4"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/48c40021da4"><link data-rh="true" rel="icon" href="https://miro.medium.com/fit/c/256/256/1*ChFMdf--f5jbm-AYv6VdYA@2x.png"><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Ffreeze\u002Fmax\u002F1200\u002F1*hrzESilcBh6DFTMGLc7JNQ.gif"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Freinforcement-learning-from-scratch-designing-and-solving-a-task-all-within-a-python-notebook-48c40021da4","dateCreated":"2018-12-19T17:08:07.797Z","datePublished":"2018-12-19T17:08:07.797Z","dateModified":"2018-12-20T09:19:00.227Z","headline":"Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook","name":"Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook","description":"In this article, I will introduce a new project that attempts to help those learning Reinforcement Learning by fully defining and solving a simple task all within a Python notebook. The environment…","identifier":"48c40021da4","keywords":["Lite:true","Tag:Machine Learning","Tag:Data Science","Tag:Reinforcement Learning","Tag:Learning","Tag:Guides And Tutorials","Topic:Machine Learning","Topic:Data Science","Publication:towards-data-science","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_NONE","LayerCake:4"],"author":{"@type":"Person","name":"Sterling Osborne, PhD Researcher","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@sterlingosborne"},"creator":["Sterling Osborne, PhD Researcher"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F330\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Freinforcement-learning-from-scratch-designing-and-solving-a-task-all-within-a-python-notebook-48c40021da4"}</script><script data-rh="true">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><link rel="preload" href="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/16180790160.js" as="script"><style type="text/css" data-fela-rehydration="565" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-webkit-keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@-moz-keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{fill:rgba(0, 0, 0, 0.84)}.r{display:block}.s{position:absolute}.t{top:0}.u{left:0}.v{right:0}.w{z-index:500}.x{box-shadow:0 4px 12px 0 rgba(0, 0, 0, 0.05)}.ag{max-width:1192px}.ah{min-width:0}.ai{width:100%}.aj{height:65px}.am{flex:1 0 auto}.an{visibility:hidden}.ao{margin-left:16px}.ap{display:none}.ar{color:rgba(90, 118, 144, 1)}.as{fill:rgba(102, 138, 170, 1)}.at{font-size:inherit}.au{border:inherit}.av{font-family:inherit}.aw{letter-spacing:inherit}.ax{font-weight:inherit}.ay{padding:0}.az{margin:0}.ba:hover{cursor:pointer}.bb:hover{color:rgba(84, 108, 131, 1)}.bc:hover{fill:rgba(90, 118, 144, 1)}.bd:focus{outline:none}.be:disabled{cursor:default}.bf:disabled{color:rgba(230, 57, 53, 0.5)}.bg:disabled{fill:rgba(230, 57, 53, 0.5)}.bh{flex:0 0 auto}.bi{font-family:medium-content-sans-serif-font, "Lucida Grande", "Lucida Sans Unicode", "Lucida Sans", Geneva, Arial, sans-serif}.bj{font-style:normal}.bk{line-height:20px}.bl{font-size:15.8px}.bm{letter-spacing:0px}.bn{color:rgba(0, 0, 0, 0.54)}.bo{fill:rgba(0, 0, 0, 0.54)}.bp{justify-content:flex-end}.bq{margin-top:16px}.br{margin-bottom:16px}.bs{display:inherit}.bt{max-width:210px}.bu{text-overflow:ellipsis}.bv{overflow:hidden}.bw{white-space:nowrap}.bx{display:inline-block}.by{border:none}.bz{outline:none}.ca{font:inherit}.cb{font-size:16px}.cc{opacity:0}.cd{position:relative}.ce{width:0px}.cf{transition:width 140ms ease-in}.cg{color:inherit}.ch{fill:inherit}.ci:hover{color:rgba(0, 0, 0, 0.9)}.cj:hover{fill:rgba(0, 0, 0, 0.9)}.ck:disabled{color:rgba(0, 0, 0, 0.54)}.cl:disabled{fill:rgba(0, 0, 0, 0.54)}.cm{margin-right:10px}.cq{margin-right:16px}.cr{margin:15px 0}.cs{padding:4px 12px}.ct{color:rgba(0, 0, 0, 0.84)}.cu{background:0}.cv{border-color:rgba(0, 0, 0, 0.54)}.cw:hover{color:rgba(0, 0, 0, 0.97)}.cx:hover{fill:rgba(0, 0, 0, 0.97)}.cy:hover{border-color:rgba(0, 0, 0, 0.84)}.cz:disabled{fill:rgba(0, 0, 0, 0.76)}.da:disabled{border-color:rgba(0, 0, 0, 0.2)}.db:disabled{cursor:inherit}.dc:disabled:hover{color:rgba(0, 0, 0, 0.54)}.dd:disabled:hover{fill:rgba(0, 0, 0, 0.76)}.de:disabled:hover{border-color:rgba(0, 0, 0, 0.2)}.df{border-radius:4px}.dg{border-width:1px}.dh{border-style:solid}.di{box-sizing:border-box}.dj{text-decoration:none}.dk{padding-bottom:10px}.dl{padding-top:10px}.dm{border-radius:50%}.dn{height:32px}.do{width:32px}.dp{border-top:none}.dq{background-color:rgba(53, 88, 118, 1)}.dr{height:54px}.ds{margin-right:40px}.dt{height:36px}.du{width:100px}.dv{overflow:auto}.dw{flex:0 1 auto}.dx{list-style-type:none}.dy{line-height:40px}.dz{overflow-x:auto}.ea{align-items:flex-start}.eb{margin-top:20px}.ec{padding-top:20px}.ed{height:80px}.ee{height:20px}.ef{margin-right:15px}.eg{margin-left:15px}.eh:first-child{margin-left:0}.ei{min-width:1px}.ej{background-color:rgba(197, 210, 225, 1)}.ek{font-weight:300}.el{font-size:15px}.em{color:rgba(197, 210, 225, 1)}.en{text-transform:uppercase}.eo{letter-spacing:1px}.ep:hover{color:rgba(251, 255, 255, 1)}.eq:hover{fill:rgba(233, 241, 250, 1)}.er:disabled{color:rgba(150, 171, 191, 1)}.es:disabled{fill:rgba(150, 171, 191, 1)}.et{margin-bottom:0px}.eu{height:119px}.ex{padding-left:24px}.ey{padding-right:24px}.ez{margin-left:auto}.fa{margin-right:auto}.fb{max-width:728px}.fc{top:calc(100vh + 100px)}.fd{bottom:calc(100vh + 100px)}.fe{width:10px}.ff{pointer-events:none}.fg{word-break:break-word}.fh{word-wrap:break-word}.fi:after{display:block}.fj:after{content:""}.fk:after{clear:both}.fl{max-width:680px}.fm{line-height:1.23}.fn{letter-spacing:0}.fo{font-family:medium-content-title-font, Georgia, Cambria, "Times New Roman", Times, serif}.fz{margin-bottom:-0.27em}.gf{line-height:1.394}.gq{margin-bottom:-0.42em}.gw{margin-top:32px}.gx{justify-content:space-between}.hb{width:48px}.hc{height:48px}.hd{fill:rgba(3, 168, 124, 1)}.he{flex-direction:row}.hf{width:calc(100% + 25px)}.hg{height:calc(100% + 25px)}.hh{top:50%}.hi{left:50%}.hj{transform:translateX(-50%) translateY(-50%)}.hk{margin-left:12px}.hl{margin-bottom:2px}.hn{max-height:20px}.ho{display:-webkit-box}.hp{-webkit-line-clamp:1}.hq{-webkit-box-orient:vertical}.hr:hover{text-decoration:underline}.hs{margin-left:8px}.ht{padding:0px 8px}.hu{border-color:rgba(102, 138, 170, 1)}.hv:hover{border-color:rgba(90, 118, 144, 1)}.hw{line-height:18px}.hx{align-items:flex-end}.if{padding-right:6px}.ig{margin-right:8px}.ih{fill:rgba(0, 0, 0, 0.76)}.ii{margin-right:-6px}.ij{line-height:1.18}.ik{letter-spacing:-0.022em}.il{font-weight:600}.iw{margin-bottom:-0.31em}.ix{line-height:1.58}.iy{letter-spacing:-0.004em}.iz{font-family:medium-content-serif-font, Georgia, Cambria, "Times New Roman", Times, serif}.ji{margin-bottom:-0.46em}.jj{letter-spacing:-0.003em}.jr{box-shadow:0 1px 4px rgba(0, 0, 0, 0.1), inset 0 0 0 1px rgba(0, 0, 0, 0.1)}.js{padding:0px}.jt{padding:16px 20px}.ju{flex-direction:column}.jv{flex:1 1 auto}.jx{font-size:18px}.jy{max-height:40px}.jz{-webkit-line-clamp:2}.ka{margin-top:8px}.kb{margin-top:12px}.kc{width:160px}.kd{background-image:url(https://miro.medium.com/max/320/0*LErpsCYVnImxewHx)}.ke{background-origin:border-box}.kf{background-size:cover}.kg{height:167px}.kh{background-position:50% 50%}.ki{max-width:100%}.kj{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.1)}.kp{font-weight:700}.kq{font-family:medium-content-slab-serif-font, Georgia, Cambria, "Times New Roman", Times, serif}.kr{font-size:28px}.ks{color:rgba(0, 0, 0, 0.97)}.kt{margin-top:30px}.ku{text-align:center}.kv:before{content:"..."}.kw:before{letter-spacing:0.6em}.kx:before{text-indent:0.6em}.ky:before{font-style:italic}.kz:before{line-height:1.4}.la{line-height:1.12}.lj{margin-bottom:-0.28em}.lk{max-width:664px}.lq{clear:both}.lr{transition:opacity 100ms 400ms}.ls{height:100%}.lt{will-change:transform}.lu{transform:translateZ(0)}.lv{margin:auto}.lw{background-color:rgba(0, 0, 0, 0.05)}.lx{padding-bottom:81.02409638554217%}.ly{height:0}.lz{filter:blur(20px)}.ma{transform:scale(1.1)}.mb{visibility:visible}.mc{background:rgba(255, 255, 255, 1)}.md{margin-top:10px}.mg{max-width:411px}.mh{padding-bottom:67.63990267639903%}.mi{list-style-type:disc}.mj{margin-left:30px}.mk{padding-left:0px}.mq{max-width:444px}.mr{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.ms{cursor:zoom-in}.mt{z-index:auto}.mu{padding-bottom:26.8018018018018%}.mv{max-width:408px}.mw{padding-bottom:14.950980392156861%}.mx{max-width:404px}.my{padding-bottom:21.534653465346533%}.mz{max-width:412px}.na{padding-bottom:14.563106796116505%}.nb{max-width:496px}.nc{padding-bottom:34.67741935483871%}.nd{max-width:469px}.ne{padding-bottom:38.80597014925373%}.nf{max-width:1285px}.ng{padding-bottom:63.735408560311285%}.nh{max-width:715px}.ni{padding-bottom:40%}.nj{max-width:397px}.nk{padding-bottom:70.27707808564232%}.nl{max-width:750px}.nm{padding-bottom:100%}.nn{max-width:474px}.no{padding-bottom:21.308016877637133%}.np{background-repeat:repeat-x}.nq{background-image:linear-gradient(to right,rgba(0, 0, 0, 0.84) 100%,rgba(0, 0, 0, 0.84) 0);background-image:url('data:image/svg+xml;utf8,<svg preserveAspectRatio="none" viewBox="0 0 1 1" xmlns="http://www.w3.org/2000/svg"><line x1="0" y1="0" x2="1" y2="1" stroke="rgba(0, 0, 0, 0.84)" /></svg>')}.nr{background-size:1px 1px}.ns{background-position:0 1.05em;background-position:0 calc(1em + 1px)}.nt{padding-bottom:53.38235294117647%}.nu{max-width:372px}.nv{padding-bottom:79.83870967741935%}.nw{max-width:1737px}.nx{padding-bottom:18.595279217040876%}.ny{max-width:381px}.nz{padding-bottom:69.29133858267717%}.oa{padding-bottom:67.71844660194175%}.ob{max-width:627px}.oc{padding-bottom:96.49122807017544%}.od{max-width:720px}.oe{max-width:439px}.of{padding-bottom:11.61731207289294%}.og{max-width:371px}.oh{padding-bottom:169.00269541778974%}.oi{max-width:394px}.oj{padding-bottom:70.55837563451776%}.op{will-change:opacity}.oq{position:fixed}.or{width:188px}.os{transform:translateX(406px)}.ot{top:calc(65px + 54px + 14px)}.ow{top:calc(65px + 54px + 40px)}.oy{width:131px}.oz{padding-bottom:28px}.pa{border-bottom:1px solid rgba(0, 0, 0, 0.1)}.pb{padding-bottom:20px}.pc{padding-top:2px}.pd{max-height:120px}.pe{-webkit-line-clamp:6}.pf{padding-top:28px}.pg{margin-bottom:19px}.ph{margin-left:-3px}.pn{outline:0}.po{border:0}.pp{user-select:none}.pq{cursor:pointer}.pr> svg{pointer-events:none}.ps:active{border-style:none}.pt{-webkit-user-select:none}.pu:focus{fill:rgba(0, 0, 0, 0.54)}.pv:hover{fill:rgba(0, 0, 0, 0.54)}.qd button{text-align:left}.qe{margin-top:40px}.qf{flex-wrap:wrap}.qg{margin-top:25px}.qh{margin-bottom:8px}.qi{border-radius:3px}.qj{padding:5px 10px}.qk{background:rgba(0, 0, 0, 0.05)}.ql{line-height:22px}.qm{margin-top:15px}.qn{max-width:155px}.qt{border:1px solid rgba(0, 0, 0, 0.1)}.qu{height:60px}.qv{width:60px}.ri:hover{border-color:rgba(0, 0, 0, 0.54)}.rj:active{border-style:solid}.rk{z-index:2}.rm{top:1px}.rs{padding-right:8px}.rt{padding-top:32px}.ru{border-top:1px solid rgba(0, 0, 0, 0.1)}.rv{margin-bottom:25px}.rx{margin-bottom:32px}.ry{min-height:80px}.sd{width:80px}.se{padding-left:102px}.sg{letter-spacing:0.05em}.sh{margin-bottom:6px}.si{line-height:36px}.sj{max-width:555px}.sk{max-width:450px}.sl{line-height:24px}.sn{max-width:550px}.so{padding-top:24px}.sp{margin-top:5px}.sq{width:40px}.sr{height:40px}.ss{font-size:12px}.st{line-height:15px}.su{padding-top:8px}.sv{padding-top:25px}.sx{color:rgba(0, 0, 0, 0.76)}.sy{opacity:1}.sz{padding:20px}.ta{border:1px solid rgba(102, 138, 170, 1)}.tb{margin-top:64px}.tc{background-color:rgba(0, 0, 0, 0.02)}.td{padding:60px 0}.te{background-color:rgba(0, 0, 0, 0.9)}.tv{padding-bottom:48px}.tw{border-bottom:1px solid rgba(255, 255, 255, 0.54)}.tx{margin:0 -12px}.ty{margin:0 12px}.tz{flex:1 1 0}.ua{padding-bottom:12px}.ub:hover{color:rgba(255, 255, 255, 0.99)}.uc:hover{fill:rgba(255, 255, 255, 0.99)}.ud:disabled{color:rgba(255, 255, 255, 0.7)}.ue:disabled{fill:rgba(255, 255, 255, 0.7)}.uf{color:rgba(255, 255, 255, 0.98)}.ug{fill:rgba(255, 255, 255, 0.98)}.uh{text-align:inherit}.ui{font-size:21.6px}.uj{letter-spacing:-0.32px}.uk{color:rgba(255, 255, 255, 0.7)}.ul{fill:rgba(255, 255, 255, 0.7)}.um{text-decoration:underline}.un{padding-bottom:8px}.uo{width:200px}.uu:disabled{color:rgba(3, 168, 124, 0.5)}.uv:disabled{fill:rgba(3, 168, 124, 0.5)}.uw{-webkit-user-select:none}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.af{margin:0 64px}.fx{font-size:40px}.fy{margin-top:0.78em}.ge{line-height:48px}.go{font-size:24px}.gp{margin-top:0.79em}.gv{line-height:32px}.ie{margin-left:30px}.iu{font-size:26px}.iv{margin-top:1.72em}.jg{font-size:21px}.jh{margin-top:0.86em}.jq{margin-top:32px}.ko{margin-top:2em}.lh{font-size:34px}.li{margin-top:1.25em}.lp{margin-top:56px}.mp{margin-top:1.05em}.oo{margin-top:1.95em}.pm{margin-right:5px}.qc{margin-top:5px}.qs{margin-right:16px}.rr{width:25px}.ts{padding-left:64px}.tt{padding-right:64px}.tu{max-width:1320px}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.id{margin-left:30px}.me{margin-left:auto}.mf{text-align:center}.pl{margin-right:5px}.qb{margin-top:5px}.qr{margin-right:16px}.rq{width:25px}.tp{padding-left:64px}.tq{padding-right:64px}.tr{max-width:1080px}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.cp{display:flex}.ic{margin-left:30px}.pk{margin-right:5px}.qa{margin-top:5px}.qq{margin-right:16px}.rp{width:15px}.tm{padding-left:48px}.tn{padding-right:48px}.to{max-width:904px}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.ak{height:56px}.al{display:flex}.aq{display:block}.cn{margin-left:10px}.co{margin-right:10px}.ev{margin-bottom:0px}.ew{height:110px}.gz{margin-top:32px}.ha{flex-direction:column-reverse}.ia{margin-bottom:30px}.ib{margin-left:0px}.jw{padding:10px 12px 10px}.pj{margin-left:8px}.py{margin-top:2px}.pz{margin-right:8px}.qp{margin-left:16px}.ro{width:15px}.rw{padding-top:0}.rz{margin-bottom:24px}.sa{align-items:center}.sb{width:102px}.sc{position:relative}.sf{padding-left:0}.sm{margin-top:24px}.sw{border-top:none}.tf{padding:32px 0}.tj{padding-left:24px}.tk{padding-right:24px}.tl{max-width:728px}.up{width:140px}.uq{margin-bottom:16px}.ur{margin-top:30px}.us{width:100%}.ut{flex-direction:row}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.z{margin:0 24px}.fp{font-size:30px}.fq{margin-top:0.72em}.ga{line-height:40px}.gg{font-size:18px}.gh{margin-top:0.79em}.gr{line-height:24px}.gy{margin-top:32px}.hm{margin-bottom:0px}.hy{margin-bottom:30px}.hz{margin-left:0px}.im{font-size:24px}.in{margin-top:1.23em}.ja{margin-top:0.67em}.jk{line-height:28px}.jm{margin-top:24px}.kk{margin-top:1.56em}.lb{margin-top:0.93em}.ll{margin-top:40px}.ml{margin-top:1.34em}.ok{margin-top:1.2em}.pi{margin-left:8px}.pw{margin-top:2px}.px{margin-right:8px}.qo{margin-left:16px}.rn{width:15px}.tg{padding-left:24px}.th{padding-right:24px}.ti{max-width:552px}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.ae{margin:0 64px}.fv{font-size:40px}.fw{margin-top:0.78em}.gd{line-height:48px}.gm{font-size:24px}.gn{margin-top:0.79em}.gu{line-height:32px}.is{font-size:26px}.it{margin-top:1.72em}.je{font-size:21px}.jf{margin-top:0.86em}.jp{margin-top:32px}.kn{margin-top:2em}.lf{font-size:34px}.lg{margin-top:1.25em}.lo{margin-top:56px}.mo{margin-top:1.05em}.on{margin-top:1.95em}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.ac{margin:0 48px}.ft{font-size:40px}.fu{margin-top:0.78em}.gc{line-height:48px}.gk{font-size:24px}.gl{margin-top:0.79em}.gt{line-height:32px}.iq{font-size:26px}.ir{margin-top:1.72em}.jc{font-size:21px}.jd{margin-top:0.86em}.jo{margin-top:32px}.km{margin-top:2em}.ld{font-size:34px}.le{margin-top:1.25em}.ln{margin-top:56px}.mn{margin-top:1.05em}.om{margin-top:1.95em}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.ab{margin:0 24px}.fr{font-size:30px}.fs{margin-top:0.72em}.gb{line-height:40px}.gi{font-size:18px}.gj{margin-top:0.79em}.gs{line-height:24px}.io{font-size:24px}.ip{margin-top:1.23em}.jb{margin-top:0.67em}.jl{line-height:28px}.jn{margin-top:24px}.kl{margin-top:1.56em}.lc{margin-top:0.93em}.lm{margin-top:40px}.mm{margin-top:1.34em}.ol{margin-top:1.2em}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="print">.y{display:none}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.ou{transition:opacity 200ms}.qw{transition:border-color 150ms ease}.qx::before{background:
      radial-gradient(circle, rgba(0, 0, 0, 0.84) 60%, transparent 70%)
    }.qy::before{border-radius:50%}.qz::before{content:""}.ra::before{display:block}.rb::before{z-index:0}.rc::before{left:0}.rd::before{height:100%}.re::before{position:absolute}.rf::before{top:0}.rg::before{width:100%}.rh:hover::before{animation:k2 2000ms infinite cubic-bezier(.1,.12,.25,1)}.rl{transition:fill 200ms ease}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (max-width: 1230px)">.ov{display:none}</style><style type="text/css" data-fela-rehydration="565" data-fela-type="RULE" media="all and (max-width: 1198px)">.ox{display:none}</style><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><nav class="r s t u v c w x y"><div><div class="r c"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="aj n o ak al"><div class="n o am w"><a href="https://medium.com/?source=post_page-----48c40021da4----------------------" aria-label="Homepage" rel="noopener"><svg width="35" height="35" viewBox="5 5 35 35" class="q"><path d="M5 40V5h35v35H5zm8.56-12.63c0 .56-.03.69-.32 1.03L10.8 31.4v.4h6.97v-.4L15.3 28.4c-.29-.34-.34-.5-.34-1.03v-8.95l6.13 13.36h.71l5.26-13.36v10.64c0 .3 0 .35-.19.53l-1.85 1.8v.4h9.2v-.4l-1.83-1.8c-.18-.18-.2-.24-.2-.53V15.94c0-.3.02-.35.2-.53l1.82-1.8v-.4h-6.47l-4.62 11.55-5.2-11.54h-6.8v.4l2.15 2.63c.24.3.29.37.29.77v10.35z"></path></svg></a><div class="mb" id="li-general-navbar-open-in-app-button"><div class="ao ap aq"><a href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F48c40021da4&amp;~feature=LiMobileNavBar&amp;~channel=ShowPostUnderCollection&amp;source=post_page-----48c40021da4----------------------" class="ar as at au av aw ax ay az ba bb bc bd be bf bg" rel="noopener nofollow">Open in app</a></div></div></div><div class="r bh w"><span class="bi b bj bk bl bm r bn bo"><div class="n o bp"><div class="n f"><div class="bx" aria-hidden="true"><div class="n"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25" class="ao cm r cn co"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></button><input class="by bz ca cb bk cc cd ce cf" placeholder="Search Towards Data Science" value=""></div></div></div><div class="ap cp"><a href="https://towardsdatascience.com/search?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="ao cq r cn co"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></a></div><a href="https://medium.com/me/list/queue?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="cq r g"><path d="M16 6a2 2 0 0 1 2 2v13.66h-.01a.5.5 0 0 1-.12.29.5.5 0 0 1-.7.03l-5.67-4.13-5.66 4.13a.5.5 0 0 1-.7-.03.48.48 0 0 1-.13-.29H5V8c0-1.1.9-2 2-2h9zM6 8v12.64l5.16-3.67a.49.49 0 0 1 .68 0L17 20.64V8a1 1 0 0 0-1-1H7a1 1 0 0 0-1 1z"></path><path d="M21 5v13.66h-.01a.5.5 0 0 1-.12.29.5.5 0 0 1-.7.03l-.17-.12V5a1 1 0 0 0-1-1h-9a1 1 0 0 0-1 1H8c0-1.1.9-2 2-2h9a2 2 0 0 1 2 2z"></path></svg></a><div class="cq n co"><div class="bx" aria-hidden="true"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl r"><svg width="25" height="25" viewBox="-293 409 25 25" class="cr r"><path d="M-273.33 423.67l-1.67-1.52v-3.65a5.5 5.5 0 0 0-6.04-5.47 5.66 5.66 0 0 0-4.96 5.71v3.41l-1.68 1.55a1 1 0 0 0-.32.74V427a1 1 0 0 0 1 1h3.49a3.08 3.08 0 0 0 3.01 2.45 3.08 3.08 0 0 0 3.01-2.45h3.49a1 1 0 0 0 1-1v-2.59a1 1 0 0 0-.33-.74zm-7.17 5.63c-.84 0-1.55-.55-1.81-1.3h3.62a1.92 1.92 0 0 1-1.81 1.3zm6.35-2.45h-12.7v-2.35l1.63-1.5c.24-.22.37-.53.37-.85v-3.41a4.51 4.51 0 0 1 3.92-4.57 4.35 4.35 0 0 1 4.78 4.33v3.65c0 .32.14.63.38.85l1.62 1.48v2.37z"></path></svg></button></div></div><div class="mb" id="li-post-page-navbar-upsell-button"><div class="cq r g"><div><a href="https://medium.com/membership?source=upgrade_membership---nav_full------------------------" class="cs ct q cu cv cw cx cy ba ck cz da db dc dd de df bi b bj bk bl bm dg dh di bx dj bd" rel="noopener">Upgrade</a></div></div></div><div class="n" aria-hidden="true"><div class="dk dl n o"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><img alt="Ayushverma" class="r dm dn do" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/0_fSKu5zWydc5B9tfM" width="32" height="32"></button></div></div></div></span></div></div></div></div></div><div class="dp r dq aq"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="dr bv n o"><div class="ds r bh"><a href="https://towardsdatascience.com/?source=post_page-----48c40021da4----------------------" rel="noopener"><div class="dt du r"><img alt="Towards Data Science" class="" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_mG6i4Bh_LgixUYXJgQpYsg@2x.png" width="100" height="36"></div></a></div><div class="dv r dw"><ul class="dx az dy bw dz n ea g eb ec ed"><li class="n o ee ef eg eh"><span class="bi ek el bk em en eo"><a href="https://towardsdatascience.com/data-science/home?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ep eq bd be er es" rel="noopener">Data Science</a></span></li><li class="n o ee ef eg eh"><span class="bi ek el bk em en eo"><a href="https://towardsdatascience.com/machine-learning/home?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ep eq bd be er es" rel="noopener">Machine Learning</a></span></li><li class="n o ee ef eg eh"><span class="bi ek el bk em en eo"><a href="https://towardsdatascience.com/programming/home?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ep eq bd be er es" rel="noopener">Programming</a></span></li><li class="n o ee ef eg eh"><span class="bi ek el bk em en eo"><a href="https://towardsdatascience.com/data-visualization/home?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ep eq bd be er es" rel="noopener">Visualization</a></span></li><li class="n o ee ef eg eh"><span class="bi ek el bk em en eo"><a href="https://towardsdatascience.com/artificial-intelligence/home?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ep eq bd be er es" rel="noopener">AI</a></span></li><li class="n o ee ef eg eh"><span class="bi ek el bk em en eo"><a href="https://towardsdatascience.com/video/home?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ep eq bd be er es" rel="noopener">Video</a></span></li><li class="n o ee ef eg eh"><span class="bi ek el bk em en eo"><a href="https://towardsdatascience.com/about-us/home?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ep eq bd be er es" rel="noopener">About</a></span></li><span class="ee ei ej"></span><li class="n o ee ef eg eh"><span class="bi ek el bk em en eo"><a href="https://towardsdatascience.com/contribute/home?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ep eq bd be er es" rel="noopener">Contribute</a></span></li></ul></div></div></div></div></div></div></nav><div class="et eu r ev ew"></div><article><section class="ex ey ez fa ai fb di r"></section><span class="r"></span><div><div class="s u fc fd fe ff"></div><section class="fg fh fi fj fk"><div class="n p"><div class="z ab ac ae af fl ah ai"><div><div id="a3c8" class="fm fn ct bj fo b fp fq fr fs ft fu fv fw fx fy fz"><h1 class="fo b fp ga fr gb ft gc fv gd fx ge ct">Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook</h1></div></div><h2 id="4ca6" class="gf fn bn bj bi ek gg gh gr gi gj gs gk gl gt gm gn gu go gp gv gq">Part 1: Defining the Environment, Finding the Optimal Policy with Value-Iteration and Introducing Q-Learning</h2><div class="gw"><div class="n gx gy gz ha"><div class="o n"><div><a href="https://towardsdatascience.com/@sterlingosborne?source=post_page-----48c40021da4----------------------" rel="noopener"><div class="cd hb hc"><div class="hd n he o p s hf hg hh hi hj ff"><svg width="57" height="57" viewBox="0 0 57 57"><path fill-rule="evenodd" clip-rule="evenodd" d="M28.5 1.2A27.45 27.45 0 0 0 4.06 15.82L3 15.27A28.65 28.65 0 0 1 28.5 0C39.64 0 49.29 6.2 54 15.27l-1.06.55A27.45 27.45 0 0 0 28.5 1.2zM4.06 41.18A27.45 27.45 0 0 0 28.5 55.8a27.45 27.45 0 0 0 24.44-14.62l1.06.55A28.65 28.65 0 0 1 28.5 57 28.65 28.65 0 0 1 3 41.73l1.06-.55z"></path></svg></div><img alt="Sterling Osborne, PhD Researcher" class="r dm hc hb" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/2_WgLcF6AYGqam8M3kLwBG6Q.jpeg" width="48" height="48"></div></a></div><div class="hk ai r"><div class="n"><div style="flex:1"><span class="bi b bj bk bl bm r ct q"><div class="hl n o hm"><span class="bi ek cb bk bv hn bu ho hp hq ct"><a href="https://towardsdatascience.com/@sterlingosborne?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener">Sterling Osborne, PhD Researcher</a></span><div class="hs r bh h"><button class="ht cu ar as hu bb bc hv ba df bi b bj hw el bm dg dh di bx dj bd">Follow</button></div></div></span></div></div><span class="bi b bj bk bl bm r bn bo"><span class="bi ek cb bk bv hn bu ho hp hq bn"><div><a class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener" href="https://towardsdatascience.com/reinforcement-learning-from-scratch-designing-and-solving-a-task-all-within-a-python-notebook-48c40021da4?source=post_page-----48c40021da4----------------------">Dec 19, 2018</a> <!-- -->·<!-- --> <!-- -->12<!-- --> min read</div></span></span></div></div><div class="n hx hy hz ia ib ic id ie y"><div class="n o"><div class="if r bh"><a href="https://medium.com/p/48c40021da4/share/twitter?source=post_actions_header---------------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></a></div><div class="if r bh"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="q"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="if r bh"><a href="https://medium.com/p/48c40021da4/share/facebook?source=post_actions_header---------------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></a></div><div class="ig r"><div><div class="ih"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="1" aria-labelledby="1"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div><div class="ii r am"><div class="bx" aria-hidden="true"><div class="bx" aria-hidden="true"><div class="r bh"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="-480.5 272.5 21 21" class="q"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></button></div></div></div></div></div></div></div></div><h2 id="c332" class="ij ik ct bj bi il im in io ip iq ir is it iu iv iw" data-selectable-paragraph="">Summary</h2><p id="78ed" class="ix jj ct bj iz b gg ja jk gi jb jl jc jd gt je jf gu jg jh gv ji fg" data-selectable-paragraph="">In this article, I will introduce a new project that attempts to help those learning Reinforcement Learning by fully defining and solving a simple task all within a Python notebook. The environment and basic methods will be explained within this article and all the code is published on Kaggle in the link below. In addition, I have created a “Meta” notebook that can be forked easily and only contains the defined environment for others to try, adapt and apply their own code to.</p><div class="jm jn jo jp jq jr"><a href="https://www.kaggle.com/osbornep/-reinforcement-learning-from-scratch-in-python" target="_blank" rel="noopener nofollow"><div class="js n bh"><div class="jt n ju p jv jw"><h2 class="bi il jx bk bv jy bu ho jz hq ct">Reinforcement Learning from Scratch in Python</h2><div class="ka r"><h3 class="bi ek cb bk bv jy bu ho jz hq bn">Beginner's Guide to Finding the Optimal Actions of a Defined Environment</h3></div><div class="kb r"><h4 class="bi ek el bk bv jy bu ho jz hq bn">www.kaggle.com</h4></div></div><div class="kc r"><div class="kd r ke kf kg kc kh ki kj"></div></div></div></a></div><h2 id="8e59" class="ij ik ct bj bi il im in io ip iq ir is it iu iv iw" data-selectable-paragraph="">Context</h2><p id="72de" class="ix jj ct bj iz b gg ja jk gi jb jl jc jd gt je jf gu jg jh gv ji fg" data-selectable-paragraph="">When I first started learning about Reinforcement Learning I went straight into replicating online guides and projects but found I was getting lost and confused. “Why do the results show this? What does this parameter do? What does the environment act in this way?” were all some of the questions I began asking myself. It wasn’t until I took a step back and started from the basics of first fully understanding how the probabilistic environment is defined and building up a small example that I could solve on paper that things began to make more sense. However, I found it hard to find environments that I could apply my knowledge on that didn’t need to be imported from external sources.</p><p id="3c99" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Therefore, I set myself a challenge:</p><p id="f865" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph=""><strong class="iz kp">Can I fully define and find the optimal actions for a task environment all self-contained within a Python notebook?</strong></p><p id="8c8d" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">By following my work I hope that that others may use this as a basic starting point for learning themselves.</p></div></div></section><hr class="kq ek kr ks by kt ku kv kw kx ky kz"><section class="fg fh fi fj fk"><div class="n p"><div class="z ab ac ae af fl ah ai"><h1 id="e13a" class="la ik ct bj bi il fp lb fr lc ld le lf lg lh li lj" data-selectable-paragraph="">Stage 1: Defining the Environment</h1><h2 id="e7a6" class="ij ik ct bj bi il im in io ip iq ir is it iu iv iw" data-selectable-paragraph="">The Task</h2><p id="6371" class="ix jj ct bj iz b gg ja jk gi jb jl jc jd gt je jf gu jg jh gv ji fg" data-selectable-paragraph="">Very simply, I want to know the best action in order to get a piece of paper into a bin (trash can) from any position in a room. I can throw the paper in any direction or move one step at a time.</p><p id="49c1" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Although simple to a human who can judge location of the bin by eyesight and have huge amounts of prior knowledge regarding the distance a robot has to learn from nothing.</p><p id="54ec" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">This defines the environment where the probability of a successful throw are calculated based on the direction in which the paper is thrown and the current distance from the bin.</p><p id="523d" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">For example, in the image below we have three people labelled A, B and C. A and B both throw in the correct direction but person A is closer than B and so will have a higher probability of landing the shot.</p><p id="df10" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Person C is closer than person B but throws in the completely wrong direction and so will have a very low probability of hitting the bin. This may seem illogical that person C would throw in this direction but, as we will show more later, an algorithm has to try a range of directions first to figure out where the successes are and will have no visual guide as to where the bin is.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa lk"><div class="lv r cd lw"><div class="lx ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_DnSXHxSk4Zn25YoOemRfJg.png" width="664" height="538" role="presentation"></div><img class="sy ux s t u ls ai mc" width="664" height="538" srcset="https://miro.medium.com/max/552/1*DnSXHxSk4Zn25YoOemRfJg.png 276w, https://miro.medium.com/max/1104/1*DnSXHxSk4Zn25YoOemRfJg.png 552w, https://miro.medium.com/max/1280/1*DnSXHxSk4Zn25YoOemRfJg.png 640w, https://miro.medium.com/max/1328/1*DnSXHxSk4Zn25YoOemRfJg.png 664w" sizes="664px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_DnSXHxSk4Zn25YoOemRfJg(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/1328/1*DnSXHxSk4Zn25YoOemRfJg.png" width="664" height="538" srcSet="https://miro.medium.com/max/552/1*DnSXHxSk4Zn25YoOemRfJg.png 276w, https://miro.medium.com/max/1104/1*DnSXHxSk4Zn25YoOemRfJg.png 552w, https://miro.medium.com/max/1280/1*DnSXHxSk4Zn25YoOemRfJg.png 640w, https://miro.medium.com/max/1328/1*DnSXHxSk4Zn25YoOemRfJg.png 664w" sizes="664px" role="presentation"/></noscript></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">Task Environment Example</figcaption></figure><p id="bc84" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">To create the environment in python, we convert the diagram into 2-d dimensions of x and y values and use bearing mathematics to calculate the angles thrown. We used normalised integer x and y values so that they must be bounded by -10 and 10.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa mg"><div class="lv r cd lw"><div class="mh ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_7GGpVQwKUV-pMZhNDboBjw.png" width="411" height="278" role="presentation"></div><img class="sy ux s t u ls ai mc" width="411" height="278" srcset="https://miro.medium.com/max/552/1*7GGpVQwKUV-pMZhNDboBjw.png 276w, https://miro.medium.com/max/822/1*7GGpVQwKUV-pMZhNDboBjw.png 411w" sizes="411px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_7GGpVQwKUV-pMZhNDboBjw(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/822/1*7GGpVQwKUV-pMZhNDboBjw.png" width="411" height="278" srcSet="https://miro.medium.com/max/552/1*7GGpVQwKUV-pMZhNDboBjw.png 276w, https://miro.medium.com/max/822/1*7GGpVQwKUV-pMZhNDboBjw.png 411w" sizes="411px" role="presentation"/></noscript></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">Environment Mapped to 2-d Space</figcaption></figure><h2 id="580d" class="ij ik ct bj bi il im in io ip iq ir is it iu iv iw" data-selectable-paragraph="">Environment Probabilities</h2><p id="c132" class="ix jj ct bj iz b gg ja jk gi jb jl jc jd gt je jf gu jg jh gv ji fg" data-selectable-paragraph="">The probability of a successful throw is relative to the distance and direction in which it is thrown. Therefore, we need to calculate two measures:</p><ul class=""><li id="51ba" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji mi mj mk" data-selectable-paragraph="">The distance the current position is from the bin</li><li id="1f71" class="ix jj ct bj iz b gg ml jk gi mm jl jc mn gt je mo gu jg mp gv ji mi mj mk" data-selectable-paragraph="">The difference between the angle at which the paper was thrown and the true direction to the bin</li></ul><p id="025a" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph=""><strong class="iz kp">Distance Measure<br></strong>As shown in the plot above, the position of person A in set to be (-5,-5). This is their current state and their distance from the bin can be calculated using the Euclidean distance measure:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="mr ms cd mt ai"><div class="ez fa mq"><div class="lv r cd lw"><div class="mu ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_DNR02ALVCLpPy10pvU3-Mg.png" width="444" height="119" role="presentation"></div><img class="sy ux s t u ls ai mc" width="444" height="119" srcset="https://miro.medium.com/max/552/1*DNR02ALVCLpPy10pvU3-Mg.png 276w, https://miro.medium.com/max/888/1*DNR02ALVCLpPy10pvU3-Mg.png 444w" sizes="444px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_DNR02ALVCLpPy10pvU3-Mg(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/888/1*DNR02ALVCLpPy10pvU3-Mg.png" width="444" height="119" srcSet="https://miro.medium.com/max/552/1*DNR02ALVCLpPy10pvU3-Mg.png 276w, https://miro.medium.com/max/888/1*DNR02ALVCLpPy10pvU3-Mg.png 444w" sizes="444px" role="presentation"/></noscript></div></div></div></div></figure><p id="46e0" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">For the final calculations, we normalise this and reverse the value so that a high score indicates that the person is closer to the target bin:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa mv"><div class="lv r cd lw"><div class="mw ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_-U1k4_DSR0EqNGYLgP1_qg.png" width="408" height="61" role="presentation"></div><img class="sy ux s t u ls ai mc" width="408" height="61" srcset="https://miro.medium.com/max/552/1*-U1k4_DSR0EqNGYLgP1_qg.png 276w, https://miro.medium.com/max/816/1*-U1k4_DSR0EqNGYLgP1_qg.png 408w" sizes="408px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_-U1k4_DSR0EqNGYLgP1_qg(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/816/1*-U1k4_DSR0EqNGYLgP1_qg.png" width="408" height="61" srcSet="https://miro.medium.com/max/552/1*-U1k4_DSR0EqNGYLgP1_qg.png 276w, https://miro.medium.com/max/816/1*-U1k4_DSR0EqNGYLgP1_qg.png 408w" sizes="408px" role="presentation"/></noscript></div></div></div></figure><p id="1e68" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Because we have fixed our 2-d dimensions between (-10, 10), the max possible distance the person could be is sqrt{(100) + (100)} = sqrt{200} from the bin. Therefore our distance score for person A is:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa mx"><div class="lv r cd lw"><div class="my ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_4Q5NHix_MJ6zqpsrEIyMwg.png" width="404" height="87" role="presentation"></div><img class="sy ux s t u ls ai mc" width="404" height="87" srcset="https://miro.medium.com/max/552/1*4Q5NHix_MJ6zqpsrEIyMwg.png 276w, https://miro.medium.com/max/808/1*4Q5NHix_MJ6zqpsrEIyMwg.png 404w" sizes="404px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_4Q5NHix_MJ6zqpsrEIyMwg(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/808/1*4Q5NHix_MJ6zqpsrEIyMwg.png" width="404" height="87" srcSet="https://miro.medium.com/max/552/1*4Q5NHix_MJ6zqpsrEIyMwg.png 276w, https://miro.medium.com/max/808/1*4Q5NHix_MJ6zqpsrEIyMwg.png 404w" sizes="404px" role="presentation"/></noscript></div></div></div></figure><p id="48d6" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph=""><strong class="iz kp">Direction Measure</strong></p><p id="e00b" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Person A then has a decision to make, do they move or do they throw in a chosen direction. For now, let imagine they choose to throw the paper, their <strong class="iz kp">first throw is at 50 degrees and the second is 60 degrees from due north</strong>. The direction of the bin from person A can be calculated by simple trigonometry:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="mr ms cd mt ai"><div class="ez fa mz"><div class="lv r cd lw"><div class="na ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_py4fdnvhJumhiOQKV6cHcg.png" width="412" height="60" role="presentation"></div><img class="sy ux s t u ls ai mc" width="412" height="60" srcset="https://miro.medium.com/max/552/1*py4fdnvhJumhiOQKV6cHcg.png 276w, https://miro.medium.com/max/824/1*py4fdnvhJumhiOQKV6cHcg.png 412w" sizes="412px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_py4fdnvhJumhiOQKV6cHcg(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/824/1*py4fdnvhJumhiOQKV6cHcg.png" width="412" height="60" srcSet="https://miro.medium.com/max/552/1*py4fdnvhJumhiOQKV6cHcg.png 276w, https://miro.medium.com/max/824/1*py4fdnvhJumhiOQKV6cHcg.png 412w" sizes="412px" role="presentation"/></noscript></div></div></div></div></figure><p id="f30b" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Therefore, the first throw is 5 degrees off the true direction and the second is 15 degrees.</p><p id="1037" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">When we consider that good throws are bounded by 45 degrees either side of the actual direction (i.e. not throwing the wrong way) then we can use the following to calculate how good this chosen direction is. Any direction beyond the 45 degree bounds will produce a negative value and be mapped to probability of 0:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa nb"><div class="lv r cd lw"><div class="nc ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_aq_h8R-DCFhtbcQEmmZRSw.png" width="496" height="172" role="presentation"></div><img class="sy ux s t u ls ai mc" width="496" height="172" srcset="https://miro.medium.com/max/552/1*aq_h8R-DCFhtbcQEmmZRSw.png 276w, https://miro.medium.com/max/992/1*aq_h8R-DCFhtbcQEmmZRSw.png 496w" sizes="496px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_aq_h8R-DCFhtbcQEmmZRSw(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/992/1*aq_h8R-DCFhtbcQEmmZRSw.png" width="496" height="172" srcSet="https://miro.medium.com/max/552/1*aq_h8R-DCFhtbcQEmmZRSw.png 276w, https://miro.medium.com/max/992/1*aq_h8R-DCFhtbcQEmmZRSw.png 496w" sizes="496px" role="presentation"/></noscript></div></div></div></figure><p id="46bc" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Both are fairly close but their first throw is more likely to hit the bin.</p><p id="f6e5" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph=""><strong class="iz kp">Probability Calculation</strong></p><p id="c40e" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">We therefore calculate our probability of a successful throw to be relative to both these measures:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa nd"><div class="lv r cd lw"><div class="ne ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_A060XDtIiAMlmJ4nEb9_KQ.png" width="469" height="182" role="presentation"></div><img class="sy ux s t u ls ai mc" width="469" height="182" srcset="https://miro.medium.com/max/552/1*A060XDtIiAMlmJ4nEb9_KQ.png 276w, https://miro.medium.com/max/938/1*A060XDtIiAMlmJ4nEb9_KQ.png 469w" sizes="469px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_A060XDtIiAMlmJ4nEb9_KQ(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/938/1*A060XDtIiAMlmJ4nEb9_KQ.png" width="469" height="182" srcSet="https://miro.medium.com/max/552/1*A060XDtIiAMlmJ4nEb9_KQ.png 276w, https://miro.medium.com/max/938/1*A060XDtIiAMlmJ4nEb9_KQ.png 469w" sizes="469px" role="presentation"/></noscript></div></div></div></figure><h2 id="ac1d" class="ij ik ct bj bi il im in io ip iq ir is it iu iv iw" data-selectable-paragraph="">Creating a Generalised Probability Function</h2><p id="6b14" class="ix jj ct bj iz b gg ja jk gi jb jl jc jd gt je jf gu jg jh gv ji fg" data-selectable-paragraph="">Although the previous calculations were fairly simple, some considerations need to be taken into account when we generalise these and begin to consider that the bin or current position are not fixed.</p><p id="0777" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">In our previous example, person A is south-west from the bin and therefore the angle was a simple calculation but if we applied the same to say a person placed north-east then this would be incorrect. Furthermore, because the bin can be placed anywhere we need to first find where the person is relative to this, not just the origin, and then used to to establish to angle calculation required.</p><p id="f4ad" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">This is summarised in the diagram below where we have generalised each of the trigonometric calculations based on the person’s relative position to the bin:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="mr ms cd mt ai"><div class="ez fa nf"><div class="lv r cd lw"><div class="ng ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_c45uGPJx-geJrjazU_1F-g.png" width="1285" height="819" role="presentation"></div><img class="sy ux s t u ls ai mc" width="1285" height="819" srcset="https://miro.medium.com/max/552/1*c45uGPJx-geJrjazU_1F-g.png 276w, https://miro.medium.com/max/1104/1*c45uGPJx-geJrjazU_1F-g.png 552w, https://miro.medium.com/max/1280/1*c45uGPJx-geJrjazU_1F-g.png 640w, https://miro.medium.com/max/1400/1*c45uGPJx-geJrjazU_1F-g.png 700w" sizes="700px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_c45uGPJx-geJrjazU_1F-g(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/2570/1*c45uGPJx-geJrjazU_1F-g.png" width="1285" height="819" srcSet="https://miro.medium.com/max/552/1*c45uGPJx-geJrjazU_1F-g.png 276w, https://miro.medium.com/max/1104/1*c45uGPJx-geJrjazU_1F-g.png 552w, https://miro.medium.com/max/1280/1*c45uGPJx-geJrjazU_1F-g.png 640w, https://miro.medium.com/max/1400/1*c45uGPJx-geJrjazU_1F-g.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">Angle Calculation Rules</figcaption></figure><p id="2669" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">With this diagram in mind, we create a function that calculates the probability of a throw’s success from only given position relative to the bin.</p><p id="2037" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">We then calculate the bearing from the person to the bin following the previous figure and calculate the score bounded within a +/- 45 degree window. Throws that are closest to the true bearing score higher whilst those further away score less, anything more than 45 degrees (or less than -45 degrees) are negative and then set to a zero probability.</p><p id="7d65" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Lastly, the overall probability is related to both the distance and direction given the current position as shown before.</p><p id="edc4" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph=""><strong class="iz kp">Note: I have chosen 45 degrees as the boundary but you may choose to change this window or could manually scale the probability calculation to weight the distance of direction measure differently.</strong></p><p id="185f" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">We re-calculate the previous examples and find the same results as expected.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="mr ms cd mt ai"><div class="ez fa nh"><div class="lv r cd lw"><div class="ni ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_Ak9zfkl4kGy8T2eDXDPtrw.png" width="715" height="286" role="presentation"></div><img class="sy ux s t u ls ai mc" width="715" height="286" srcset="https://miro.medium.com/max/552/1*Ak9zfkl4kGy8T2eDXDPtrw.png 276w, https://miro.medium.com/max/1104/1*Ak9zfkl4kGy8T2eDXDPtrw.png 552w, https://miro.medium.com/max/1280/1*Ak9zfkl4kGy8T2eDXDPtrw.png 640w, https://miro.medium.com/max/1400/1*Ak9zfkl4kGy8T2eDXDPtrw.png 700w" sizes="700px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_Ak9zfkl4kGy8T2eDXDPtrw(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/1430/1*Ak9zfkl4kGy8T2eDXDPtrw.png" width="715" height="286" srcSet="https://miro.medium.com/max/552/1*Ak9zfkl4kGy8T2eDXDPtrw.png 276w, https://miro.medium.com/max/1104/1*Ak9zfkl4kGy8T2eDXDPtrw.png 552w, https://miro.medium.com/max/1280/1*Ak9zfkl4kGy8T2eDXDPtrw.png 640w, https://miro.medium.com/max/1400/1*Ak9zfkl4kGy8T2eDXDPtrw.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div></figure><h2 id="3693" class="ij ik ct bj bi il im in io ip iq ir is it iu iv iw" data-selectable-paragraph="">Plotting Probabilities for Each State</h2><p id="3595" class="ix jj ct bj iz b gg ja jk gi jb jl jc jd gt je jf gu jg jh gv ji fg" data-selectable-paragraph="">Now that we have this as a function, we can easily calculate and plot the probabilities of all points in our 2-d grid for a fixed throwing direction.</p><p id="5469" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">The probabilities are defined by the angle we set in the previous function, currently this is 45 degrees but this can reduced or increased if desired and the results will change accordingly. We may also want to scale the probability differently for distances.</p><p id="6ced" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">For example, the probability when the paper is thrown at a 180 degree bearing (due South) for each x/y position is shown below.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa nj"><div class="lv r cd lw"><div class="nk ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_sG4BMmyPirJyozOUpYULuQ.png" width="397" height="279" role="presentation"></div><img class="sy ux s t u ls ai mc" width="397" height="279" srcset="https://miro.medium.com/max/552/1*sG4BMmyPirJyozOUpYULuQ.png 276w, https://miro.medium.com/max/794/1*sG4BMmyPirJyozOUpYULuQ.png 397w" sizes="397px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_sG4BMmyPirJyozOUpYULuQ(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/794/1*sG4BMmyPirJyozOUpYULuQ.png" width="397" height="279" srcSet="https://miro.medium.com/max/552/1*sG4BMmyPirJyozOUpYULuQ.png 276w, https://miro.medium.com/max/794/1*sG4BMmyPirJyozOUpYULuQ.png 397w" sizes="397px" role="presentation"/></noscript></div></div></div></figure><p id="a881" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph=""><strong class="iz kp">Animated Plot for All Throwing Directions</strong></p><p id="3ddf" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">To demonstrate this further, we can iterate through a number of throwing directions and create an interactive animation. The code becomes a little complex and you can always simply use the previous code chunk and change the “throw_direction ” parameter manually to explore different positions. However this helps explore the probabilities and can be found in the Kaggle notebook.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="mr ms cd mt ai"><div class="ez fa nl"><div class="lv r cd lw"><div class="nm ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_T5E6Nff0zLCCy-nwI7aXYQ.png" width="750" height="750" role="presentation"></div><img class="sy ux s t u ls ai mc" width="750" height="750" srcset="https://miro.medium.com/max/552/1*T5E6Nff0zLCCy-nwI7aXYQ.png 276w, https://miro.medium.com/max/1104/1*T5E6Nff0zLCCy-nwI7aXYQ.png 552w, https://miro.medium.com/max/1280/1*T5E6Nff0zLCCy-nwI7aXYQ.png 640w, https://miro.medium.com/max/1400/1*T5E6Nff0zLCCy-nwI7aXYQ.png 700w" sizes="700px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_T5E6Nff0zLCCy-nwI7aXYQ(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/1500/1*T5E6Nff0zLCCy-nwI7aXYQ.png" width="750" height="750" srcSet="https://miro.medium.com/max/552/1*T5E6Nff0zLCCy-nwI7aXYQ.png 276w, https://miro.medium.com/max/1104/1*T5E6Nff0zLCCy-nwI7aXYQ.png 552w, https://miro.medium.com/max/1280/1*T5E6Nff0zLCCy-nwI7aXYQ.png 640w, https://miro.medium.com/max/1400/1*T5E6Nff0zLCCy-nwI7aXYQ.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div></figure><div class="jm jn jo jp jq jr"><a href="https://www.kaggle.com/osbornep/rl-from-scratch-part-1-defining-the-environment" target="_blank" rel="noopener nofollow"><div class="js n bh"><div class="jt n ju p jv jw"><h2 class="bi il jx bk bv jy bu ho jz hq ct">RL from Scratch Part 1: Defining the Environment | Kaggle</h2><div class="ka r"><h3 class="bi ek cb bk bv jy bu ho jz hq bn">Edit description</h3></div><div class="kb r"><h4 class="bi ek el bk bv jy bu ho jz hq bn">www.kaggle.com</h4></div></div></div></a></div></div></div></section><hr class="kq ek kr ks by kt ku kv kw kx ky kz"><section class="fg fh fi fj fk"><div class="n p"><div class="z ab ac ae af fl ah ai"><h1 id="2a72" class="la ik ct bj bi il fp lb fr lc ld le lf lg lh li lj" data-selectable-paragraph="">Stage 2: Finding the Optimal Policy for Environment where the Probabilities are Known</h1><h2 id="2c94" class="ij ik ct bj bi il im in io ip iq ir is it iu iv iw" data-selectable-paragraph="">Model-based Methods</h2><p id="7774" class="ix jj ct bj iz b gg ja jk gi jb jl jc jd gt je jf gu jg jh gv ji fg" data-selectable-paragraph="">The aim is for us to find the optimal action in each state by either throwing or moving in a given direction. Because we have known probabilities, we can actually use model-based methods and will demonstrate this first and can use <strong class="iz kp">value-iteration</strong> to achieve this via the following formula:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa nn"><div class="lv r cd lw"><div class="no ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_-DkkELogkP_tb8AWaWZu9w.png" width="474" height="101" role="presentation"></div><img class="sy ux s t u ls ai mc" width="474" height="101" srcset="https://miro.medium.com/max/552/1*-DkkELogkP_tb8AWaWZu9w.png 276w, https://miro.medium.com/max/948/1*-DkkELogkP_tb8AWaWZu9w.png 474w" sizes="474px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_-DkkELogkP_tb8AWaWZu9w(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/948/1*-DkkELogkP_tb8AWaWZu9w.png" width="474" height="101" srcSet="https://miro.medium.com/max/552/1*-DkkELogkP_tb8AWaWZu9w.png 276w, https://miro.medium.com/max/948/1*-DkkELogkP_tb8AWaWZu9w.png 474w" sizes="474px" role="presentation"/></noscript></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">Value Iteration Update Rules</figcaption></figure><p id="7b2b" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Value iteration starts with an arbitrary function V0 and uses the following equations to get the functions for k+1 stages to go from the functions for k stages to go (<a href="https://artint.info/html/ArtInt_227.html" class="cg dj np nq nr ns" target="_blank" rel="noopener nofollow">https://artint.info/html/ArtInt_227.html</a>).</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa fl"><div class="lv r cd lw"><div class="nt ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_pTq2-fdmY_lOZSm_0-RzVg.png" width="680" height="363" role="presentation"></div><img class="sy ux s t u ls ai mc" width="680" height="363" srcset="https://miro.medium.com/max/552/1*pTq2-fdmY_lOZSm_0-RzVg.png 276w, https://miro.medium.com/max/1104/1*pTq2-fdmY_lOZSm_0-RzVg.png 552w, https://miro.medium.com/max/1280/1*pTq2-fdmY_lOZSm_0-RzVg.png 640w, https://miro.medium.com/max/1360/1*pTq2-fdmY_lOZSm_0-RzVg.png 680w" sizes="680px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_pTq2-fdmY_lOZSm_0-RzVg(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/1360/1*pTq2-fdmY_lOZSm_0-RzVg.png" width="680" height="363" srcSet="https://miro.medium.com/max/552/1*pTq2-fdmY_lOZSm_0-RzVg.png 276w, https://miro.medium.com/max/1104/1*pTq2-fdmY_lOZSm_0-RzVg.png 552w, https://miro.medium.com/max/1280/1*pTq2-fdmY_lOZSm_0-RzVg.png 640w, https://miro.medium.com/max/1360/1*pTq2-fdmY_lOZSm_0-RzVg.png 680w" sizes="680px" role="presentation"/></noscript></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">Initial Value of Each State</figcaption></figure><p id="b6ab" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">The calculation of MOVE actions are fairly simple because I have defined the probability of a movements success to be guaranteed (equal to 1). Therefore, the Q value of, for example, action (1,1) from state (-5,-5) is equal to:</p><p id="437e" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Q((-5,-5),MOVE(1,1)) = 1*( R((-5,-5),(1,1),(-4,-4))+ gamma*V(-4,-4)))</p><p id="2625" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">for now, the rewards are also all 0 therefore the value for this first calculation is simply:</p><p id="85c3" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Q((-5,-5),(1,1)) = 1*(0+gamma*0) = 0</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa nu"><div class="lv r cd lw"><div class="nv ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_C0iOu9WCw19UOC25M0HXHw.png" width="372" height="297" role="presentation"></div><img class="sy ux s t u ls ai mc" width="372" height="297" srcset="https://miro.medium.com/max/552/1*C0iOu9WCw19UOC25M0HXHw.png 276w, https://miro.medium.com/max/744/1*C0iOu9WCw19UOC25M0HXHw.png 372w" sizes="372px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_C0iOu9WCw19UOC25M0HXHw(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/744/1*C0iOu9WCw19UOC25M0HXHw.png" width="372" height="297" srcSet="https://miro.medium.com/max/552/1*C0iOu9WCw19UOC25M0HXHw.png 276w, https://miro.medium.com/max/744/1*C0iOu9WCw19UOC25M0HXHw.png 372w" sizes="372px" role="presentation"/></noscript></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">First Q update for Move Actions</figcaption></figure><p id="dd22" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">All move actions within the first update will be calculated similarly. Value is added to the system from successful throws. Therefore, we can calculate the Q value for a specific throw action. Previously, we found the probability of throw direction 50 degrees from (-5,-5) to be equal to 0.444. Therefore, the Q value for this action updates accordingly:</p><p id="9e79" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Q((-5,-5),THROW(50)) =</p><p id="3fbe" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">0.444*(R((-5,-5),(50),bin) + gamma*V(bin+))) +</p><p id="8cda" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">(1–0.444)*(R((-5,-5),(50),bin) + gamma*V(bin-)))</p><p id="2937" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Again the rewards are set to 0 and the positive value of the bin is 1 while the negative value of the bin is -1. Therefore we have:</p><p id="2503" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Q((-5,-5),THROW(50)) =</p><p id="d2c4" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">0.444*(0 + gamma*1) +</p><p id="db1d" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">(1–0.444)*(0 + gamma*1) = 0.3552–0.4448 = -0.0896</p><p id="7ca7" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">It becomes clear that although moving following the first update doesn’t change from the initialised values, throwing at 50 degrees is worse due to the distance and probability of missing.</p><p id="16a8" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Once each Q(s,a) is calculated for all states and actions, the value of each state, V(s), is updated as the maximum Q value for this state. The process is repeated back and forth until the results converge.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="mr ms cd mt ai"><div class="ez fa nw"><div class="lv r cd lw"><div class="nx ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_alDG2IwxdsDN7PMglgGnLA.png" width="1737" height="323" role="presentation"></div><img class="sy ux s t u ls ai mc" width="1737" height="323" srcset="https://miro.medium.com/max/552/1*alDG2IwxdsDN7PMglgGnLA.png 276w, https://miro.medium.com/max/1104/1*alDG2IwxdsDN7PMglgGnLA.png 552w, https://miro.medium.com/max/1280/1*alDG2IwxdsDN7PMglgGnLA.png 640w, https://miro.medium.com/max/1400/1*alDG2IwxdsDN7PMglgGnLA.png 700w" sizes="700px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_alDG2IwxdsDN7PMglgGnLA(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/3474/1*alDG2IwxdsDN7PMglgGnLA.png" width="1737" height="323" srcSet="https://miro.medium.com/max/552/1*alDG2IwxdsDN7PMglgGnLA.png 276w, https://miro.medium.com/max/1104/1*alDG2IwxdsDN7PMglgGnLA.png 552w, https://miro.medium.com/max/1280/1*alDG2IwxdsDN7PMglgGnLA.png 640w, https://miro.medium.com/max/1400/1*alDG2IwxdsDN7PMglgGnLA.png 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">Value-Iteration Update Procedure</figcaption></figure><p id="8358" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">There is not set limit for how many times this needs to be repeated and is dependent on the problem. Because our environment is so simple, it actually converges to the optimal policy within just 10 updates.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa ny"><div class="lv r cd lw"><div class="nz ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_IQb5OcbJWlnOFtOTHofEoQ.png" width="381" height="264" role="presentation"></div><img class="sy ux s t u ls ai mc" width="381" height="264" srcset="https://miro.medium.com/max/552/1*IQb5OcbJWlnOFtOTHofEoQ.png 276w, https://miro.medium.com/max/762/1*IQb5OcbJWlnOFtOTHofEoQ.png 381w" sizes="381px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_IQb5OcbJWlnOFtOTHofEoQ(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/762/1*IQb5OcbJWlnOFtOTHofEoQ.png" width="381" height="264" srcSet="https://miro.medium.com/max/552/1*IQb5OcbJWlnOFtOTHofEoQ.png 276w, https://miro.medium.com/max/762/1*IQb5OcbJWlnOFtOTHofEoQ.png 381w" sizes="381px" role="presentation"/></noscript></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">Convergence of Value-Iteration Updates</figcaption></figure><p id="e87a" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">We first show the best action based on throwing or moving by a simple coloured scatter shown below.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa mz"><div class="lv r cd lw"><div class="oa ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_aMqIvRj7bSPzcFhy_IK7uA.png" width="412" height="279" role="presentation"></div><img class="sy ux s t u ls ai mc" width="412" height="279" srcset="https://miro.medium.com/max/552/1*aMqIvRj7bSPzcFhy_IK7uA.png 276w, https://miro.medium.com/max/824/1*aMqIvRj7bSPzcFhy_IK7uA.png 412w" sizes="412px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_aMqIvRj7bSPzcFhy_IK7uA(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/824/1*aMqIvRj7bSPzcFhy_IK7uA.png" width="412" height="279" srcSet="https://miro.medium.com/max/552/1*aMqIvRj7bSPzcFhy_IK7uA.png 276w, https://miro.medium.com/max/824/1*aMqIvRj7bSPzcFhy_IK7uA.png 412w" sizes="412px" role="presentation"/></noscript></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">Optimal Policy Plot v1</figcaption></figure><p id="8074" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph=""><strong class="iz kp">Improving Visualisation of Optimal Policy</strong></p><p id="0bba" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Although the chart shows whether the optimal action is either a throw or move it doesn’t show us which direction these are in. Therefore, we will map each optimal action to a vector of u and v and use these to create a quiver plot (<a href="https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.quiver.html" class="cg dj np nq nr ns" target="_blank" rel="noopener nofollow">https://matplotlib.org/api/_as_gen/matplotlib.axes.Axes.quiver.html</a>).</p><p id="3d23" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">We define the scale of the arrows and use this to define the horizontal component labelled u. For movement actions, we simply multiply the movement in the x direction by this factor and for the throw direction we either move 1 unit left or right (accounting for no horizontal movement for 0 or 180 degrees and no vertical movement at 90 or 270 degrees).</p><p id="8588" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">The horizontal component is then used to calculate the vertical component with some basic trigonometry where we again account for certain angles that would cause errors in the calculations.</p><p id="c2ba" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">We see that some states have multiple best actions. Those directly north, east, south of west can move in multiple directions whereas the states (1,1), (1,-1),(-1,-1) and (-1,1) can either move or throw towards the bin.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa ob"><div class="lv r cd lw"><div class="oc ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_wYrRHhXVJknC9FHj7XTdZw.png" width="627" height="605" role="presentation"></div><img class="sy ux s t u ls ai mc" width="627" height="605" srcset="https://miro.medium.com/max/552/1*wYrRHhXVJknC9FHj7XTdZw.png 276w, https://miro.medium.com/max/1104/1*wYrRHhXVJknC9FHj7XTdZw.png 552w, https://miro.medium.com/max/1254/1*wYrRHhXVJknC9FHj7XTdZw.png 627w" sizes="627px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_wYrRHhXVJknC9FHj7XTdZw(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/1254/1*wYrRHhXVJknC9FHj7XTdZw.png" width="627" height="605" srcSet="https://miro.medium.com/max/552/1*wYrRHhXVJknC9FHj7XTdZw.png 276w, https://miro.medium.com/max/1104/1*wYrRHhXVJknC9FHj7XTdZw.png 552w, https://miro.medium.com/max/1254/1*wYrRHhXVJknC9FHj7XTdZw.png 627w" sizes="627px" role="presentation"/></noscript></div></div></div></figure><p id="9fb0" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Lastly, I decided to show the change of the optimal policy over each update by exporting each plot and passing into a small animation.</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="mr ms cd mt ai"><div class="ez fa od"><div class="lv r cd lw"><div class="nm ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_hrzESilcBh6DFTMGLc7JNQ.gif" width="720" height="720" role="presentation"></div><img class="sy ux s t u ls ai mc" width="720" height="720" srcset="https://miro.medium.com/max/552/1*hrzESilcBh6DFTMGLc7JNQ.gif 276w, https://miro.medium.com/max/1104/1*hrzESilcBh6DFTMGLc7JNQ.gif 552w, https://miro.medium.com/max/1280/1*hrzESilcBh6DFTMGLc7JNQ.gif 640w, https://miro.medium.com/max/1400/1*hrzESilcBh6DFTMGLc7JNQ.gif 700w" sizes="700px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_hrzESilcBh6DFTMGLc7JNQ(1).gif"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/1440/1*hrzESilcBh6DFTMGLc7JNQ.gif" width="720" height="720" srcSet="https://miro.medium.com/max/552/1*hrzESilcBh6DFTMGLc7JNQ.gif 276w, https://miro.medium.com/max/1104/1*hrzESilcBh6DFTMGLc7JNQ.gif 552w, https://miro.medium.com/max/1280/1*hrzESilcBh6DFTMGLc7JNQ.gif 640w, https://miro.medium.com/max/1400/1*hrzESilcBh6DFTMGLc7JNQ.gif 700w" sizes="700px" role="presentation"/></noscript></div></div></div></div></figure></div></div></section><hr class="kq ek kr ks by kt ku kv kw kx ky kz"><section class="fg fh fi fj fk"><div class="n p"><div class="z ab ac ae af fl ah ai"><h1 id="2f7f" class="la ik ct bj bi il fp lb fr lc ld le lf lg lh li lj" data-selectable-paragraph="">Stage 3: Finding the Optimal Policy with Reinforcement Learning where the Probabilities are hidden</h1><h2 id="87b1" class="ij ik ct bj bi il im in io ip iq ir is it iu iv iw" data-selectable-paragraph="">Q-Learning Algorithm</h2><p id="70d3" class="ix jj ct bj iz b gg ja jk gi jb jl jc jd gt je jf gu jg jh gv ji fg" data-selectable-paragraph="">We will now imagine that the probabilities are unknown to the person and therefore experience is needed to find the optimal actions.</p><p id="0499" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">First, let’s try to find the optimal action if the person starts in a fixed position and the bin is fixed to (0,0) as before.</p><p id="308b" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">We will be applying Q-learning and initialise all state-action pairs with a value of 0 and use the update rule:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa oe"><div class="lv r cd lw"><div class="of ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_PxiAVctAXhM5Mm19PoLZpw.png" width="439" height="51" role="presentation"></div><img class="sy ux s t u ls ai mc" width="439" height="51" srcset="https://miro.medium.com/max/552/1*PxiAVctAXhM5Mm19PoLZpw.png 276w, https://miro.medium.com/max/878/1*PxiAVctAXhM5Mm19PoLZpw.png 439w" sizes="439px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_PxiAVctAXhM5Mm19PoLZpw(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/878/1*PxiAVctAXhM5Mm19PoLZpw.png" width="439" height="51" srcSet="https://miro.medium.com/max/552/1*PxiAVctAXhM5Mm19PoLZpw.png 276w, https://miro.medium.com/max/878/1*PxiAVctAXhM5Mm19PoLZpw.png 439w" sizes="439px" role="presentation"/></noscript></div></div></div><figcaption class="md ku fb ez fa me mf bi ek cb bk bn" data-selectable-paragraph="">Q learning Update Rule</figcaption></figure><p id="3183" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">We give the algorithm the choice to throw in any 360 degree direction (to a whole degree) or to move to any surrounding position of the current one. There are therefore 8 places it can move: north, north-east, east, etc.</p><p id="148e" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">When it chooses to throw the paper, it will either receive a positive reward of +1 or a negative of -1 depending on whether it hits the bin or not and the episode ends.</p><p id="7f45" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">It will need to establish by a number of trial and error attempts where the bin is located and then whether it is better to move first or throw from the current position.</p><p id="63d5" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph=""><strong class="iz kp">Q-Learning Pseudo-code</strong></p><p id="162f" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">First, as before, we initialise the Q-table with arbitrary values of 0.</p><p id="1e6c" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">For now, the start of the episode’s position will be fixed to one state and we also introduce a cap on the number of actions in each episode so that it doesn’t accidentally keep going endlessly.</p><p id="ed01" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Each episode ends naturally if the paper is thrown, the action the algorithm performs is decided by the epsilon-greedy action selection procedure whereby the action is selected randomly with probability epsilon and greedily (current max) otherwise. To balance the random selection slightly between move or throwing actions (as there are only 8 move actions but 360 throwing actions) I decided to give the algorithm a 50/50 chance of moving or throwing then will subsequently pick an action randomly from these.</p><p id="7ff1" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">As before, the random movement action cannot go beyond the boundary of the room and once found we update the current Q(s,a) dependent upon the max Q(s’,a) for all possible subsequent actions. For example, if we move from -9,-9 to -8,-8, Q( (-9,-9), (1,1) ) will update according the the maximum of Q( (-8,-8), a ) for all possible actions including the throwing ones.</p><p id="3220" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">If the algorithms throws the paper, the probability of success is calculated for this throw and we simulate whether in this case it was successful and receives a positive terminal reward or was unsuccessful and receives a negative terminal reward.</p><p id="4769" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">The algorithm continues to update the Q values for each state-action pair until the results converge.</p><p id="c2a1" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph=""><strong class="iz kp">We will analyse the effect of varying parameters in the next post but for now simply introduce some arbitrary parameter choices of:</strong><br> — num_episodes = 100<br> — alpha = 0.5<br> — gamma = 0.5<br> — epsilon = 0.2<br> — max_actions = 1000<br> — pos_terminal_reward = 1<br> — neg_terminal_reward = -1</p><p id="20bb" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Running the algorithm with these parameters 10 times we produce the following ‘optimal’ action for state -5,-5:</p><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa og"><div class="lv r cd lw"><div class="oh ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_pXjvkz7Pl94yx_tyNUICQg.png" width="371" height="627" role="presentation"></div><img class="sy ux s t u ls ai mc" width="371" height="627" srcset="https://miro.medium.com/max/552/1*pXjvkz7Pl94yx_tyNUICQg.png 276w, https://miro.medium.com/max/742/1*pXjvkz7Pl94yx_tyNUICQg.png 371w" sizes="371px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_pXjvkz7Pl94yx_tyNUICQg(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/742/1*pXjvkz7Pl94yx_tyNUICQg.png" width="371" height="627" srcSet="https://miro.medium.com/max/552/1*pXjvkz7Pl94yx_tyNUICQg.png 276w, https://miro.medium.com/max/742/1*pXjvkz7Pl94yx_tyNUICQg.png 371w" sizes="371px" role="presentation"/></noscript></div></div></div></figure><figure class="ll lm ln lo lp lq ez fa paragraph-image"><div class="ez fa oi"><div class="lv r cd lw"><div class="oj ly r"><div class="cc lr s t u ls ai bv lt lu"><img class="s t u ls ai lz ma an uz" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_DSW1rqJ2m4QKFikX0HLABg.png" width="394" height="278" role="presentation"></div><img class="sy ux s t u ls ai mc" width="394" height="278" srcset="https://miro.medium.com/max/552/1*DSW1rqJ2m4QKFikX0HLABg.png 276w, https://miro.medium.com/max/788/1*DSW1rqJ2m4QKFikX0HLABg.png 394w" sizes="394px" role="presentation" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_DSW1rqJ2m4QKFikX0HLABg(1).png"><noscript><img class="s t u ls ai" src="https://miro.medium.com/max/788/1*DSW1rqJ2m4QKFikX0HLABg.png" width="394" height="278" srcSet="https://miro.medium.com/max/552/1*DSW1rqJ2m4QKFikX0HLABg.png 276w, https://miro.medium.com/max/788/1*DSW1rqJ2m4QKFikX0HLABg.png 394w" sizes="394px" role="presentation"/></noscript></div></div></div></figure><p id="c34f" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Clearly these are not aligned which heavily suggests the actions are not in fact optimal. Therefore, we need to consider how the parameters we have chosen effect the output and what can be done to improve the results.</p><h1 id="54fa" class="la ik ct bj bi il fp ok fr ol ld om lf on lh oo lj" data-selectable-paragraph="">Conclusion</h1><p id="5d35" class="ix jj ct bj iz b gg ja jk gi jb jl jc jd gt je jf gu jg jh gv ji fg" data-selectable-paragraph="">We have introduced an environment from scratch in Python and found the optimal policy. Furthermore, I have begun to introduce the method for finding the optimal policy with Q-learning.</p><p id="9b59" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">I will continue this in a follow up post and improve these initial results by varying the parameters. For now, I hope this demonstrates enough for you to begin trying their own algorithms on this example.</p><p id="00cc" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">If you have any questions, please feel free to comment below or on the Kaggle pages.</p><p id="ebc6" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Thanks</p><p id="b4ee" class="ix jj ct bj iz b gg kk jk gi kl jl jc km gt je kn gu jg ko gv ji fg" data-selectable-paragraph="">Phil</p></div></div></section></div></article><div class="sy ff op oq ai ow ou ox" data-test-id="post-sidebar"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="oy n ju"><div class="uy"><div class="oz pa r"><a href="https://towardsdatascience.com/?source=post_sidebar--------------------------post_sidebar-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener"><h2 class="bi il jx bk ct">Towards Data Science</h2></a><div class="pb pc r"><h4 class="bi ek cb bk bv pd bu ho pe hq bn">A Medium publication sharing concepts, ideas, and codes.</h4></div><div class="bx" aria-hidden="true"><button class="cs cu ar as hu bb bc hv ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div><div class="pf pg ph n"><div class="n o"><div class="r cd pi pj pk pl pm"><div class=""><button class="ay pn po pp pq pr ps pt q pu pv"><svg width="29" height="29"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r pw px py pz qa qb qc"><div class="qd"><h4 class="bi ek cb bk bn"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl">238 </button></h4></div></div></div></div><div class="pg r"></div><div><div class="ih"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="2" aria-labelledby="2"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div><div class="sy uy op oq or hi os ot ou ov"></div><div><div class="qe lq n ju p"><div class="n p"><div class="z ab ac ae af fl ah ai"><div class="n qf"></div><div class="n o qf"></div><div class="qg r"><ul class="ay az"><li class="bx dx ig qh"><a href="https://towardsdatascience.com/tagged/machine-learning" class="qi qj dj bn r qk ql a b el">Machine Learning</a></li><li class="bx dx ig qh"><a href="https://towardsdatascience.com/tagged/data-science" class="qi qj dj bn r qk ql a b el">Data Science</a></li><li class="bx dx ig qh"><a href="https://towardsdatascience.com/tagged/reinforcement-learning" class="qi qj dj bn r qk ql a b el">Reinforcement Learning</a></li><li class="bx dx ig qh"><a href="https://towardsdatascience.com/tagged/learning" class="qi qj dj bn r qk ql a b el">Learning</a></li><li class="bx dx ig qh"><a href="https://towardsdatascience.com/tagged/guides-and-tutorials" class="qi qj dj bn r qk ql a b el">Guides And Tutorials</a></li></ul></div><div class="qm n gx y"><div class="n he"><div class="qn r"><div class="n o"><div class="r cd qo qp qq qr qs"><div class=""><div class="c qt dm n o qu cd qv qw qx qy qz ra rb rc rd re rf rg rh ri"><button class="ay pn po pp pq pr rj pt o mc dm n p rk u ls s t ai q pu pv rl"><svg width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></button></div></div></div><div class="r pw px py pz qa qb qc"><div class="cd rm qd"><h4 class="bi ek cb bk ct"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl">238 claps</button></h4></div></div></div></div><div class="r rn ro rp rq rr"></div></div><div class="n o"><div class="if r bh"><a href="https://medium.com/p/48c40021da4/share/twitter?source=post_actions_footer---------------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></a></div><div class="if r bh"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="q"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="if r bh"><a href="https://medium.com/p/48c40021da4/share/facebook?source=post_actions_footer---------------------------" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></a></div><div class="rs r bh"><div><div class="ih"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="3" aria-labelledby="3"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div><div class="bx" aria-hidden="true"><div class="bx" aria-hidden="true"><div class="r bh"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="-480.5 272.5 21 21" class="q"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></button></div></div></div></div></div><div class="rt ru rv qg r rw y"><div class="r g"><div class="rx ry r cd"><span class="r rz al sa"><div class="r s sb sc"><a href="https://towardsdatascience.com/@sterlingosborne?source=follow_footer--------------------------follow_footer-" rel="noopener"><div class="cd sd ed"><div class="hd n he o p s hf hg hh hi hj ff"><svg width="91" height="91" viewBox="0 0 91 91"><path fill-rule="evenodd" clip-rule="evenodd" d="M45.5 1.4c-17.14 0-32 9.95-39.25 24.5L5 25.28C12.47 10.28 27.8 0 45.5 0S78.53 10.29 86 25.28l-1.25.62C77.5 11.35 62.65 1.4 45.5 1.4zM6.25 65.1c7.25 14.55 22.1 24.5 39.25 24.5 17.14 0 32-9.95 39.25-24.5l1.25.62C78.53 80.72 63.2 91 45.5 91S12.47 80.71 5 65.72l1.25-.62z"></path></svg></div><img alt="Sterling Osborne, PhD Researcher" class="r dm ed sd" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/2_WgLcF6AYGqam8M3kLwBG6Q(1).jpeg" width="80" height="80"></div></a></div><span class="r"><div class="se r sf"><p class="bi ek el bk bn en sg">Written by</p></div><div class="se sh n sf"><div class="ai n o gx"><h2 class="bi il kr si ct"><a href="https://towardsdatascience.com/@sterlingosborne?source=follow_footer--------------------------follow_footer-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener">Sterling Osborne, PhD Researcher</a></h2><div class="r g"><button class="cs cu ar as hu bb bc hv ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div></div></span></span><div class="se sj r sf aq"><div class="sk r"><h4 class="bi ek jx sl bn">PhD Research Student in Artificial Intelligence at the University of Manchester (UK).</h4></div><div class="ap sm aq"><button class="cs cu ar as hu bb bc hv ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div></div><div class="rt r"></div><div class="rx ry r cd"><span class="r rz al sa"><div class="r s sb sc"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-" rel="noopener"><img alt="Towards Data Science" class="df sd ed" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_hVxgUA6kP-PgL5TJjuyePg.png" width="80" height="80"></a></div><span class="r"><div class="se sh n sf"><div class="ai n o gx"><h2 class="bi il kr si ct"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener">Towards Data Science</a></h2><div class="r g"><div class="bx" aria-hidden="true"><button class="cs cu ar as hu bb bc hv ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div></div></div></span></span><div class="se sn r sf aq"><div class="sk r"><h4 class="bi ek jx sl bn">A Medium publication sharing concepts, ideas, and codes.</h4></div><div class="ap sm aq"><div class="bx" aria-hidden="true"><button class="cs cu ar as hu bb bc hv ba df bi b bj bk bl bm dg dh di bx dj bd">Follow</button></div></div></div></div></div><div class="ap aq"><div class="so r"><div class="n he"><div class="sp r"><a href="https://towardsdatascience.com/@sterlingosborne?source=follow_footer--------------------------follow_footer-" rel="noopener"><div class="cd sq sr"><div class="hd n he o p s hf hg hh hi hj ff"><svg width="49" height="49" viewBox="0 0 49 49"><path fill-rule="evenodd" clip-rule="evenodd" d="M24.5 1.1c-9.39 0-17.53 5.55-21.51 13.66L2 14.28C6.15 5.82 14.66 0 24.5 0S42.85 5.82 47 14.28l-.99.48C42.03 6.65 33.9 1.1 24.5 1.1zM2.99 34.24C6.97 42.35 15.1 47.9 24.5 47.9c9.39 0 17.53-5.55 21.51-13.66l.99.48C42.85 43.18 34.34 49 24.5 49S6.15 43.18 2 34.72l.99-.48z"></path></svg></div><img alt="Sterling Osborne, PhD Researcher" class="r dm sr sq" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/2_WgLcF6AYGqam8M3kLwBG6Q(2).jpeg" width="40" height="40"></div></a></div><div class="hk r"><p class="bi ek ss st bn en sg">Written by</p><div class="n he"><h2 class="bi il jx bk ct"><a href="https://towardsdatascience.com/@sterlingosborne?source=follow_footer--------------------------follow_footer-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener">Sterling Osborne, PhD Researcher</a></h2><div class="hk r"><button class="ht cu ar as hu bb bc hv ba df bi b bj hw el bm dg dh di bx dj bd">Follow</button></div></div><div class="su r"><h4 class="bi ek cb bk bn">PhD Research Student in Artificial Intelligence at the University of Manchester (UK).</h4></div></div></div><div class="so r"><div class="n he"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-" rel="noopener"><img alt="Towards Data Science" class="df sq sr" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_hVxgUA6kP-PgL5TJjuyePg(1).png" width="40" height="40"></a><div class="hk r"><div class="n he"><h2 class="bi il jx bk ct"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener">Towards Data Science</a></h2><div class="hk r"><div class="bx" aria-hidden="true"><button class="ht cu ar as hu bb bc hv ba df bi b bj hw el bm dg dh di bx dj bd">Follow</button></div></div></div><div class="su r"><h4 class="bi ek cb bk bn">A Medium publication sharing concepts, ideas, and codes.</h4></div></div></div></div></div></div></div><div class="sv ru r rw sw y"><a href="https://medium.com/p/48c40021da4/responses/show?source=follow_footer--------------------------follow_footer-" class="cg ch at au av aw ax ay az ba ci cj bd be ck cl" rel="noopener"><span class="sx sy pq"><div class="sz ta df r ku aq"><span class="ar">See responses (2)</span></div></span></a></div></div></div><div class="tb r tc y"><div class="n p"><div class="z ab ac ae af ag ah ai"><div class="va r vb"><div class="un pa rx r"><h2 class="bi il vc vd ct">More From Medium</h2></div><div class="ea n he qf ve vf vg vh vi vj vk vl vm vn vo vp vq vr vs"><div class="vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn"><div class="ai ls"><div class="r wo"><div class="wp wq ve vf vg wr ws vh vi vj wt wu vk vl vm wv ww vn vo vp wx wy vq vr vs n qf"><div class="vt vu vv vw vx vy wz xa wb wc xb xc wf wg xd xe wj wk xf xg wn"><div class="xh r xi f"><h4 class="bi ek cb bk bn">More from Towards Data Science</h4></div><div class="br r xj vb"><a class="cg ch at au av aw ax ay az ba ci cj bd be ck cl r" rel="noopener" href="https://towardsdatascience.com/coding-mistakes-i-made-as-a-junior-developer-e151dd3b3c7d?source=post_recirc---------0------------------"></a></div></div><div class="vt vu vv vw vx vy wz xa wb wc xb xc wf wg xd xe wj wk xf xg wn"><div class="br r"><div class="xk ap h xl"><h4 class="bi ek cb bk bn">More from Towards Data Science</h4></div><a rel="noopener" href="https://towardsdatascience.com/coding-mistakes-i-made-as-a-junior-developer-e151dd3b3c7d?source=post_recirc---------0------------------"><h3 class="ct q fo xm bj xn xo xp">Coding Mistakes I Made As A Junior Developer</h3></a></div><div class="n o gx"><div class="cm r dw"><div class="o n"><div></div><div class="ai r"><div class="n"><div style="flex: 1 1 0%;"><span class="bi b bj bk bl bm r ct q"><div class="et n o hm"><span class="bi ek cb bk bv hn bu ho hp hq ct"><a href="https://towardsdatascience.com/@chris.the.data.scientist?source=post_recirc---------0------------------" class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener">Chris</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------0------------------" class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener">Towards Data Science</a></span></span></div></span></div></div><span class="bi b bj bk bl bm r bn bo"><span class="bi ek cb bk bv hn bu ho hp hq bn"><div><a class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener" href="https://towardsdatascience.com/coding-mistakes-i-made-as-a-junior-developer-e151dd3b3c7d?source=post_recirc---------0------------------">May 22</a> · 4 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="n o"><div class="n o"><div class="r cd pi pj pk pl pm"><div class=""><button class="ay pn po pp pq pr ps uw q pu pv"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r pw px py pz qa qb qc"><div class="qd"><h4 class="bi ek cb bk bn">1.5K</h4></div></div></div><div class="xq hk cm ee xr r"></div><div class="ih"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="25" aria-labelledby="25"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div><div class="vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn"><div class="ai ls"><div class="r wo"><div class="wp wq ve vf vg wr ws vh vi vj wt wu vk vl vm wv ww vn vo vp wx wy vq vr vs n qf"><div class="vt vu vv vw vx vy wz xa wb wc xb xc wf wg xd xe wj wk xf xg wn"><div class="xh r xi f"><h4 class="bi ek cb bk bn">More from Towards Data Science</h4></div><div class="br r xj vb"><a class="cg ch at au av aw ax ay az ba ci cj bd be ck cl r" rel="noopener" href="https://towardsdatascience.com/sorry-online-courses-wont-make-you-a-data-scientist-8639d5f00889?source=post_recirc---------1------------------"></a></div></div><div class="vt vu vv vw vx vy wz xa wb wc xb xc wf wg xd xe wj wk xf xg wn"><div class="br r"><div class="xk ap h xl"><h4 class="bi ek cb bk bn">More from Towards Data Science</h4></div><a rel="noopener" href="https://towardsdatascience.com/sorry-online-courses-wont-make-you-a-data-scientist-8639d5f00889?source=post_recirc---------1------------------"><h3 class="ct q fo xm bj xn xo xp">Sorry, Online Courses Won’t Make you a Data Scientist</h3></a></div><div class="n o gx"><div class="cm r dw"><div class="o n"><div></div><div class="ai r"><div class="n"><div style="flex: 1 1 0%;"><span class="bi b bj bk bl bm r ct q"><div class="et n o hm"><span class="bi ek cb bk bv hn bu ho hp hq ct"><a href="https://towardsdatascience.com/@yadramshankar?source=post_recirc---------1------------------" class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener">Ramshankar Yadhunath</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------1------------------" class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener">Towards Data Science</a></span></span></div></span></div></div><span class="bi b bj bk bl bm r bn bo"><span class="bi ek cb bk bv hn bu ho hp hq bn"><div><a class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener" href="https://towardsdatascience.com/sorry-online-courses-wont-make-you-a-data-scientist-8639d5f00889?source=post_recirc---------1------------------">May 14</a> · 8 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="n o"><div class="n o"><div class="r cd pi pj pk pl pm"><div class=""><button class="ay pn po pp pq pr ps uw q pu pv"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r pw px py pz qa qb qc"><div class="qd"><h4 class="bi ek cb bk bn">4.1K</h4></div></div></div><div class="xq hk cm ee xr r"></div><div class="ih"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="26" aria-labelledby="26"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div><div class="vt vu vv vw vx vy vz wa wb wc wd we wf wg wh wi wj wk wl wm wn"><div class="ai ls"><div class="r wo"><div class="wp wq ve vf vg wr ws vh vi vj wt wu vk vl vm wv ww vn vo vp wx wy vq vr vs n qf"><div class="vt vu vv vw vx vy wz xa wb wc xb xc wf wg xd xe wj wk xf xg wn"><div class="xh r xi f"><h4 class="bi ek cb bk bn">More from Towards Data Science</h4></div><div class="br r xj vb"><a class="cg ch at au av aw ax ay az ba ci cj bd be ck cl r" rel="noopener" href="https://towardsdatascience.com/lesser-known-python-features-f87af511887?source=post_recirc---------2------------------"></a></div></div><div class="vt vu vv vw vx vy wz xa wb wc xb xc wf wg xd xe wj wk xf xg wn"><div class="br r"><div class="xk ap h xl"><h4 class="bi ek cb bk bn">More from Towards Data Science</h4></div><a rel="noopener" href="https://towardsdatascience.com/lesser-known-python-features-f87af511887?source=post_recirc---------2------------------"><h3 class="ct q fo xm bj xn xo xp">Lesser known Python Features</h3></a></div><div class="n o gx"><div class="cm r dw"><div class="o n"><div></div><div class="ai r"><div class="n"><div style="flex: 1 1 0%;"><span class="bi b bj bk bl bm r ct q"><div class="et n o hm"><span class="bi ek cb bk bv hn bu ho hp hq ct"><a href="https://towardsdatascience.com/@jamescalam?source=post_recirc---------2------------------" class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener">James Briggs</a><span> in <a href="https://towardsdatascience.com/?source=post_recirc---------2------------------" class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener">Towards Data Science</a></span></span></div></span></div></div><span class="bi b bj bk bl bm r bn bo"><span class="bi ek cb bk bv hn bu ho hp hq bn"><div><a class="cg ch at au av aw ax ay az ba hr bd be ck cl" rel="noopener" href="https://towardsdatascience.com/lesser-known-python-features-f87af511887?source=post_recirc---------2------------------">May 23</a> · 4 min read<span style="padding-left: 4px;"><svg class="star-15px_svg__svgIcon-use" width="15" height="15" viewBox="0 0 15 15" style="margin-top: -2px;"><path d="M7.44 2.32c.03-.1.09-.1.12 0l1.2 3.53a.29.29 0 0 0 .26.2h3.88c.11 0 .13.04.04.1L9.8 8.33a.27.27 0 0 0-.1.29l1.2 3.53c.03.1-.01.13-.1.07l-3.14-2.18a.3.3 0 0 0-.32 0L4.2 12.22c-.1.06-.14.03-.1-.07l1.2-3.53a.27.27 0 0 0-.1-.3L2.06 6.16c-.1-.06-.07-.12.03-.12h3.89a.29.29 0 0 0 .26-.19l1.2-3.52z"></path></svg></span></div></span></span></div></div></div><div class="n o"><div class="n o"><div class="r cd pi pj pk pl pm"><div class=""><button class="ay pn po pp pq pr ps uw q pu pv"><svg width="25" height="25" viewBox="0 0 25 25"><g fill-rule="evenodd"><path d="M11.74 0l.76 2.97.76-2.97zM14.81 3.78l1.84-2.56-1.42-.47zM8.38 1.22l1.84 2.56L9.8.75zM20.38 21.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M7.1 21.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L4.1 14.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L4.4 10.26 3.22 9.08a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L9.96 13a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L6.43 8.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L18.63 14c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM11 5.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 21 22.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="r pw px py pz qa qb qc"><div class="qd"><h4 class="bi ek cb bk bn">869</h4></div></div></div><div class="xq hk cm ee xr r"></div><div class="ih"><div><div class="bx" role="tooltip" aria-hidden="true" aria-describedby="27" aria-labelledby="27"><button class="cg ch at au av aw ax ay az ba ci cj bd be ck cl"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div><div class="td r te tf"><section class="ez fa ai di r tg th ti tj tk tl tm tn to tp tq tr ts tt tu"><div class="tv tw rx n gx g"><div class="tx n gx"><div class="ty r tz"><div class="ua r"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ub uc bd be ud ue" rel="noopener"><h4 class="uf ug uh bi il bj sl ui uj r">Discover <!-- -->Medium</h4></a></div><span class="bi b bj bk bl bm r uk ul">Welcome to a place where words matter. On <!-- -->Medium<!-- -->, smart voices and original ideas take center stage - with no ads in sight.<!-- --> <a href="https://medium.com/about?autoplay=1&amp;source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba bd be ud ue um" rel="noopener">Watch</a></span></div><div class="ty r tz"><div class="un r"><a href="https://medium.com/topics?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ub uc bd be ud ue" rel="noopener"><h4 class="uf ug uh bi il bj sl ui uj r">Make <!-- -->Medium<!-- --> yours</h4></a></div><span class="bi b bj bk bl bm r uk ul">Follow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox.<!-- --> <a href="https://medium.com/topics?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba bd be ud ue um" rel="noopener">Explore</a></span></div><div class="ty r tz"><div class="ua r"><a href="https://medium.com/membership?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ub uc bd be ud ue" rel="noopener"><h4 class="uf ug uh bi il bj sl ui uj r">Become a member</h4></a></div><span class="bi b bj bk bl bm r uk ul">Get unlimited access to the best stories on <!-- -->Medium<!-- --> — and support writers while you’re at it. Just $5/month.<!-- --> <a href="https://medium.com/membership?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba bd be ud ue um" rel="noopener">Upgrade</a></span></div></div></div><div class="n ju"><div class="n o gx"><a href="https://medium.com/?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ub uc bd be ud ue" rel="noopener"><svg height="22" width="112" viewBox="0 0 111.5 22" class="ug"><path d="M56.3 19.5c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5V19c-.7 1.8-2.4 3-4.3 3-3.3 0-5.8-2.6-5.8-7.5 0-4.5 2.6-7.6 6.3-7.6 1.6-.1 3.1.8 3.8 2.4V3.2c0-.3-.1-.6-.3-.7l-1.4-1.4V1l6.5-.8v19.3zm-4.8-.8V9.5c-.5-.6-1.2-.9-1.9-.9-1.6 0-3.1 1.4-3.1 5.7 0 4 1.3 5.4 3 5.4.8.1 1.6-.3 2-1zm9.1 3.1V9.4c0-.3-.1-.6-.3-.7l-1.4-1.5v-.1h6.5v12.5c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5zm-.2-19.2C60.4 1.2 61.5 0 63 0c1.4 0 2.6 1.2 2.6 2.6S64.4 5.3 63 5.3a2.6 2.6 0 0 1-2.6-2.7zm22.5 16.9c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5v-3.2c-.6 2-2.4 3.4-4.5 3.4-2.9 0-4.4-2.1-4.4-6.2 0-1.9 0-4.1.1-6.5 0-.3-.1-.5-.3-.7L67.7 7v.1H74v8c0 2.6.4 4.4 2 4.4.9-.1 1.7-.6 2.1-1.3V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v12.4zm22 2.3c0-.5.1-6.5.1-7.9 0-2.6-.4-4.5-2.2-4.5-.9 0-1.8.5-2.3 1.3.2.8.3 1.7.3 2.5 0 1.8-.1 4.2-.1 6.5 0 .3.1.5.3.7l1.5 1.4v.1H96c0-.4.1-6.5.1-7.9 0-2.7-.4-4.5-2.2-4.5-.9 0-1.7.5-2.2 1.3v9c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v3.1a4.6 4.6 0 0 1 4.6-3.4c2.2 0 3.6 1.2 4.2 3.5.7-2.1 2.7-3.6 4.9-3.5 2.9 0 4.5 2.2 4.5 6.2 0 1.9-.1 4.2-.1 6.5-.1.3.1.6.3.7l1.4 1.4v.1h-6.6zm-81.4-2l1.9 1.9v.1h-9.8v-.1l2-1.9c.2-.2.3-.4.3-.7V7.3c0-.5 0-1.2.1-1.8L11.4 22h-.1L4.5 6.8c-.1-.4-.2-.4-.3-.6v10c-.1.7 0 1.3.3 1.9l2.7 3.6v.1H0v-.1L2.7 18c.3-.6.4-1.3.3-1.9v-11c0-.5-.1-1.1-.5-1.5L.7 1.1V1h7l5.8 12.9L18.6 1h6.8v.1l-1.9 2.2c-.2.2-.3.5-.3.7v15.2c0 .2.1.5.3.6zm7.6-5.9c0 3.8 1.9 5.3 4.2 5.3 1.9.1 3.6-1 4.4-2.7h.1c-.8 3.7-3.1 5.5-6.5 5.5-3.7 0-7.2-2.2-7.2-7.4 0-5.5 3.5-7.6 7.3-7.6 3.1 0 6.4 1.5 6.4 6.2v.8h-8.7zm0-.8h4.3v-.8c0-3.9-.8-4.9-2-4.9-1.4.1-2.3 1.6-2.3 5.7z"></path></svg></a><span class="bi b bj bk bl bm r uk ul"><div class="su uo n gx up al"><h4 class="bi ek jx sl uf"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba hr bd be ud ue" rel="noopener">About</a></h4><h4 class="bi ek jx sl uf"><a href="https://help.medium.com/?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba hr bd be ud ue" rel="noopener">Help</a></h4><h4 class="bi ek jx sl uf"><a href="https://medium.com/policy/9db0094a1e0f?source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba hr bd be ud ue" rel="noopener">Legal</a></h4></div></span></div><div class="ap uq ur al"><h4 class="bi ek jx sl uk">Get the Medium app</h4></div><div class="ap uq us al ut"><div class="cq r"><a href="https://itunes.apple.com/app/medium-everyones-stories/id828256236?pt=698524&amp;mt=8&amp;ct=post_page&amp;source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ub uc bd be ud ue" rel="noopener nofollow"><img alt="A button that says &#39;Download on the App Store&#39;, and if clicked it will lead you to the iOS App store" class="" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_M2FVPPidy2x386MRAE-EeA.png" width="135" height="41"></a></div><div class="r"><a href="https://play.google.com/store/apps/details?id=com.medium.reader&amp;source=post_page-----48c40021da4----------------------" class="cg ch at au av aw ax ay az ba ub uc bd be ud ue" rel="noopener nofollow"><img alt="A button that says &#39;Get it on, Google Play&#39;, and if clicked it will lead you to the Google Play store" class="" src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/1_HyH8oIcJvXp7xzu5oF6dTg.png" width="135" height="41"></a></div></div></div></section></div></div></div><script>window.__BUILD_ID__ = "master-20200528-213348-f9ebf73a83"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"config":{"nodeEnv":"production","version":"master-20200528-213348-f9ebf73a83","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"lightstep.medium.systems","token":"ce5be895bef60919541332990ac9fef2","appVersion":"master-20200528-213348-f9ebf73a83"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","datadog":{"clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","context":{"deployment":{"target":"production","tag":"master-20200528-213348-f9ebf73a83","commit":"f9ebf73a83ac5346a4cebab0ff5e06bc6e5d1a1e"}},"datacenter":"us"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e","8ccfed20cbb2","ae2a65f35510","3f6ecf56618","7b6769f2748b","fc8964313712","ef8e90590e66","191186aaafa0","d944778ce714","bdc4052bbdba","88d9857e584e"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"internalLinksPostIds":["0","1","2","3","4","5","6","7"],"webpMiroImageIds":["1*y7gegIZOYlsnhWFJwIyDJw","1*ByGRQD1zlYXGS4YBYAoLVA","1*orNowUCqCER-BwaAXOZx0A","1*itOsotYFripvvRKY1itrVQ","1*b_LB1ifqWQ2x3JG_m3MJsg","1*AD7jcqVRun0Hhwmg0-Vqfg","1*0kJoJveqoxkYXEmdM2FZ3A","1*pTq8R2lALVUytg_k4y5CpQ","1*1_tSnwIHb_oPsU9vucJijQ","1*EBN0PWXjvaF2gRdk9fCvzA","1*Uxc2_wlnoVQNMQUhQaLVZg","1*ABOw4ARUQ90kwKfXqeVdXA","1*Ok2A1h7LmAtYjWVG9c8IMA","1*Kw1AUMFyy3AGJ1BbTdeyWg","1*2RZldaiJQXadc5zjscYncg","1*hPIJUpxe2QMvOMNcTlnOlQ","1*MZyvxFpPUvfBUfoNvFhRzg","1*2ROzqt2hXcYs6BuKjG2_nQ","1*NO9eMccT-vPrY8nylJ4PVw","2*6cf2Ep3P-r1vCrc-6Bc-vA","1*hVxgUA6kP-PgL5TJjuyePg","1*VGtACZSU6AxT3ugiNr-WGg","0*8dBf1Vy9mkDdcuwQ","1*5ciI2lDFX8sJanIJa6ppnA","1*Hqtfw2Juvf6Zb9uGimLLMg","1*suPSqLiNrJPCUbtdUwLnGw","1*dIANAeHtMxPlVO9awEN0Jw","1*N2KcM3GCLymsKxnSBXyG_g","1*fgNVzsUlPl9tA8ladAT-KA","1*h-La0GVOrPo6SrFpNWQLtw","1*3IPJZVYg-95RkV8H4DRjvA","1*DgnF3PmTVG14Oz_-8BWX_g","1*x_SKDZtUCcWMH9FB092srw","1*oQ4U4pCo7OUPMXXphwqzTg","1*fjC3jxxcmOwXLwqxraNHfw","1*DXy0NEVftDaLKDVG8dS3YQ","1*KbxEajPgdT9GhcWWGG8JmQ","1*e6oTrX0jQU0lPM_0Tt-oYw","1*oQ4U4pCo7OUPMXXphwqzTg","1*5I_5X9Of8dwLfLEwJWd9jA","1*wYUZRoGUFOj1kdT7R8S0TQ","1*dzn6a448FO7kqbXk2K1qiA","1*YQDEXca6FZq-9L5WXBH-3A","1*YlpXJYsNOORiPqY0Rx6zIQ","1*NM3ybm1NGbyvF_IGL5DPYQ","1*DJ36tR2MtLrCRA1BO62L8Q","1*wV6yqGmy-aGNGWt1paWy5g","0*iWmcqANWK8Ayo6NP","0*nB8YhFfPe8q0sJcJ","0*GN_xV2uMHSeGuotv","0*oT1BmxuFNEyN0XC4","0*Aow5I0AXoM8HG4RA","0*geqIA7abXJGEobLr"],"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*3sela1OADrJr7dJk_CXaEQ.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"performanceTags":[],"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":["pandemic","epidemic","coronavirus","covid19","co-vid-19","containment","self-care","flatten-the-curve","public-health","virus","public-health-crisis","quarantine","self-quarantine","zika","corona","disease-prevention","wuhan","chinavirus","outbreak","influenza","socialdistancing","social-distance","flu","vaccines","healthcare","medicine","conspiracy-theories","conspiracy","virality","epidemia","pandemia","salud","corona-e-virus","coronavirus-covid19","covid-19","covid-19-symptoms","covid-19-crisis","covid-19-testing","covid-19-treatment","coronavirus-update","coronavirus-diaries"],"COVID_APPLICABLE_TOPIC_NAMES":["coronavirus"],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":["coronavirus","health"],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4"},"debug":{"requestId":"6581bd1b-f15c-42e7-825d-7c2910ea1b41","edge":"","originalSpanCarrier":{"ot-tracer-spanid":"3c2009df4acef3a3","ot-tracer-traceid":"70913ad32a7e8eec","ot-tracer-sampled":"true"}},"session":{"user":{"id":"85164a79d2b9"},"xsrf":"wApGUsUFy04c","isSpoofed":false},"stats":{"itemCount":0,"sending":false,"timeout":null,"backup":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Freinforcement-learning-from-scratch-designing-and-solving-a-task-all-within-a-python-notebook-48c40021da4","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"https:\u002F\u002Fwww.google.com\u002F","susiModal":{"step":null,"operation":"register"},"postRead":false},"client":{"isBot":false,"isCustomDomain":true,"isEu":false,"isNativeMedium":false,"isSafariMobile":false,"inAppBrowserName":"","supportsWebp":true},"multiVote":{"clapsPerPost":{}},"tracing":{}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY.variantFlags.0":{"name":"add_friction_to_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.0.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.0.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.1":{"name":"allow_access","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.1.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.1.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.2":{"name":"allow_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.2.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.2.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.3":{"name":"allow_test_auth","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.3.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.3.valueType":{"__typename":"VariantFlagString","value":"disallow"},"ROOT_QUERY.variantFlags.4":{"name":"assign_default_topic_to_posts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.4.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.4.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.5":{"name":"available_annual_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.5.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.5.valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"},"ROOT_QUERY.variantFlags.6":{"name":"available_monthly_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.6.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.6.valueType":{"__typename":"VariantFlagString","value":"60e220181034"},"ROOT_QUERY.variantFlags.7":{"name":"bane_add_user","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.7.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.7.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.8":{"name":"branch_seo_metadata","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.8.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.8.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.9":{"name":"browsable_stream_config_bucket","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.9.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.9.valueType":{"__typename":"VariantFlagString","value":"curated-topics"},"ROOT_QUERY.variantFlags.10":{"name":"coronavirus_topic_recirc","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.10.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.10.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.11":{"name":"covid_19_cdc_banner","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.11.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.11.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.12":{"name":"disable_android_subscription_activity_carousel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.12.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.12.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.13":{"name":"disable_gosocial_followers_that_you_follow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.13.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.13.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.14":{"name":"disable_ios_resume_reading_toast","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.14.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.14.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.15":{"name":"disable_ios_subscription_activity_carousel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.15.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.15.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.16":{"name":"disable_mobile_featured_chunk","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.16.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.16.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.17":{"name":"disable_post_recommended_from_friends_provider","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.17.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.17.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.18":{"name":"enable_android_local_currency","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.18.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.18.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.19":{"name":"enable_annual_renewal_reminder_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.19.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.19.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.20":{"name":"enable_app_flirty_thirty","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.20.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.20.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.21":{"name":"enable_apple_sign_in","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.21.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.21.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.22":{"name":"enable_automated_mission_control_triggers","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.22.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.22.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.23":{"name":"enable_braintree_integration","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.23.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.23.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.24":{"name":"enable_braintree_webhook","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.24.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.24.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.25":{"name":"enable_branch_io","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.25.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.25.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.26":{"name":"enable_branding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.26.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.26.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.27":{"name":"enable_branding_fonts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.27.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.27.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.28":{"name":"enable_cleansweep_cachev2_reads","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.28.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.28.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.29":{"name":"enable_cleansweep_double_writes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.29.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.29.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.30":{"name":"enable_confirm_sign_in","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.30.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.30.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.31":{"name":"enable_cta_meter","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.31.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.31.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.32":{"name":"enable_curation_priority_queue_experiment","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.32.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.32.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.33":{"name":"enable_dedicated_series_tab_api_ios","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.33.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.33.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.34":{"name":"enable_different_grid","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.34.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.34.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.35":{"name":"enable_digest_feature_logging","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.35.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.35.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.36":{"name":"enable_digest_tagline","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.36.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.36.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.37":{"name":"enable_disregard_trunc_state_for_footer","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.37.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.37.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.38":{"name":"enable_edit_alt_text","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.38.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.38.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.39":{"name":"enable_email_sign_in_captcha","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.39.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.39.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.40":{"name":"enable_embedding_based_diversification","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.40.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.40.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.41":{"name":"enable_end_of_post_cleanup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.41.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.41.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.42":{"name":"enable_ev_mission_email_v3","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.42.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.42.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.43":{"name":"enable_ev_mission_trial_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.43.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.43.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.44":{"name":"enable_expanded_feature_chunk_pool","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.44.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.44.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.45":{"name":"enable_filter_by_resend_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.45.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.45.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.46":{"name":"enable_filter_expire_processor","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.46.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.46.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.47":{"name":"enable_first_name_on_paywall","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.47.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.47.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.48":{"name":"enable_footer_app_buttons","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.48.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.48.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.49":{"name":"enable_free_corona_topic","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.49.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.49.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.50":{"name":"enable_global_susi_modal","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.50.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.50.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.51":{"name":"enable_google_one_tap","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.51.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.51.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.52":{"name":"enable_highlander_member_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.52.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.52.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.53":{"name":"enable_ios_post_stats","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.53.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.53.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.54":{"name":"enable_janky_spam_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.54.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.54.valueType":{"__typename":"VariantFlagString","value":"users,posts"},"ROOT_QUERY.variantFlags.55":{"name":"enable_json_logs_trained_ranker","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.55.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.55.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.56":{"name":"enable_kafka_events","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.56.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.56.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.57":{"name":"enable_kbfd_rex","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.57.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.57.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.58":{"name":"enable_kbfd_rex_app_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.58.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.58.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.59":{"name":"enable_kbfd_rex_daily_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.59.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.59.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.60":{"name":"enable_li_open_in_app","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.60.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.60.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.61":{"name":"enable_lite_about_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.61.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.61.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.62":{"name":"enable_lite_notifications","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.62.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.62.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.63":{"name":"enable_lite_post","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.63.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.63.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.64":{"name":"enable_lite_post_cd","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.64.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.64.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.65":{"name":"enable_lite_post_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.65.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.65.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.66":{"name":"enable_lite_post_highlights_view_only","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.66.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.66.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.67":{"name":"enable_lite_profile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.67.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.67.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.68":{"name":"enable_lite_pub_header_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.68.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.68.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.69":{"name":"enable_lite_server_upstream_deadlines","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.69.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.69.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.70":{"name":"enable_lite_stories","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.70.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.70.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.71":{"name":"enable_lite_topics","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.71.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.71.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.72":{"name":"enable_lite_unread_notification_count_mutation","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.72.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.72.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.73":{"name":"enable_lo_open_in_app","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.73.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.73.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.74":{"name":"enable_logged_out_history","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.74.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.74.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.75":{"name":"enable_login_code_flow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.75.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.75.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.76":{"name":"enable_marketing_emails","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.76.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.76.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.77":{"name":"enable_media_resource_try_catch","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.77.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.77.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.78":{"name":"enable_membership_remove_section_a","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.78.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.78.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.79":{"name":"enable_miro_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.79.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.79.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.80":{"name":"enable_ml_rank_modules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.80.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.80.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.81":{"name":"enable_ml_rank_rex_anno","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.81.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.81.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.82":{"name":"enable_more_on_coronavirus","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.82.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.82.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.83":{"name":"enable_mute","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.83.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.83.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.84":{"name":"enable_new_collaborative_filtering_data","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.84.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.84.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.85":{"name":"enable_new_suspended_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.85.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.85.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.86":{"name":"enable_new_three_dot_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.86.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.86.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.87":{"name":"enable_olsen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.87.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.87.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.88":{"name":"enable_open_in_app_regwall","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.88.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.88.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.89":{"name":"enable_optimizely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.89.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.89.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.90":{"name":"enable_parsely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.90.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.90.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.91":{"name":"enable_patronus_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.91.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.91.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.92":{"name":"enable_popularity_feature","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.92.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.92.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.93":{"name":"enable_post_import","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.93.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.93.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.94":{"name":"enable_post_page_nav_stickiness_removal","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.94.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.94.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.95":{"name":"enable_post_seo_settings_screen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.95.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.95.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.96":{"name":"enable_post_settings_screen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.96.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.96.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.97":{"name":"enable_primary_topic_for_mobile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.97.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.97.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.98":{"name":"enable_responses_2","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.98.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.98.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.99":{"name":"enable_rito_upstream_deadlines","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.99.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.99.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.100":{"name":"enable_rtr_channel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.100.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.100.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.101":{"name":"enable_save_to_medium","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.101.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.101.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.102":{"name":"enable_sepia_to_olsen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.102.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.102.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.103":{"name":"enable_starspace","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.103.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.103.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.104":{"name":"enable_starspace_digest_app","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.104.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.104.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.105":{"name":"enable_starspace_ranker_starspace","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.105.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.105.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.106":{"name":"enable_tick_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.106.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.106.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.107":{"name":"enable_tipalti_onboarding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.107.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.107.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.108":{"name":"enable_topic_lifecycle_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.108.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.108.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.109":{"name":"enable_tribute_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.109.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.109.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.110":{"name":"enable_trumpland_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.110.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.110.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.111":{"name":"enable_utc_fix_on_partner_program_dashboard","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.111.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.111.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.112":{"name":"exclude_curated_in_popular_topic","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.112.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.112.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.113":{"name":"featured_fc_and_ydr","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.113.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.113.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.114":{"name":"filter_low_scoring_users","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.114.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.114.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.115":{"name":"glyph_embed_commands","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.115.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.115.valueType":{"__typename":"VariantFlagString","value":"control"},"ROOT_QUERY.variantFlags.116":{"name":"glyph_font_set","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.116.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.116.valueType":{"__typename":"VariantFlagString","value":"m2"},"ROOT_QUERY.variantFlags.117":{"name":"google_sign_in_android","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.117.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.117.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.118":{"name":"is_not_medium_subscriber","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.118.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.118.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.119":{"name":"limit_post_referrers","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.119.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.119.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.120":{"name":"make_nav_sticky","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.120.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.120.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.121":{"name":"new_transition_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.121.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.121.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.122":{"name":"pub_sidebar","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.122.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.122.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.123":{"name":"rank_model","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.123.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.123.valueType":{"__typename":"VariantFlagString","value":"default"},"ROOT_QUERY.variantFlags.124":{"name":"remove_post_post_similarity","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.124.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.124.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.125":{"name":"share_post_linkedin","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.125.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.125.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.126":{"name":"sign_up_with_email_button","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.126.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.126.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.127":{"name":"signin_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.127.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.127.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"},"ROOT_QUERY.variantFlags.128":{"name":"signup_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.128.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.128.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"},"ROOT_QUERY.variantFlags.129":{"name":"skip_sign_in_recaptcha","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.129.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.129.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.130":{"name":"use_new_admin_topic_backend","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.130.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.130.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.131":{"name":"xgboost_auto_suspend","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.131.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.131.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY":{"variantFlags":[{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.0","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.1","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.2","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.3","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.4","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.5","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.6","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.7","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.8","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.9","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.10","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.11","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.12","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.13","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.14","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.15","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.16","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.17","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.18","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.19","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.20","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.21","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.22","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.23","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.24","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.25","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.26","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.27","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.28","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.29","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.30","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.31","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.32","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.33","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.34","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.35","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.36","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.37","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.38","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.39","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.40","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.41","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.42","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.43","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.44","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.45","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.46","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.47","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.48","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.49","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.50","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.51","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.52","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.53","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.54","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.55","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.56","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.57","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.58","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.59","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.60","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.61","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.62","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.63","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.64","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.65","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.66","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.67","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.68","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.69","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.70","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.71","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.72","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.73","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.74","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.75","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.76","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.77","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.78","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.79","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.80","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.81","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.82","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.83","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.84","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.85","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.86","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.87","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.88","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.89","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.90","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.91","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.92","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.93","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.94","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.95","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.96","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.97","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.98","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.99","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.100","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.101","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.102","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.103","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.104","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.105","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.106","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.107","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.108","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.109","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.110","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.111","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.112","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.113","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.114","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.115","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.116","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.117","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.118","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.119","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.120","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.121","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.122","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.123","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.124","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.125","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.126","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.127","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.128","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.129","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.130","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.131","typename":"VariantFlag"}],"viewer":{"type":"id","generated":false,"id":"User:85164a79d2b9","typename":"User"},"meterPost({\"postId\":\"48c40021da4\",\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"type":"id","generated":false,"id":"MeteringInfo:singleton","typename":"MeteringInfo"},"postResult({\"id\":\"48c40021da4\"})":{"type":"id","generated":false,"id":"Post:48c40021da4","typename":"Post"}},"User:85164a79d2b9":{"id":"85164a79d2b9","username":"ayushverma1321","name":"Ayushverma","imageId":"0*fSKu5zWydc5B9tfM","mediumMemberAt":0,"hasPastMemberships":false,"isPartnerProgramEnrolled":false,"email":"ayushverma1321@gmail.com","unverifiedEmail":"","createdAt":1589189777130,"isEligibleToViewNewResponses":false,"isMembershipTrialEligible":true,"isSuspended":false,"__typename":"User"},"MeteringInfo:singleton":{"__typename":"MeteringInfo","postIds":{"type":"json","json":[]},"maxUnlockCount":4,"unlocksRemaining":4},"Post:48c40021da4":{"__typename":"Post","id":"48c40021da4","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Freinforcement-learning-from-scratch-designing-and-solving-a-task-all-within-a-python-notebook-48c40021da4","canonicalUrl":"","collection":{"type":"id","generated":false,"id":"Collection:7f60cf5620c9","typename":"Collection"},"content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"type":"id","generated":true,"id":"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})","typename":"PostContent"},"creator":{"type":"id","generated":false,"id":"User:3e06d9b2f907","typename":"User"},"firstPublishedAt":1545239287797,"isLocked":false,"isPublished":true,"layerCake":4,"primaryTopic":null,"title":"Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook","latestPublishedVersion":"f4719c50ce8c","visibility":"PUBLIC","isLimitedState":false,"sequence":null,"pendingCollection":null,"shareKey":null,"statusForCollection":"APPROVED","readingTime":11.809433962264151,"readingList":"READING_LIST_NONE","allowResponses":true,"clapCount":238,"viewerClapCount":null,"voterCount":62,"recommenders":[],"license":"ALL_RIGHTS_RESERVED","tags":[{"type":"id","generated":false,"id":"Tag:machine-learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:data-science","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:reinforcement-learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:guides-and-tutorials","typename":"Tag"}],"topics":[{"type":"id","generated":false,"id":"1eca0103fff3","typename":"Topic"},{"type":"id","generated":false,"id":"ae5d4995e225","typename":"Topic"}],"postResponses":{"type":"id","generated":true,"id":"$Post:48c40021da4.postResponses","typename":"PostResponses"},"responsesCount":2,"collaborators":[],"translationSourcePost":null,"newsletterId":"","inResponseToPostResult":null,"inResponseToMediaResource":null,"lockedSource":"LOCKED_POST_SOURCE_NONE","curationEligibleAt":0,"isDistributionAlertDismissed":false,"audioVersionUrl":"","socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1545297540227,"previewContent":{"type":"id","generated":true,"id":"$Post:48c40021da4.previewContent","typename":"PreviewContent"},"previewImage":{"type":"id","generated":false,"id":"ImageMetadata:1*hrzESilcBh6DFTMGLc7JNQ.gif","typename":"ImageMetadata"},"isShortform":false,"seoTitle":"","updatedAt":1545297540227,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false},"Collection:7f60cf5620c9":{"id":"7f60cf5620c9","domain":"towardsdatascience.com","googleAnalyticsId":null,"slug":"towards-data-science","customStyleSheet":null,"colorBehavior":"ACCENT_COLOR_AND_FILL_BACKGROUND","isAuroraPilot":false,"isAuroraVisible":false,"favicon":{"type":"id","generated":false,"id":"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png","typename":"ImageMetadata"},"name":"Towards Data Science","logo":{"type":"id","generated":false,"id":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","typename":"ImageMetadata"},"__typename":"Collection","avatar":{"type":"id","generated":false,"id":"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png","typename":"ImageMetadata"},"isAuroraEligible":false,"isEnrolledInHightower":false,"isNewsletterV3Enabled":true,"newsletterV3":{"type":"id","generated":false,"id":"NewsletterV3:d6fe9076899","typename":"NewsletterV3"},"creator":{"type":"id","generated":false,"id":"User:895063a310f4","typename":"User"},"viewerIsEditor":false,"navItems":[{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.0","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.1","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.2","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.3","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.4","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.5","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.6","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.7","typename":"NavItem"}],"colorPalette":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette","typename":"ColorPalette"},"description":"A Medium publication sharing concepts, ideas, and codes.","shortDescription":"A Medium publication sharing concepts, ideas, and codes.","tagline":"A Medium publication sharing concepts, ideas, and codes.","viewerIsFollowing":false,"viewerIsSubscribedToLetters":false,"canToggleEmail":true,"isUserSubscribedToCollectionEmails":false,"viewerCanEditOwnPosts":false,"viewerCanEditPosts":false,"viewerIsMuting":false,"ampEnabled":false,"twitterUsername":"TDataScience","facebookPageId":null},"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png":{"id":"1*ChFMdf--f5jbm-AYv6VdYA@2x.png","__typename":"ImageMetadata"},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","originalWidth":337,"originalHeight":122,"__typename":"ImageMetadata"},"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png":{"id":"1*hVxgUA6kP-PgL5TJjuyePg.png","__typename":"ImageMetadata"},"NewsletterV3:d6fe9076899":{"id":"d6fe9076899","slug":"monthly-edition","__typename":"NewsletterV3","isSubscribed":false,"showPromo":false,"name":"Monthly Edition","description":"Well-written and informative articles that you’ll be excited to read. Find our best content here, including tutorials, hands-on real-world examples, research, and cutting-edge techniques. It’s the best way to learn new things and stay up to date with Towards Data Science. ","collection":{"type":"id","generated":false,"id":"Collection:7f60cf5620c9","typename":"Collection"}},"User:895063a310f4":{"id":"895063a310f4","__typename":"User"},"Collection:7f60cf5620c9.navItems.0":{"title":"Data Science","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-science\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.1":{"title":"Machine Learning","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmachine-learning\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.2":{"title":"Programming","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fprogramming\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.3":{"title":"Visualization","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-visualization\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.4":{"title":"AI","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fartificial-intelligence\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.5":{"title":"Video","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fvideo\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.6":{"title":"About","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fabout-us\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.7":{"title":"Contribute","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcontribute\u002Fhome","type":"EXTERNAL_LINK_NAV_ITEM","__typename":"NavItem"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum":{"backgroundColor":"#FF355876","colorPoints":[{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.0":{"color":"#FF355876","point":0,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.1":{"color":"#FF4D6C88","point":0.1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.2":{"color":"#FF637F99","point":0.2,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.3":{"color":"#FF7791A8","point":0.3,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.4":{"color":"#FF8CA2B7","point":0.4,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.5":{"color":"#FF9FB3C6","point":0.5,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.6":{"color":"#FFB2C3D4","point":0.6,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.7":{"color":"#FFC5D2E1","point":0.7,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.8":{"color":"#FFD7E2EE","point":0.8,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.9":{"color":"#FFE9F1FA","point":0.9,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.10":{"color":"#FFFBFFFF","point":1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette":{"tintBackgroundSpectrum":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum","typename":"ColorSpectrum"},"__typename":"ColorPalette","highlightSpectrum":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum","typename":"ColorSpectrum"},"defaultBackgroundSpectrum":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum","typename":"ColorSpectrum"}},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.0":{"color":"#FFEDF4FC","point":0,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.1":{"color":"#FFE9F2FD","point":0.1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.2":{"color":"#FFE6F1FD","point":0.2,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.3":{"color":"#FFE2EFFD","point":0.3,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.4":{"color":"#FFDFEEFD","point":0.4,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.5":{"color":"#FFDBECFE","point":0.5,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.6":{"color":"#FFD7EBFE","point":0.6,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.7":{"color":"#FFD4E9FE","point":0.7,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.8":{"color":"#FFD0E7FF","point":0.8,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.9":{"color":"#FFCCE6FF","point":0.9,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.10":{"color":"#FFC8E4FF","point":1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.0":{"color":"#FF668AAA","point":0,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.1":{"color":"#FF61809D","point":0.1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.2":{"color":"#FF5A7690","point":0.2,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.3":{"color":"#FF546C83","point":0.3,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.4":{"color":"#FF4D6275","point":0.4,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.5":{"color":"#FF455768","point":0.5,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.6":{"color":"#FF3D4C5A","point":0.6,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.7":{"color":"#FF34414C","point":0.7,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.8":{"color":"#FF2B353E","point":0.8,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.9":{"color":"#FF21282F","point":0.9,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.10":{"color":"#FF161B1F","point":1,"__typename":"ColorPoint"},"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"isLockedPreviewOnly":false,"validatedShareKey":"","__typename":"PostContent","bodyModel":{"type":"id","generated":true,"id":"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel","typename":"RichText"}},"User:3e06d9b2f907":{"id":"3e06d9b2f907","isSuspended":false,"__typename":"User","allowNotes":true,"name":"Sterling Osborne, PhD Researcher","isFollowing":false,"username":"sterlingosborne","bio":"PhD Research Student in Artificial Intelligence at the University of Manchester (UK).","imageId":"2*WgLcF6AYGqam8M3kLwBG6Q.jpeg","mediumMemberAt":1558690023000,"isBlocking":false,"isMuting":false,"isPartnerProgramEnrolled":false,"twitterScreenName":"DataOsborne"},"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.0":{"name":"e46c","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.1":{"name":"0303","startIndex":10,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.2":{"name":"d9ec","startIndex":60,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.3":{"name":"e3a6","startIndex":94,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel":{"sections":[{"type":"id","generated":true,"id":"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.0","typename":"Section"},{"type":"id","generated":true,"id":"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.1","typename":"Section"},{"type":"id","generated":true,"id":"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.2","typename":"Section"},{"type":"id","generated":true,"id":"$Post:48c40021da4.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.3","typename":"Section"}],"paragraphs":[{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_0","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_1","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_2","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_3","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_4","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_5","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_6","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_7","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_8","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_9","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_10","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_11","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_12","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_13","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_14","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_15","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_16","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_17","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_18","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_19","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_20","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_21","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_22","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_23","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_24","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_25","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_26","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_27","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_28","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_29","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_30","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_31","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_32","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_33","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_34","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_35","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_36","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_37","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_38","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_39","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_40","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_41","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_42","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_43","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_44","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_45","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_46","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_47","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_48","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_49","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_50","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_51","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_52","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_53","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_54","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_55","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_56","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_57","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_58","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_59","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_60","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_61","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_62","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_63","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_64","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_65","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_66","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_67","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_68","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_69","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_70","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_71","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_72","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_73","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_74","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_75","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_76","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_77","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_78","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_79","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_80","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_81","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_82","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_83","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_84","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_85","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_86","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_87","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_88","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_89","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_90","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_91","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_92","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_93","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_94","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_95","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_96","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_97","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_98","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_99","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_100","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_101","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_102","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_103","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_104","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_105","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_106","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_107","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_108","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_109","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_110","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_111","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_112","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_113","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_114","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_115","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_116","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_117","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_118","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_119","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:f4719c50ce8c_120","typename":"Paragraph"}],"__typename":"RichText"},"Paragraph:f4719c50ce8c_0":{"id":"f4719c50ce8c_0","name":"a3c8","type":"H3","href":null,"layout":null,"metadata":null,"text":"Reinforcement Learning from Scratch: Designing and Solving a Task All Within a Python Notebook","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_1":{"id":"f4719c50ce8c_1","name":"4ca6","type":"H4","href":null,"layout":null,"metadata":null,"text":"Part 1: Defining the Environment, Finding the Optimal Policy with Value-Iteration and Introducing Q-Learning","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_2":{"id":"f4719c50ce8c_2","name":"c332","type":"H4","href":null,"layout":null,"metadata":null,"text":"Summary","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_3":{"id":"f4719c50ce8c_3","name":"78ed","type":"P","href":null,"layout":null,"metadata":null,"text":"In this article, I will introduce a new project that attempts to help those learning Reinforcement Learning by fully defining and solving a simple task all within a Python notebook. The environment and basic methods will be explained within this article and all the code is published on Kaggle in the link below. In addition, I have created a “Meta” notebook that can be forked easily and only contains the defined environment for others to try, adapt and apply their own code to.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_4":{"id":"f4719c50ce8c_4","name":"4755","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"Reinforcement Learning from Scratch in Python\nBeginner's Guide to Finding the Optimal Actions of a Defined Environmentwww.kaggle.com","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_4.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_4.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_4.markups.2","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":{"type":"id","generated":true,"id":"$Paragraph:f4719c50ce8c_4.mixtapeMetadata","typename":"MixtapeMetadata"}},"Paragraph:f4719c50ce8c_4.markups.0":{"type":"A","start":0,"end":132,"href":"https:\u002F\u002Fwww.kaggle.com\u002Fosbornep\u002F-reinforcement-learning-from-scratch-in-python","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_4.markups.1":{"type":"STRONG","start":0,"end":45,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_4.markups.2":{"type":"EM","start":46,"end":118,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"$Paragraph:f4719c50ce8c_4.mixtapeMetadata":{"href":"https:\u002F\u002Fwww.kaggle.com\u002Fosbornep\u002F-reinforcement-learning-from-scratch-in-python","thumbnailImageId":"0*LErpsCYVnImxewHx","__typename":"MixtapeMetadata"},"Paragraph:f4719c50ce8c_5":{"id":"f4719c50ce8c_5","name":"8e59","type":"H4","href":null,"layout":null,"metadata":null,"text":"Context","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_6":{"id":"f4719c50ce8c_6","name":"72de","type":"P","href":null,"layout":null,"metadata":null,"text":"When I first started learning about Reinforcement Learning I went straight into replicating online guides and projects but found I was getting lost and confused. “Why do the results show this? What does this parameter do? What does the environment act in this way?” were all some of the questions I began asking myself. It wasn’t until I took a step back and started from the basics of first fully understanding how the probabilistic environment is defined and building up a small example that I could solve on paper that things began to make more sense. However, I found it hard to find environments that I could apply my knowledge on that didn’t need to be imported from external sources.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_7":{"id":"f4719c50ce8c_7","name":"3c99","type":"P","href":null,"layout":null,"metadata":null,"text":"Therefore, I set myself a challenge:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_8":{"id":"f4719c50ce8c_8","name":"f865","type":"P","href":null,"layout":null,"metadata":null,"text":"Can I fully define and find the optimal actions for a task environment all self-contained within a Python notebook?","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_8.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_8.markups.0":{"type":"STRONG","start":0,"end":115,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_9":{"id":"f4719c50ce8c_9","name":"8c8d","type":"P","href":null,"layout":null,"metadata":null,"text":"By following my work I hope that that others may use this as a basic starting point for learning themselves.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_10":{"id":"f4719c50ce8c_10","name":"e13a","type":"H3","href":null,"layout":null,"metadata":null,"text":"Stage 1: Defining the Environment","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_11":{"id":"f4719c50ce8c_11","name":"e7a6","type":"H4","href":null,"layout":null,"metadata":null,"text":"The Task","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_12":{"id":"f4719c50ce8c_12","name":"6371","type":"P","href":null,"layout":null,"metadata":null,"text":"Very simply, I want to know the best action in order to get a piece of paper into a bin (trash can) from any position in a room. I can throw the paper in any direction or move one step at a time.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_13":{"id":"f4719c50ce8c_13","name":"49c1","type":"P","href":null,"layout":null,"metadata":null,"text":"Although simple to a human who can judge location of the bin by eyesight and have huge amounts of prior knowledge regarding the distance a robot has to learn from nothing.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_14":{"id":"f4719c50ce8c_14","name":"54ec","type":"P","href":null,"layout":null,"metadata":null,"text":"This defines the environment where the probability of a successful throw are calculated based on the direction in which the paper is thrown and the current distance from the bin.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_15":{"id":"f4719c50ce8c_15","name":"523d","type":"P","href":null,"layout":null,"metadata":null,"text":"For example, in the image below we have three people labelled A, B and C. A and B both throw in the correct direction but person A is closer than B and so will have a higher probability of landing the shot.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_16":{"id":"f4719c50ce8c_16","name":"df10","type":"P","href":null,"layout":null,"metadata":null,"text":"Person C is closer than person B but throws in the completely wrong direction and so will have a very low probability of hitting the bin. This may seem illogical that person C would throw in this direction but, as we will show more later, an algorithm has to try a range of directions first to figure out where the successes are and will have no visual guide as to where the bin is.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_17":{"id":"f4719c50ce8c_17","name":"ec4a","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*DnSXHxSk4Zn25YoOemRfJg.png","typename":"ImageMetadata"},"text":"Task Environment Example","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*DnSXHxSk4Zn25YoOemRfJg.png":{"id":"1*DnSXHxSk4Zn25YoOemRfJg.png","originalHeight":538,"originalWidth":664,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_18":{"id":"f4719c50ce8c_18","name":"bc84","type":"P","href":null,"layout":null,"metadata":null,"text":"To create the environment in python, we convert the diagram into 2-d dimensions of x and y values and use bearing mathematics to calculate the angles thrown. We used normalised integer x and y values so that they must be bounded by -10 and 10.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_19":{"id":"f4719c50ce8c_19","name":"925e","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*7GGpVQwKUV-pMZhNDboBjw.png","typename":"ImageMetadata"},"text":"Environment Mapped to 2-d Space","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*7GGpVQwKUV-pMZhNDboBjw.png":{"id":"1*7GGpVQwKUV-pMZhNDboBjw.png","originalHeight":278,"originalWidth":411,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_20":{"id":"f4719c50ce8c_20","name":"580d","type":"H4","href":null,"layout":null,"metadata":null,"text":"Environment Probabilities","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_21":{"id":"f4719c50ce8c_21","name":"c132","type":"P","href":null,"layout":null,"metadata":null,"text":"The probability of a successful throw is relative to the distance and direction in which it is thrown. Therefore, we need to calculate two measures:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_22":{"id":"f4719c50ce8c_22","name":"51ba","type":"ULI","href":null,"layout":null,"metadata":null,"text":"The distance the current position is from the bin","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_23":{"id":"f4719c50ce8c_23","name":"1f71","type":"ULI","href":null,"layout":null,"metadata":null,"text":"The difference between the angle at which the paper was thrown and the true direction to the bin","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_24":{"id":"f4719c50ce8c_24","name":"025a","type":"P","href":null,"layout":null,"metadata":null,"text":"Distance Measure\nAs shown in the plot above, the position of person A in set to be (-5,-5). This is their current state and their distance from the bin can be calculated using the Euclidean distance measure:","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_24.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_24.markups.0":{"type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_25":{"id":"f4719c50ce8c_25","name":"a1ec","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*DNR02ALVCLpPy10pvU3-Mg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*DNR02ALVCLpPy10pvU3-Mg.png":{"id":"1*DNR02ALVCLpPy10pvU3-Mg.png","originalHeight":119,"originalWidth":444,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_26":{"id":"f4719c50ce8c_26","name":"46e0","type":"P","href":null,"layout":null,"metadata":null,"text":"For the final calculations, we normalise this and reverse the value so that a high score indicates that the person is closer to the target bin:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_27":{"id":"f4719c50ce8c_27","name":"e522","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*-U1k4_DSR0EqNGYLgP1_qg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*-U1k4_DSR0EqNGYLgP1_qg.png":{"id":"1*-U1k4_DSR0EqNGYLgP1_qg.png","originalHeight":61,"originalWidth":408,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_28":{"id":"f4719c50ce8c_28","name":"1e68","type":"P","href":null,"layout":null,"metadata":null,"text":"Because we have fixed our 2-d dimensions between (-10, 10), the max possible distance the person could be is sqrt{(100) + (100)} = sqrt{200} from the bin. Therefore our distance score for person A is:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_29":{"id":"f4719c50ce8c_29","name":"a65d","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*4Q5NHix_MJ6zqpsrEIyMwg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*4Q5NHix_MJ6zqpsrEIyMwg.png":{"id":"1*4Q5NHix_MJ6zqpsrEIyMwg.png","originalHeight":87,"originalWidth":404,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_30":{"id":"f4719c50ce8c_30","name":"48d6","type":"P","href":null,"layout":null,"metadata":null,"text":"Direction Measure","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_30.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_30.markups.0":{"type":"STRONG","start":0,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_31":{"id":"f4719c50ce8c_31","name":"e00b","type":"P","href":null,"layout":null,"metadata":null,"text":"Person A then has a decision to make, do they move or do they throw in a chosen direction. For now, let imagine they choose to throw the paper, their first throw is at 50 degrees and the second is 60 degrees from due north. The direction of the bin from person A can be calculated by simple trigonometry:","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_31.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_31.markups.0":{"type":"STRONG","start":150,"end":222,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_32":{"id":"f4719c50ce8c_32","name":"76b1","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*py4fdnvhJumhiOQKV6cHcg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*py4fdnvhJumhiOQKV6cHcg.png":{"id":"1*py4fdnvhJumhiOQKV6cHcg.png","originalHeight":60,"originalWidth":412,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_33":{"id":"f4719c50ce8c_33","name":"f30b","type":"P","href":null,"layout":null,"metadata":null,"text":"Therefore, the first throw is 5 degrees off the true direction and the second is 15 degrees.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_34":{"id":"f4719c50ce8c_34","name":"1037","type":"P","href":null,"layout":null,"metadata":null,"text":"When we consider that good throws are bounded by 45 degrees either side of the actual direction (i.e. not throwing the wrong way) then we can use the following to calculate how good this chosen direction is. Any direction beyond the 45 degree bounds will produce a negative value and be mapped to probability of 0:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_35":{"id":"f4719c50ce8c_35","name":"b494","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*aq_h8R-DCFhtbcQEmmZRSw.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*aq_h8R-DCFhtbcQEmmZRSw.png":{"id":"1*aq_h8R-DCFhtbcQEmmZRSw.png","originalHeight":172,"originalWidth":496,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_36":{"id":"f4719c50ce8c_36","name":"46bc","type":"P","href":null,"layout":null,"metadata":null,"text":"Both are fairly close but their first throw is more likely to hit the bin.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_37":{"id":"f4719c50ce8c_37","name":"f6e5","type":"P","href":null,"layout":null,"metadata":null,"text":"Probability Calculation","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_37.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_37.markups.0":{"type":"STRONG","start":0,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_38":{"id":"f4719c50ce8c_38","name":"c40e","type":"P","href":null,"layout":null,"metadata":null,"text":"We therefore calculate our probability of a successful throw to be relative to both these measures:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_39":{"id":"f4719c50ce8c_39","name":"93ac","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*A060XDtIiAMlmJ4nEb9_KQ.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*A060XDtIiAMlmJ4nEb9_KQ.png":{"id":"1*A060XDtIiAMlmJ4nEb9_KQ.png","originalHeight":182,"originalWidth":469,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_40":{"id":"f4719c50ce8c_40","name":"ac1d","type":"H4","href":null,"layout":null,"metadata":null,"text":"Creating a Generalised Probability Function","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_41":{"id":"f4719c50ce8c_41","name":"6b14","type":"P","href":null,"layout":null,"metadata":null,"text":"Although the previous calculations were fairly simple, some considerations need to be taken into account when we generalise these and begin to consider that the bin or current position are not fixed.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_42":{"id":"f4719c50ce8c_42","name":"0777","type":"P","href":null,"layout":null,"metadata":null,"text":"In our previous example, person A is south-west from the bin and therefore the angle was a simple calculation but if we applied the same to say a person placed north-east then this would be incorrect. Furthermore, because the bin can be placed anywhere we need to first find where the person is relative to this, not just the origin, and then used to to establish to angle calculation required.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_43":{"id":"f4719c50ce8c_43","name":"f4ad","type":"P","href":null,"layout":null,"metadata":null,"text":"This is summarised in the diagram below where we have generalised each of the trigonometric calculations based on the person’s relative position to the bin:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_44":{"id":"f4719c50ce8c_44","name":"4cd4","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*c45uGPJx-geJrjazU_1F-g.png","typename":"ImageMetadata"},"text":"Angle Calculation Rules","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*c45uGPJx-geJrjazU_1F-g.png":{"id":"1*c45uGPJx-geJrjazU_1F-g.png","originalHeight":819,"originalWidth":1285,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_45":{"id":"f4719c50ce8c_45","name":"2669","type":"P","href":null,"layout":null,"metadata":null,"text":"With this diagram in mind, we create a function that calculates the probability of a throw’s success from only given position relative to the bin.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_46":{"id":"f4719c50ce8c_46","name":"2037","type":"P","href":null,"layout":null,"metadata":null,"text":"We then calculate the bearing from the person to the bin following the previous figure and calculate the score bounded within a +\u002F- 45 degree window. Throws that are closest to the true bearing score higher whilst those further away score less, anything more than 45 degrees (or less than -45 degrees) are negative and then set to a zero probability.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_47":{"id":"f4719c50ce8c_47","name":"7d65","type":"P","href":null,"layout":null,"metadata":null,"text":"Lastly, the overall probability is related to both the distance and direction given the current position as shown before.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_48":{"id":"f4719c50ce8c_48","name":"edc4","type":"P","href":null,"layout":null,"metadata":null,"text":"Note: I have chosen 45 degrees as the boundary but you may choose to change this window or could manually scale the probability calculation to weight the distance of direction measure differently.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_48.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_48.markups.0":{"type":"STRONG","start":0,"end":196,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_49":{"id":"f4719c50ce8c_49","name":"185f","type":"P","href":null,"layout":null,"metadata":null,"text":"We re-calculate the previous examples and find the same results as expected.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_50":{"id":"f4719c50ce8c_50","name":"968f","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*Ak9zfkl4kGy8T2eDXDPtrw.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*Ak9zfkl4kGy8T2eDXDPtrw.png":{"id":"1*Ak9zfkl4kGy8T2eDXDPtrw.png","originalHeight":286,"originalWidth":715,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_51":{"id":"f4719c50ce8c_51","name":"3693","type":"H4","href":null,"layout":null,"metadata":null,"text":"Plotting Probabilities for Each State","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_52":{"id":"f4719c50ce8c_52","name":"3595","type":"P","href":null,"layout":null,"metadata":null,"text":"Now that we have this as a function, we can easily calculate and plot the probabilities of all points in our 2-d grid for a fixed throwing direction.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_53":{"id":"f4719c50ce8c_53","name":"5469","type":"P","href":null,"layout":null,"metadata":null,"text":"The probabilities are defined by the angle we set in the previous function, currently this is 45 degrees but this can reduced or increased if desired and the results will change accordingly. We may also want to scale the probability differently for distances.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_54":{"id":"f4719c50ce8c_54","name":"6ced","type":"P","href":null,"layout":null,"metadata":null,"text":"For example, the probability when the paper is thrown at a 180 degree bearing (due South) for each x\u002Fy position is shown below.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_55":{"id":"f4719c50ce8c_55","name":"a857","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*sG4BMmyPirJyozOUpYULuQ.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*sG4BMmyPirJyozOUpYULuQ.png":{"id":"1*sG4BMmyPirJyozOUpYULuQ.png","originalHeight":279,"originalWidth":397,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_56":{"id":"f4719c50ce8c_56","name":"a881","type":"P","href":null,"layout":null,"metadata":null,"text":"Animated Plot for All Throwing Directions","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_56.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_56.markups.0":{"type":"STRONG","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_57":{"id":"f4719c50ce8c_57","name":"3ddf","type":"P","href":null,"layout":null,"metadata":null,"text":"To demonstrate this further, we can iterate through a number of throwing directions and create an interactive animation. The code becomes a little complex and you can always simply use the previous code chunk and change the “throw_direction ” parameter manually to explore different positions. However this helps explore the probabilities and can be found in the Kaggle notebook.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_58":{"id":"f4719c50ce8c_58","name":"3d2e","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*T5E6Nff0zLCCy-nwI7aXYQ.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*T5E6Nff0zLCCy-nwI7aXYQ.png":{"id":"1*T5E6Nff0zLCCy-nwI7aXYQ.png","originalHeight":750,"originalWidth":750,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_59":{"id":"f4719c50ce8c_59","name":"3e2c","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"RL from Scratch Part 1: Defining the Environment | Kaggle\nEdit descriptionwww.kaggle.com","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_59.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_59.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_59.markups.2","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":{"type":"id","generated":true,"id":"$Paragraph:f4719c50ce8c_59.mixtapeMetadata","typename":"MixtapeMetadata"}},"Paragraph:f4719c50ce8c_59.markups.0":{"type":"A","start":0,"end":88,"href":"https:\u002F\u002Fwww.kaggle.com\u002Fosbornep\u002Frl-from-scratch-part-1-defining-the-environment","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_59.markups.1":{"type":"STRONG","start":0,"end":57,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_59.markups.2":{"type":"EM","start":58,"end":74,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"$Paragraph:f4719c50ce8c_59.mixtapeMetadata":{"href":"https:\u002F\u002Fwww.kaggle.com\u002Fosbornep\u002Frl-from-scratch-part-1-defining-the-environment","thumbnailImageId":"","__typename":"MixtapeMetadata"},"Paragraph:f4719c50ce8c_60":{"id":"f4719c50ce8c_60","name":"2a72","type":"H3","href":null,"layout":null,"metadata":null,"text":"Stage 2: Finding the Optimal Policy for Environment where the Probabilities are Known","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_61":{"id":"f4719c50ce8c_61","name":"2c94","type":"H4","href":null,"layout":null,"metadata":null,"text":"Model-based Methods","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_62":{"id":"f4719c50ce8c_62","name":"7774","type":"P","href":null,"layout":null,"metadata":null,"text":"The aim is for us to find the optimal action in each state by either throwing or moving in a given direction. Because we have known probabilities, we can actually use model-based methods and will demonstrate this first and can use value-iteration to achieve this via the following formula:","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_62.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_62.markups.0":{"type":"STRONG","start":231,"end":246,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_63":{"id":"f4719c50ce8c_63","name":"22d1","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*-DkkELogkP_tb8AWaWZu9w.png","typename":"ImageMetadata"},"text":"Value Iteration Update Rules","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*-DkkELogkP_tb8AWaWZu9w.png":{"id":"1*-DkkELogkP_tb8AWaWZu9w.png","originalHeight":101,"originalWidth":474,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_64":{"id":"f4719c50ce8c_64","name":"7b2b","type":"P","href":null,"layout":null,"metadata":null,"text":"Value iteration starts with an arbitrary function V0 and uses the following equations to get the functions for k+1 stages to go from the functions for k stages to go (https:\u002F\u002Fartint.info\u002Fhtml\u002FArtInt_227.html).","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_64.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_64.markups.0":{"type":"A","start":167,"end":207,"href":"https:\u002F\u002Fartint.info\u002Fhtml\u002FArtInt_227.html","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_65":{"id":"f4719c50ce8c_65","name":"2a56","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*pTq2-fdmY_lOZSm_0-RzVg.png","typename":"ImageMetadata"},"text":"Initial Value of Each State","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*pTq2-fdmY_lOZSm_0-RzVg.png":{"id":"1*pTq2-fdmY_lOZSm_0-RzVg.png","originalHeight":363,"originalWidth":680,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_66":{"id":"f4719c50ce8c_66","name":"b6ab","type":"P","href":null,"layout":null,"metadata":null,"text":"The calculation of MOVE actions are fairly simple because I have defined the probability of a movements success to be guaranteed (equal to 1). Therefore, the Q value of, for example, action (1,1) from state (-5,-5) is equal to:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_67":{"id":"f4719c50ce8c_67","name":"437e","type":"P","href":null,"layout":null,"metadata":null,"text":"Q((-5,-5),MOVE(1,1)) = 1*( R((-5,-5),(1,1),(-4,-4))+ gamma*V(-4,-4)))","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_68":{"id":"f4719c50ce8c_68","name":"2625","type":"P","href":null,"layout":null,"metadata":null,"text":"for now, the rewards are also all 0 therefore the value for this first calculation is simply:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_69":{"id":"f4719c50ce8c_69","name":"85c3","type":"P","href":null,"layout":null,"metadata":null,"text":"Q((-5,-5),(1,1)) = 1*(0+gamma*0) = 0","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_70":{"id":"f4719c50ce8c_70","name":"8035","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*C0iOu9WCw19UOC25M0HXHw.png","typename":"ImageMetadata"},"text":"First Q update for Move Actions","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*C0iOu9WCw19UOC25M0HXHw.png":{"id":"1*C0iOu9WCw19UOC25M0HXHw.png","originalHeight":297,"originalWidth":372,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_71":{"id":"f4719c50ce8c_71","name":"dd22","type":"P","href":null,"layout":null,"metadata":null,"text":"All move actions within the first update will be calculated similarly. Value is added to the system from successful throws. Therefore, we can calculate the Q value for a specific throw action. Previously, we found the probability of throw direction 50 degrees from (-5,-5) to be equal to 0.444. Therefore, the Q value for this action updates accordingly:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_72":{"id":"f4719c50ce8c_72","name":"9e79","type":"P","href":null,"layout":null,"metadata":null,"text":"Q((-5,-5),THROW(50)) =","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_73":{"id":"f4719c50ce8c_73","name":"3fbe","type":"P","href":null,"layout":null,"metadata":null,"text":"0.444*(R((-5,-5),(50),bin) + gamma*V(bin+))) +","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_74":{"id":"f4719c50ce8c_74","name":"8cda","type":"P","href":null,"layout":null,"metadata":null,"text":"(1–0.444)*(R((-5,-5),(50),bin) + gamma*V(bin-)))","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_75":{"id":"f4719c50ce8c_75","name":"2937","type":"P","href":null,"layout":null,"metadata":null,"text":"Again the rewards are set to 0 and the positive value of the bin is 1 while the negative value of the bin is -1. Therefore we have:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_76":{"id":"f4719c50ce8c_76","name":"2503","type":"P","href":null,"layout":null,"metadata":null,"text":"Q((-5,-5),THROW(50)) =","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_77":{"id":"f4719c50ce8c_77","name":"d2c4","type":"P","href":null,"layout":null,"metadata":null,"text":"0.444*(0 + gamma*1) +","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_78":{"id":"f4719c50ce8c_78","name":"db1d","type":"P","href":null,"layout":null,"metadata":null,"text":"(1–0.444)*(0 + gamma*1) = 0.3552–0.4448 = -0.0896","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_79":{"id":"f4719c50ce8c_79","name":"7ca7","type":"P","href":null,"layout":null,"metadata":null,"text":"It becomes clear that although moving following the first update doesn’t change from the initialised values, throwing at 50 degrees is worse due to the distance and probability of missing.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_80":{"id":"f4719c50ce8c_80","name":"16a8","type":"P","href":null,"layout":null,"metadata":null,"text":"Once each Q(s,a) is calculated for all states and actions, the value of each state, V(s), is updated as the maximum Q value for this state. The process is repeated back and forth until the results converge.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_81":{"id":"f4719c50ce8c_81","name":"3bc9","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*alDG2IwxdsDN7PMglgGnLA.png","typename":"ImageMetadata"},"text":"Value-Iteration Update Procedure","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*alDG2IwxdsDN7PMglgGnLA.png":{"id":"1*alDG2IwxdsDN7PMglgGnLA.png","originalHeight":323,"originalWidth":1737,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_82":{"id":"f4719c50ce8c_82","name":"8358","type":"P","href":null,"layout":null,"metadata":null,"text":"There is not set limit for how many times this needs to be repeated and is dependent on the problem. Because our environment is so simple, it actually converges to the optimal policy within just 10 updates.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_83":{"id":"f4719c50ce8c_83","name":"565b","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*IQb5OcbJWlnOFtOTHofEoQ.png","typename":"ImageMetadata"},"text":"Convergence of Value-Iteration Updates","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*IQb5OcbJWlnOFtOTHofEoQ.png":{"id":"1*IQb5OcbJWlnOFtOTHofEoQ.png","originalHeight":264,"originalWidth":381,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_84":{"id":"f4719c50ce8c_84","name":"e87a","type":"P","href":null,"layout":null,"metadata":null,"text":"We first show the best action based on throwing or moving by a simple coloured scatter shown below.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_85":{"id":"f4719c50ce8c_85","name":"a581","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*aMqIvRj7bSPzcFhy_IK7uA.png","typename":"ImageMetadata"},"text":"Optimal Policy Plot v1","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*aMqIvRj7bSPzcFhy_IK7uA.png":{"id":"1*aMqIvRj7bSPzcFhy_IK7uA.png","originalHeight":279,"originalWidth":412,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_86":{"id":"f4719c50ce8c_86","name":"8074","type":"P","href":null,"layout":null,"metadata":null,"text":"Improving Visualisation of Optimal Policy","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_86.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_86.markups.0":{"type":"STRONG","start":0,"end":41,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_87":{"id":"f4719c50ce8c_87","name":"0bba","type":"P","href":null,"layout":null,"metadata":null,"text":"Although the chart shows whether the optimal action is either a throw or move it doesn’t show us which direction these are in. Therefore, we will map each optimal action to a vector of u and v and use these to create a quiver plot (https:\u002F\u002Fmatplotlib.org\u002Fapi\u002F_as_gen\u002Fmatplotlib.axes.Axes.quiver.html).","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_87.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_87.markups.0":{"type":"A","start":232,"end":299,"href":"https:\u002F\u002Fmatplotlib.org\u002Fapi\u002F_as_gen\u002Fmatplotlib.axes.Axes.quiver.html","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_88":{"id":"f4719c50ce8c_88","name":"3d23","type":"P","href":null,"layout":null,"metadata":null,"text":"We define the scale of the arrows and use this to define the horizontal component labelled u. For movement actions, we simply multiply the movement in the x direction by this factor and for the throw direction we either move 1 unit left or right (accounting for no horizontal movement for 0 or 180 degrees and no vertical movement at 90 or 270 degrees).","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_89":{"id":"f4719c50ce8c_89","name":"8588","type":"P","href":null,"layout":null,"metadata":null,"text":"The horizontal component is then used to calculate the vertical component with some basic trigonometry where we again account for certain angles that would cause errors in the calculations.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_90":{"id":"f4719c50ce8c_90","name":"c2ba","type":"P","href":null,"layout":null,"metadata":null,"text":"We see that some states have multiple best actions. Those directly north, east, south of west can move in multiple directions whereas the states (1,1), (1,-1),(-1,-1) and (-1,1) can either move or throw towards the bin.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_91":{"id":"f4719c50ce8c_91","name":"2ac6","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*wYrRHhXVJknC9FHj7XTdZw.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*wYrRHhXVJknC9FHj7XTdZw.png":{"id":"1*wYrRHhXVJknC9FHj7XTdZw.png","originalHeight":605,"originalWidth":627,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_92":{"id":"f4719c50ce8c_92","name":"9fb0","type":"P","href":null,"layout":null,"metadata":null,"text":"Lastly, I decided to show the change of the optimal policy over each update by exporting each plot and passing into a small animation.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_93":{"id":"f4719c50ce8c_93","name":"8800","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*hrzESilcBh6DFTMGLc7JNQ.gif","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*hrzESilcBh6DFTMGLc7JNQ.gif":{"id":"1*hrzESilcBh6DFTMGLc7JNQ.gif","originalHeight":720,"originalWidth":720,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_94":{"id":"f4719c50ce8c_94","name":"2f7f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Stage 3: Finding the Optimal Policy with Reinforcement Learning where the Probabilities are hidden","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_95":{"id":"f4719c50ce8c_95","name":"87b1","type":"H4","href":null,"layout":null,"metadata":null,"text":"Q-Learning Algorithm","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_96":{"id":"f4719c50ce8c_96","name":"70d3","type":"P","href":null,"layout":null,"metadata":null,"text":"We will now imagine that the probabilities are unknown to the person and therefore experience is needed to find the optimal actions.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_97":{"id":"f4719c50ce8c_97","name":"0499","type":"P","href":null,"layout":null,"metadata":null,"text":"First, let’s try to find the optimal action if the person starts in a fixed position and the bin is fixed to (0,0) as before.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_98":{"id":"f4719c50ce8c_98","name":"308b","type":"P","href":null,"layout":null,"metadata":null,"text":"We will be applying Q-learning and initialise all state-action pairs with a value of 0 and use the update rule:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_99":{"id":"f4719c50ce8c_99","name":"4da9","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*PxiAVctAXhM5Mm19PoLZpw.png","typename":"ImageMetadata"},"text":"Q learning Update Rule","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*PxiAVctAXhM5Mm19PoLZpw.png":{"id":"1*PxiAVctAXhM5Mm19PoLZpw.png","originalHeight":51,"originalWidth":439,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_100":{"id":"f4719c50ce8c_100","name":"3183","type":"P","href":null,"layout":null,"metadata":null,"text":"We give the algorithm the choice to throw in any 360 degree direction (to a whole degree) or to move to any surrounding position of the current one. There are therefore 8 places it can move: north, north-east, east, etc.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_101":{"id":"f4719c50ce8c_101","name":"148e","type":"P","href":null,"layout":null,"metadata":null,"text":"When it chooses to throw the paper, it will either receive a positive reward of +1 or a negative of -1 depending on whether it hits the bin or not and the episode ends.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_102":{"id":"f4719c50ce8c_102","name":"7f45","type":"P","href":null,"layout":null,"metadata":null,"text":"It will need to establish by a number of trial and error attempts where the bin is located and then whether it is better to move first or throw from the current position.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_103":{"id":"f4719c50ce8c_103","name":"63d5","type":"P","href":null,"layout":null,"metadata":null,"text":"Q-Learning Pseudo-code","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_103.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_103.markups.0":{"type":"STRONG","start":0,"end":22,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_104":{"id":"f4719c50ce8c_104","name":"162f","type":"P","href":null,"layout":null,"metadata":null,"text":"First, as before, we initialise the Q-table with arbitrary values of 0.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_105":{"id":"f4719c50ce8c_105","name":"1e6c","type":"P","href":null,"layout":null,"metadata":null,"text":"For now, the start of the episode’s position will be fixed to one state and we also introduce a cap on the number of actions in each episode so that it doesn’t accidentally keep going endlessly.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_106":{"id":"f4719c50ce8c_106","name":"ed01","type":"P","href":null,"layout":null,"metadata":null,"text":"Each episode ends naturally if the paper is thrown, the action the algorithm performs is decided by the epsilon-greedy action selection procedure whereby the action is selected randomly with probability epsilon and greedily (current max) otherwise. To balance the random selection slightly between move or throwing actions (as there are only 8 move actions but 360 throwing actions) I decided to give the algorithm a 50\u002F50 chance of moving or throwing then will subsequently pick an action randomly from these.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_107":{"id":"f4719c50ce8c_107","name":"7ff1","type":"P","href":null,"layout":null,"metadata":null,"text":"As before, the random movement action cannot go beyond the boundary of the room and once found we update the current Q(s,a) dependent upon the max Q(s’,a) for all possible subsequent actions. For example, if we move from -9,-9 to -8,-8, Q( (-9,-9), (1,1) ) will update according the the maximum of Q( (-8,-8), a ) for all possible actions including the throwing ones.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_108":{"id":"f4719c50ce8c_108","name":"3220","type":"P","href":null,"layout":null,"metadata":null,"text":"If the algorithms throws the paper, the probability of success is calculated for this throw and we simulate whether in this case it was successful and receives a positive terminal reward or was unsuccessful and receives a negative terminal reward.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_109":{"id":"f4719c50ce8c_109","name":"4769","type":"P","href":null,"layout":null,"metadata":null,"text":"The algorithm continues to update the Q values for each state-action pair until the results converge.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_110":{"id":"f4719c50ce8c_110","name":"c2a1","type":"P","href":null,"layout":null,"metadata":null,"text":"We will analyse the effect of varying parameters in the next post but for now simply introduce some arbitrary parameter choices of:\n — num_episodes = 100\n — alpha = 0.5\n — gamma = 0.5\n — epsilon = 0.2\n — max_actions = 1000\n — pos_terminal_reward = 1\n — neg_terminal_reward = -1","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:f4719c50ce8c_110.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_110.markups.0":{"type":"STRONG","start":0,"end":131,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:f4719c50ce8c_111":{"id":"f4719c50ce8c_111","name":"20bb","type":"P","href":null,"layout":null,"metadata":null,"text":"Running the algorithm with these parameters 10 times we produce the following ‘optimal’ action for state -5,-5:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_112":{"id":"f4719c50ce8c_112","name":"86d6","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*pXjvkz7Pl94yx_tyNUICQg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*pXjvkz7Pl94yx_tyNUICQg.png":{"id":"1*pXjvkz7Pl94yx_tyNUICQg.png","originalHeight":627,"originalWidth":371,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_113":{"id":"f4719c50ce8c_113","name":"03e6","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*DSW1rqJ2m4QKFikX0HLABg.png","typename":"ImageMetadata"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*DSW1rqJ2m4QKFikX0HLABg.png":{"id":"1*DSW1rqJ2m4QKFikX0HLABg.png","originalHeight":278,"originalWidth":394,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:f4719c50ce8c_114":{"id":"f4719c50ce8c_114","name":"c34f","type":"P","href":null,"layout":null,"metadata":null,"text":"Clearly these are not aligned which heavily suggests the actions are not in fact optimal. Therefore, we need to consider how the parameters we have chosen effect the output and what can be done to improve the results.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_115":{"id":"f4719c50ce8c_115","name":"54fa","type":"H3","href":null,"layout":null,"metadata":null,"text":"Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_116":{"id":"f4719c50ce8c_116","name":"5d35","type":"P","href":null,"layout":null,"metadata":null,"text":"We have introduced an environment from scratch in Python and found the optimal policy. Furthermore, I have begun to introduce the method for finding the optimal policy with Q-learning.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_117":{"id":"f4719c50ce8c_117","name":"9b59","type":"P","href":null,"layout":null,"metadata":null,"text":"I will continue this in a follow up post and improve these initial results by varying the parameters. For now, I hope this demonstrates enough for you to begin trying their own algorithms on this example.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_118":{"id":"f4719c50ce8c_118","name":"00cc","type":"P","href":null,"layout":null,"metadata":null,"text":"If you have any questions, please feel free to comment below or on the Kaggle pages.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_119":{"id":"f4719c50ce8c_119","name":"ebc6","type":"P","href":null,"layout":null,"metadata":null,"text":"Thanks","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:f4719c50ce8c_120":{"id":"f4719c50ce8c_120","name":"b4ee","type":"P","href":null,"layout":null,"metadata":null,"text":"Phil","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Tag:machine-learning":{"id":"machine-learning","displayTitle":"Machine Learning","__typename":"Tag"},"Tag:data-science":{"id":"data-science","displayTitle":"Data Science","__typename":"Tag"},"Tag:reinforcement-learning":{"id":"reinforcement-learning","displayTitle":"Reinforcement Learning","__typename":"Tag"},"Tag:learning":{"id":"learning","displayTitle":"Learning","__typename":"Tag"},"Tag:guides-and-tutorials":{"id":"guides-and-tutorials","displayTitle":"Guides And Tutorials","__typename":"Tag"},"1eca0103fff3":{"topicId":"1eca0103fff3","name":"Machine Learning","__typename":"Topic","slug":"machine-learning"},"ae5d4995e225":{"topicId":"ae5d4995e225","name":"Data Science","__typename":"Topic","slug":"data-science"},"$Post:48c40021da4.postResponses":{"count":1,"__typename":"PostResponses"},"$Post:48c40021da4.previewContent":{"subtitle":"Part 1: Defining the Environment, Finding the Optimal Policy with Value-Iteration and Introducing Q-Learning","__typename":"PreviewContent"}}</script><script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/manifest.7ab78621.js"></script><script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/vendors_main.9b112131.chunk.js"></script><script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/main.341af579.chunk.js"></script><script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/vendors_instrumentation.d7114bfc.chunk.js"></script>
<script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/instrumentation.26954fdd.chunk.js"></script>
<script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/reporting.f609fc16.chunk.js"></script>
<script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/vendors_AMPPost_CollectionHomepage_CollectionHomepagePreview_CollectionNewShortformEditor_Collection_37c9fa1e.77e6fe9c.chunk.js"></script>
<script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/vendors_AMPPost_DebugCachedPost_Post_SequencePost_Series.0bf77567.chunk.js"></script>
<script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/AMPPost_CollectionHomepage_CollectionHomepagePreview_CollectionNewShortformEditor_CollectionPostShor_3fa3f642.7fd9e351.chunk.js"></script>
<script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/AMPPost_CollectionHomepage_CollectionHomepagePreview_DebugCachedPost_PackageBuilder_Post_PostSetting_8e568ca5.4f4062b9.chunk.js"></script>
<script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/Post.8264eaf7.chunk.js"></script><script>window.main();</script><script src="./Reinforcement Learning from Scratch_ Designing and Solving a Task All Within a Python Notebook_files/p.js" async="" id="parsely-cf"></script></body></html>